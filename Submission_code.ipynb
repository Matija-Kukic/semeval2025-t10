{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64155810-5954-48ec-bd27-28e070e9b74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/matijak/Documents/programiranje/projects/semeval/merged_data/subtask1.parquet\n",
      "/home/matijak/Documents/programiranje/projects/semeval/merged_data/subtask1_test.parquet\n",
      "/home/matijak/Documents/programiranje/projects/semeval/merged_data/subtask1_submisson.parquet\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "wd = Path.cwd()\n",
    "wd = wd / 'merged_data'\n",
    "sub1 = str(wd) + '/subtask1.parquet'\n",
    "sub2 = str(wd) + '/subtask1_test.parquet'\n",
    "sub3 = str(wd) + '/subtask1_submisson.parquet'\n",
    "print(sub1)\n",
    "print(sub2)\n",
    "print(sub3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66792dfe-a4e3-4a09-9eb1-b4a0ce6ec526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(sub1)\n",
    "df2 = pd.read_parquet(sub2)\n",
    "df3 = pd.read_parquet(sub3)\n",
    "#print(df2.tail())\n",
    "#print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "397afe56-bd73-436e-94b0-7890b1d9aed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3506, 8)\n",
      "(1186, 6)\n",
      "(4692, 8)\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df, df2], ignore_index=True)\n",
    "print(df.shape)\n",
    "print(df3.shape)\n",
    "df = pd.concat([df, df3], ignore_index=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34541725-575a-403a-afd4-887cae34c5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def labelNum(row):\n",
    "    if row['class1'] == 'Antagonist':\n",
    "        return int(0)\n",
    "    if row['class1'] == 'Innocent':\n",
    "        return int(1)\n",
    "    if row['class1'] == 'Protagonist':\n",
    "        return int(2)\n",
    "def cleanText(row):\n",
    "    text = str(row['text'])\n",
    "    #text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = text.replace('\\n',' ').replace('  ', ' ')\n",
    "    return text\n",
    "df['label1'] = df.apply(labelNum,axis=1)\n",
    "df['input'] = df.apply(cleanText,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04af205a-5ac7-41a6-8eba-ecbadd30f207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelNum2(row):\n",
    "    labels2 = [0 for _ in range(22)]\n",
    "    if row['label1'] == 2:\n",
    "        #labels2 = [0 for _ in range(6)]\n",
    "        if 'Guardian' in row['classes2']:\n",
    "            labels2[0] = 1\n",
    "        if 'Martyr' in row['classes2']:\n",
    "            labels2[1] = 1\n",
    "        if 'Peacemaker' in row['classes2']:\n",
    "            labels2[2] = 1\n",
    "        if 'Rebel' in row['classes2']:\n",
    "            labels2[3] = 1\n",
    "        if 'Underdog' in row['classes2']:\n",
    "            labels2[4] = 1\n",
    "        if 'Virtuous' in row['classes2']:\n",
    "            labels2[5] = 1\n",
    "    elif row['label1'] == 0:\n",
    "        #labels2 = [0 for _ in range(12)]\n",
    "        if 'Instigator' in row['classes2']:\n",
    "           labels2[6] = 1\n",
    "        if 'Conspirator' in row['classes2']:\n",
    "            labels2[7] = 1\n",
    "        if 'Tyrant' in row['classes2']:\n",
    "            labels2[8] = 1\n",
    "        if  'Foreign Adversary' in row['classes2']:\n",
    "            labels2[9] = 1\n",
    "        if 'Traitor' in row['classes2']:\n",
    "            labels2[10] = 1\n",
    "        if 'Spy' in row['classes2']:\n",
    "            labels2[11] = 1\n",
    "        if 'Saboteur' in row['classes2']:\n",
    "            labels2[12] = 1\n",
    "        if 'Corrupt' in row['classes2']:\n",
    "            labels2[13] = 1\n",
    "        if 'Incompetent' in row['classes2']:\n",
    "            labels2[14] = 1\n",
    "        if 'Terrorist' in row['classes2']:\n",
    "            labels2[15] = 1\n",
    "        if 'Deceiver' in row['classes2']:\n",
    "            labels2[16] = 1\n",
    "        if 'Bigot' in row['classes2']:\n",
    "            labels2[17] = 1\n",
    "    elif row['label1'] == 1:\n",
    "        #labels2 = [0 for _ in range(4)]\n",
    "        if 'Forgotten' in row['classes2']:\n",
    "            labels2[18] = 1\n",
    "        if 'Exploited' in row['classes2']:\n",
    "            labels2[19] = 1\n",
    "        if 'Victim' in row['classes2']:\n",
    "            labels2[20] = 1\n",
    "        if 'Scapegoat' in row['classes2']:\n",
    "            labels2[21] = 1\n",
    "    return labels2\n",
    "\n",
    "df['label2'] = df.apply(labelNum2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c835a5a-f3af-4177-bca8-40f830fc5f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang                                                            BG\n",
      "art_name                                                BG_670.txt\n",
      "entity                                                       Запад\n",
      "start                                                          152\n",
      "end                                                            156\n",
      "class1                                                  Antagonist\n",
      "classes2              [Conspirator, Instigator, Foreign Adversary]\n",
      "text             Опитът на колективния Запад да „обезкърви Руси...\n",
      "label1                                                         0.0\n",
      "input            Опитът на колективния Запад да „обезкърви Руси...\n",
      "label2           [0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, ...\n",
      "new_start_end                                           (151, 156)\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def find_all_substring_start_end(text, substring):\n",
    "    # Use re.finditer to find all occurrences of the substring in the text\n",
    "    matches = re.finditer(re.escape(substring), text)\n",
    "\n",
    "    # Collect the start and end indices of all matches\n",
    "    positions = [(match.start(), match.end()) for match in matches]\n",
    "\n",
    "    return positions\n",
    "def adjust_start_end(row):\n",
    "    org_text,cl_text,start,end,entity = str(row['text']),str(row['input']),int(row['start']),int(row['end']),str(row['entity'])\n",
    "    ss1 = find_all_substring_start_end(org_text,entity)\n",
    "    ss2 = find_all_substring_start_end(cl_text,entity)\n",
    "    #print(ss1,ss2)\n",
    "    #print(row['text'][start:end])\n",
    "    a = 0\n",
    "    for i in range(len(ss1)):\n",
    "        if abs((ss1[i][0] - start) + (ss1[i][1] - end) ) <= 2:\n",
    "            a = i\n",
    "            break\n",
    "    if org_text[ss1[a][0]:ss1[a][1]] != cl_text[ss2[a][0]:ss2[a][1]]:\n",
    "        print(\"ERROR!\")\n",
    "    return ss2[a][0],ss2[a][1]\n",
    "df['new_start_end'] = df.apply(adjust_start_end,axis=1)\n",
    "print(df.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e4d380a-01d9-4793-8731-3291fd0cacbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTokensToInput(row):\n",
    "    inp = row['input']\n",
    "    start,end = row['new_start_end']\n",
    "    #print(start,end)\n",
    "    start = int(start)\n",
    "    end = int(end)\n",
    "    token_input = inp[:start] + \"[SPAN_START] \" + inp[start:end] + \" [SPAN_END]\" + inp[end:]\n",
    "    return token_input\n",
    "\n",
    "df['span_input'] = df.apply(addTokensToInput,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65b7700b-c814-44c9-883f-6eec7f81d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upStartEnd(row):\n",
    "    start,end = row['new_start_end']\n",
    "    start += len(\"[SPAN_START] \")\n",
    "    end += len(\"[SPAN_START] \")\n",
    "    return start,end\n",
    "\n",
    "df['new_start_end'] = df.apply(upStartEnd,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9c64aea-5bdf-492d-8892-ee07cdf6f080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizerFast\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-base\", num_labels=22,problem_type=\"multi_label_classification\").to(device)\n",
    "tokenizer = XLMRobertaTokenizerFast.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['span_input'], padding=True, truncation=True,max_length=8192,return_offsets_mapping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "290717e8-95f7-4444-93b6-389c1da9c3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(250004, 768, padding_idx=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraTokens = {\n",
    "    \"additional_special_tokens\": [\"[SPAN_START]\", \"[SPAN_END]\"]\n",
    "}\n",
    "num_added_toks = tokenizer.add_special_tokens(extraTokens)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a67ee28d-061b-4a62-88ca-804633d3173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.loc[ : , ['span_input', 'label1', 'label2', 'new_start_end', 'entity']]\n",
    "data['tokenized']=data.apply(preprocess_function,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec01928f-d196-4eeb-9e35-0014559334e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexes(row):\n",
    "    off_mask = row['tokenized']['offset_mapping']\n",
    "    start,end = row['new_start_end'][0],row['new_start_end'][1]\n",
    "    inds = list()\n",
    "    for p in range(len(off_mask)):\n",
    "        if off_mask[p][0] >= start and off_mask[p][1] <= end:\n",
    "            if p != len(off_mask)-1:\n",
    "                inds.append(p)\n",
    "    #if len(inds) > 1:\n",
    "        #print(\"GREATER THAN 1\")\n",
    "    if len(inds) == 0:\n",
    "        print(start,end)\n",
    "    return inds\n",
    "data['indexes'] = data.apply(indexes,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e20ceb34-0d7a-47da-9005-1f1a0405b767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4692 4692 4692\n"
     ]
    }
   ],
   "source": [
    "data['list'] = data['tokenized'].apply(lambda x: x['input_ids'])\n",
    "data['attention'] = data['tokenized'].apply(lambda x: x['attention_mask'])\n",
    "ids = data['list']\n",
    "att = data['attention']\n",
    "indexes = data['indexes']\n",
    "tids = list()\n",
    "tatt = list()\n",
    "print(len(ids),len(att),len(indexes))\n",
    "for i in range(len(ids)):\n",
    "    tids.append(torch.tensor(ids[i]))\n",
    "    tatt.append(torch.tensor(att[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9c46c4a-09b4-4073-a7da-a9a78a91fdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_ids = list()\n",
    "sliced_ntids = list()\n",
    "sliced_att = list()\n",
    "key_inds = list()\n",
    "key_ids = list()\n",
    "\n",
    "def slices(index,size,context_size):\n",
    "    if (size<context_size):\n",
    "        return 0,size\n",
    "    lower_c = int(context_size/2-1)\n",
    "    upper_c = int(context_size/2)\n",
    "    #print(lower_c,upper_c)\n",
    "    if index < lower_c:\n",
    "        return 0,context_size\n",
    "    elif index >= lower_c:\n",
    "        if index + upper_c > size:\n",
    "            return index-(context_size-(size-index)), size\n",
    "        else:\n",
    "            return index-lower_c,index+upper_c+1\n",
    "\n",
    "\n",
    "for i in range(len(tids)):\n",
    "    slower,supper = slices(indexes[i][0],len(tids[i]),510)\n",
    "    #key_tid = tids[i][indexes[i][0]]\n",
    "    pid = ids[i][slower:supper]\n",
    "    key_inds.append([])\n",
    "    for j in indexes[i]:\n",
    "        key_id = ids[i][j]\n",
    "        if key_id not in pid:\n",
    "           print(len(ids[i]),key_id,slower,supper,indexes[i])\n",
    "        key_inds[i].append(pid.index(key_id))\n",
    "    apid = tids[i][slower:supper]\n",
    "    apatt = tatt[i][slower:supper]\n",
    "    if 0 not in pid:\n",
    "        apid = torch.cat((torch.tensor([0]),apid),dim=0)\n",
    "        apatt = torch.cat((torch.tensor([1]),apatt),dim=0)\n",
    "    if 2 not in pid:\n",
    "        apid = torch.cat((apid,torch.tensor([2])),dim=0)\n",
    "        apatt = torch.cat((apatt,torch.tensor([1])),dim=0)\n",
    "    sliced_ids.append(apid)\n",
    "    sliced_att.append(apatt)\n",
    "\n",
    "Min = 10000\n",
    "Max = 0\n",
    "ind2 = 0\n",
    "for i in range(len(indexes)):\n",
    "    if len(sliced_ids[i]) < Min:\n",
    "        Min = len(sliced_ids[i])\n",
    "        ind2 = i\n",
    "\n",
    "    if len(sliced_ids[i]) > Max:\n",
    "        Max = len(sliced_ids[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d636addb-7f8d-471c-8f2b-5cfe1ce9b785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "input_ids = list()\n",
    "att_mask = list()\n",
    "for ten,att in zip(sliced_ids,sliced_att):\n",
    "    if len(ten) < 512:\n",
    "        padding_length = 512 - len(ten)\n",
    "        padding_tensor = torch.full((padding_length,), tokenizer.pad_token_id, dtype=ten.dtype)\n",
    "        padding_tensor2 = torch.full((padding_length,), 0, dtype=att.dtype)\n",
    "        ten = torch.cat((ten,padding_tensor),dim=0)\n",
    "        att = torch.cat((att,padding_tensor2),dim=0)\n",
    "    input_ids.append(ten)\n",
    "    att_mask.append(att)\n",
    "inputIds = torch.stack(input_ids)\n",
    "attMask = torch.stack(att_mask)\n",
    "\n",
    "inputIds_np = inputIds.numpy()\n",
    "attMask_np = attMask.numpy()\n",
    "y1 = data['label1'].values\n",
    "y2 = data['label2'].values\n",
    "lang = df['lang'].tolist()\n",
    "lang = np.array(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43732a6f-bfed-4414-b2b3-b85495386fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ids = inputIds_np[:3506]\n",
    "X_test_ids = inputIds_np[3506:]\n",
    "#print(len(X_train_ids),len(X_test_ids))\n",
    "X_train_mask = attMask_np[:3506]\n",
    "X_test_mask = attMask_np[3506:]\n",
    "\n",
    "y1_train = y1[:3506]\n",
    "y1_test = y1[3506:]\n",
    "\n",
    "y2_train = y2[:3506]\n",
    "y2_test = y2[3506:]\n",
    "\n",
    "lang_train = lang[:3506]\n",
    "lang_test = lang[3506:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3366fe9-1fe3-4bdb-b079-53558afebbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y2_train = np.array(y2_train.tolist(), dtype=np.int8)\n",
    "y2_test = np.array(y2_test.tolist(), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90969f59-eee0-45e4-9846-352a96729c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ids = torch.tensor(X_train_ids, dtype=torch.long).to(device)\n",
    "X_test_ids = torch.tensor(X_test_ids, dtype=torch.long).to(device)\n",
    "X_train_mask = torch.tensor(X_train_mask, dtype=torch.long).to(device)\n",
    "X_test_mask = torch.tensor(X_test_mask, dtype=torch.long).to(device)\n",
    "y1_train = torch.tensor(y1_train, dtype=torch.long).to(device)\n",
    "y1_test = torch.tensor(y1_test, dtype=torch.long).to(device)\n",
    "y2_train = torch.tensor(y2_train, dtype=torch.long).to(device)\n",
    "y2_test = torch.tensor(y2_test, dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a501f38-daa3-4ba2-a40a-1cbaebb7cb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(X_train_ids, X_train_mask, y1_train, y2_train)\n",
    "test_dataset = TensorDataset(X_test_ids, X_test_mask, y1_test, y2_test )\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True) #shuffle=True provides data shuffle for batches in different epochs\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4e117d1-3c82-4672-ad51-a20e4f99d732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class HierarchicalNN(nn.Module):\n",
    "    def __init__(self, input_dim, num_parent_classes, num_subcategory_classes,hidden_size):\n",
    "        super(HierarchicalNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_size)\n",
    "        \n",
    "\n",
    "        # Parent class output head\n",
    "        self.parent_fc = nn.Linear(hidden_size, num_parent_classes)\n",
    "\n",
    "        # Subcategory output head (conditional on parent class)\n",
    "        self.subcategory_fc = nn.Linear(hidden_size, num_subcategory_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        gelu = nn.GELU()\n",
    "        x = self.fc1(x)\n",
    "        x = gelu(x)\n",
    "\n",
    "        #parent_output = self.parent_fc(x)  # Parent class logits\n",
    "        subcategory_output = self.subcategory_fc(x)  # Subcategory logits\n",
    "\n",
    "        return subcategory_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "065a3f7d-7660-4361-8c1d-a2e6d071d6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "#classifier = nn.Linear(model.config.hidden_size * 2, 22).to(device)\n",
    "classifier = HierarchicalNN(model.config.hidden_size * 2,3,22, model.config.hidden_size * 2).to(device)\n",
    "optimizer = AdamW([\n",
    "    {'params': model.parameters(),'lr':2e-5},  # Lower learning rate for XLM-RoBERTa\n",
    "    {'params': classifier.parameters(),'lr':1e-3}     # Higher learning rate for the classifier\n",
    "])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion2 = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02f6a0d4-66e4-4068-90bc-3efd88ed8ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: tensor([False, False, False, False, False, False,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True]), 0: tensor([ True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True,  True,\n",
      "         True,  True]), 1: tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "        False, False])}\n"
     ]
    }
   ],
   "source": [
    "test_batch= torch.Tensor([\n",
    "    #1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22\n",
    "    [1,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0],\n",
    "    [1,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "    [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1]\n",
    "])\n",
    "test_parent = torch.Tensor([\n",
    "    [2],\n",
    "    [0],\n",
    "    [1]\n",
    "])\n",
    "mask = {}\n",
    "mask[2] = torch.cat([torch.zeros(6, dtype=torch.bool), torch.ones(16, dtype=torch.bool)])\n",
    "mask[0] = torch.cat([torch.ones(6, dtype=torch.bool), torch.zeros(12, dtype=torch.bool), torch.ones(4, dtype=torch.bool)])\n",
    "mask[1] = torch.cat([torch.ones(18, dtype=torch.bool), torch.zeros(4, dtype=torch.bool)])\n",
    "print(mask)\n",
    "def apply_mask(labels,parent,mask):\n",
    "    \n",
    "    # Create an empty tensor to store the results\n",
    "    result = labels.clone()\n",
    "\n",
    "    # Loop through the batch and apply the corresponding tensor from result_dict\n",
    "    for i in range(labels.shape[0]):\n",
    "        idx = parent[i].item()  # Get the index (0, 1, or 2)\n",
    "        mask2 = mask[idx]  # Apply the corresponding tensor from result_dict\n",
    "\n",
    "        result[i][~mask2] = 0 \n",
    "\n",
    "    return result\n",
    "#print(apply_mask(test_batch,test_parent,mask))\n",
    "zero_ten = torch.zeros((16, 22), dtype=torch.float32).to(device)\n",
    "#print(zero_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d753725-2bd3-46a2-a89f-19766f784e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the confusion matrix in the end\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "span_start_token_id = tokenizer.convert_tokens_to_ids('[SPAN_START]')\n",
    "span_end_token_id = tokenizer.convert_tokens_to_ids('[SPAN_END]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f31933d1-1b4c-4a0e-8513-6225421fcf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 220/220 [03:19<00:00,  1.11it/s, loss=0.922]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Parent Train accuracy: 0.6771\n",
      "Training loss: 0.7293, Training accuracy: 0.1965\n",
      "Train Micro Precision: 0.3050, Recall: 0.3150, F1: 0.3099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 220/220 [03:19<00:00,  1.10it/s, loss=0.401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "Parent Train accuracy: 0.8314\n",
      "Training loss: 0.6661, Training accuracy: 0.2944\n",
      "Train Micro Precision: 0.4425, Recall: 0.5581, F1: 0.4936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 220/220 [03:20<00:00,  1.10it/s, loss=0.885]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "Parent Train accuracy: 0.9062\n",
      "Training loss: 0.6360, Training accuracy: 0.3756\n",
      "Train Micro Precision: 0.5060, Recall: 0.7121, F1: 0.5916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 220/220 [03:20<00:00,  1.10it/s, loss=0.528]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "Parent Train accuracy: 0.9361\n",
      "Training loss: 0.6142, Training accuracy: 0.4469\n",
      "Train Micro Precision: 0.5582, Recall: 0.7985, F1: 0.6571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 220/220 [03:20<00:00,  1.10it/s, loss=0.609]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "Parent Train accuracy: 0.9649\n",
      "Training loss: 0.5922, Training accuracy: 0.5585\n",
      "Train Micro Precision: 0.6425, Recall: 0.8712, F1: 0.7395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 220/220 [03:20<00:00,  1.10it/s, loss=0.616]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "Parent Train accuracy: 0.9792\n",
      "Training loss: 0.5746, Training accuracy: 0.6563\n",
      "Train Micro Precision: 0.7239, Recall: 0.9226, F1: 0.8113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 220/220 [03:20<00:00,  1.10it/s, loss=0.662]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "Parent Train accuracy: 0.9812\n",
      "Training loss: 0.5657, Training accuracy: 0.7210\n",
      "Train Micro Precision: 0.7728, Recall: 0.9381, F1: 0.8475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 220/220 [03:20<00:00,  1.10it/s, loss=0.572]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "Parent Train accuracy: 0.9872\n",
      "Training loss: 0.5565, Training accuracy: 0.8015\n",
      "Train Micro Precision: 0.8359, Recall: 0.9555, F1: 0.8917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 220/220 [03:20<00:00,  1.10it/s, loss=0.389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "Parent Train accuracy: 0.9875\n",
      "Training loss: 0.5511, Training accuracy: 0.8406\n",
      "Train Micro Precision: 0.8681, Recall: 0.9655, F1: 0.9142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/10: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 220/220 [03:20<00:00,  1.10it/s, loss=0.791]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "Parent Train accuracy: 0.9869\n",
      "Training loss: 0.5542, Training accuracy: 0.8383\n",
      "Train Micro Precision: 0.8645, Recall: 0.9610, F1: 0.9102\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "debug = 0\n",
    "pred_list = list()\n",
    "labels_list = list()\n",
    "log_list =list()\n",
    "losses=list()\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model.train()\n",
    "    classifier.train()\n",
    "    total_loss = 0\n",
    "    correct_parents = 0\n",
    "    total_parents = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    train_preds = np.empty((0, 22), dtype=np.int8)\n",
    "    train_labels = np.empty((0, 22), dtype=np.int8)\n",
    "    \n",
    "    train_progress_bar = tqdm(train_dataloader, desc=f\"Training Epoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    for batch in train_progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        parents = batch[2].to(device)\n",
    "        labels = batch[3].to(device)\n",
    "        batch_size = input_ids.size(0)\n",
    "\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels.float(), output_hidden_states=True)\n",
    "\n",
    "        hidden_states = outputs.hidden_states[-1]\n",
    "\n",
    "        entity_representations = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            ind_start = torch.nonzero(input_ids[i] == span_start_token_id).squeeze()\n",
    "            ind_end = torch.nonzero(input_ids[i] == span_end_token_id).squeeze()\n",
    "            start_ten = hidden_states[i,ind_start]\n",
    "            end_ten = hidden_states[i,ind_end]\n",
    "            #if debug == 0:\n",
    "                #print (ind_start,ind_end)\n",
    "                #print(start_ten.shape,end_ten.shape)\n",
    "            rep = torch.cat((hidden_states[i,ind_start],hidden_states[i,ind_end]),dim=0)\n",
    "            entity_representations.append(rep)\n",
    "\n",
    "\n",
    "        \n",
    "        entity_representations = torch.stack(entity_representations, dim=0)\n",
    "        \n",
    "        \n",
    "        #\n",
    "        child_log = classifier(entity_representations)\n",
    "        child_log2 = apply_mask(child_log,parents,mask)\n",
    "        zero_ten = torch.zeros((input_ids.size(0), 22), dtype=torch.float32).to(device)\n",
    "       \n",
    "        #loss = criterion(parent_log, parents) + criterion2(child_log,labels.float()) + 2 * criterion2(child_log2,zero_ten) \n",
    "        loss = criterion2(child_log,labels.float()) + 2 * criterion2(child_log2,zero_ten)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        preds = (torch.sigmoid(child_log) > 0.15).int()\n",
    "        train_preds = np.vstack([train_preds,preds.cpu().numpy()])\n",
    "        train_labels = np.vstack([train_labels,labels.cpu().numpy()])\n",
    "        correct_predictions += ((preds == labels.int()).all(dim=1)).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "\n",
    "        argmax_indices = torch.argmax(child_log, dim=1)\n",
    "        \n",
    "\n",
    "        parent_preds = torch.where(\n",
    "            argmax_indices <= 5, \n",
    "            torch.tensor(2),  # Set to 2 for indices 0-5\n",
    "            torch.where(\n",
    "            argmax_indices <= 17, \n",
    "            torch.tensor(0),  # Set to 0 for indices 6-17\n",
    "            torch.tensor(1)   # Set to 1 for indices 18-21\n",
    "            )\n",
    "        )\n",
    "        correct_parents += (parent_preds == parents).sum().item()\n",
    "        total_parents += labels.size(0)\n",
    "        \n",
    "\n",
    "        train_progress_bar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "    parent_train_accuracy = correct_parents / total_parents\n",
    "\n",
    "    #parent_train_acc = correct_parents / total_parents\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    print(f\"Parent Train accuracy: {parent_train_accuracy:.4f}\")\n",
    "    print(f\"Training loss: {avg_train_loss:.4f}, Training accuracy: {train_accuracy:.4f}\")\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(train_labels, train_preds, average='micro')\n",
    "    print(f\"Train Micro Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ab9d8d2-088b-4526-81a9-5b2c53ed2858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "argmax_indices =torch.tensor([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21])\n",
    "preds2 = torch.where(\n",
    "            argmax_indices <= 5, \n",
    "            torch.tensor(2),  # Set to 2 for indices 0-5\n",
    "            torch.where(\n",
    "            argmax_indices <= 17, \n",
    "            torch.tensor(0),  # Set to 0 for indices 6-17\n",
    "            torch.tensor(1)   # Set to 1 for indices 18-21\n",
    "            )\n",
    "        )\n",
    "print(preds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb767afb-a49d-4218-955a-30e5a2a06835",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "classifier.eval()\n",
    "test_preds = np.empty((0, 22), dtype=np.int8)\n",
    "par_preds = list()\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        parents = batch[2].to(device)\n",
    "        labels = batch[3].to(device)\n",
    "\n",
    "        batch_size = input_ids.size(0)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels.float(), output_hidden_states=True)\n",
    "\n",
    "        hidden_states = outputs.hidden_states[-1]\n",
    "\n",
    "        entity_representations = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            ind_start = torch.nonzero(input_ids[i] == span_start_token_id).squeeze()\n",
    "            ind_end = torch.nonzero(input_ids[i] == span_end_token_id).squeeze()\n",
    "            start_ten = hidden_states[i,ind_start]\n",
    "            end_ten = hidden_states[i,ind_end]\n",
    "            rep = torch.cat((hidden_states[i,ind_start],hidden_states[i,ind_end]),dim=0)\n",
    "            entity_representations.append(rep)\n",
    "        entity_representations = torch.stack(entity_representations, dim=0)\n",
    "\n",
    "        #parent_log,\n",
    "        child_log = classifier(entity_representations)\n",
    "\n",
    "\n",
    "        sigmoid_probs = torch.sigmoid(child_log)\n",
    "\n",
    "        preds = (sigmoid_probs > 0.15).int()  # Shape: (batch_size, num_labels)\n",
    "        \n",
    "        max_indices = torch.argmax(sigmoid_probs, dim=1)  # Shape: (batch_size,)\n",
    "        \n",
    "        \n",
    "        batch_indices = torch.arange(labels.size(0))  \n",
    "        preds[batch_indices, max_indices] = 1 \n",
    "\n",
    "        \n",
    "        argmax_indices = torch.argmax(child_log, dim=1)\n",
    "        parent_preds = torch.where(\n",
    "            argmax_indices <= 5, \n",
    "            torch.tensor(2),  # Set to 2 for indices 0-5\n",
    "            torch.where(\n",
    "            argmax_indices <= 17, \n",
    "            torch.tensor(0),  # Set to 0 for indices 6-17\n",
    "            torch.tensor(1)   # Set to 1 for indices 18-21\n",
    "            )\n",
    "        )\n",
    "        test_preds = np.vstack([test_preds,preds.cpu().numpy()])\n",
    "        par_preds.append(parent_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e46d89d2-91e5-48b9-9494-86ec17842da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1186])\n",
      "(1186,)\n"
     ]
    }
   ],
   "source": [
    "#print(test_preds.shape)\n",
    "# Concatenate the entire list at once\n",
    "result = torch.cat(par_preds, dim=0)\n",
    "print(result.shape) \n",
    "parent_pred = result.cpu().numpy()\n",
    "print(parent_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3837cf0-6a7c-4bcc-97a3-a67e1f2ae491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>art_name</th>\n",
       "      <th>entity</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BG</td>\n",
       "      <td>A5_CC_BG_10689.txt</td>\n",
       "      <td>па</td>\n",
       "      <td>107</td>\n",
       "      <td>108</td>\n",
       "      <td>Китай: Западните страни носят голяма историчес...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BG</td>\n",
       "      <td>A5_CC_BG_10689.txt</td>\n",
       "      <td>Китай</td>\n",
       "      <td>907</td>\n",
       "      <td>911</td>\n",
       "      <td>Китай: Западните страни носят голяма историчес...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BG</td>\n",
       "      <td>A5_CC_BG_10689.txt</td>\n",
       "      <td>ЕС</td>\n",
       "      <td>4144</td>\n",
       "      <td>4145</td>\n",
       "      <td>Китай: Западните страни носят голяма историчес...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BG</td>\n",
       "      <td>A6_CC_BG_10457.txt</td>\n",
       "      <td>Грета Тунберг</td>\n",
       "      <td>125</td>\n",
       "      <td>137</td>\n",
       "      <td>Грета Тунберг поиска \"радикален обрат в борбат...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BG</td>\n",
       "      <td>A4_URW_BG_14024.txt</td>\n",
       "      <td>Запада</td>\n",
       "      <td>463</td>\n",
       "      <td>468</td>\n",
       "      <td>Путин пред посланици: Илюзорни сметки за побед...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang             art_name         entity start   end  \\\n",
       "0   BG   A5_CC_BG_10689.txt             па   107   108   \n",
       "1   BG   A5_CC_BG_10689.txt          Китай   907   911   \n",
       "2   BG   A5_CC_BG_10689.txt             ЕС  4144  4145   \n",
       "3   BG   A6_CC_BG_10457.txt  Грета Тунберг   125   137   \n",
       "4   BG  A4_URW_BG_14024.txt         Запада   463   468   \n",
       "\n",
       "                                                text  \\\n",
       "0  Китай: Западните страни носят голяма историчес...   \n",
       "1  Китай: Западните страни носят голяма историчес...   \n",
       "2  Китай: Западните страни носят голяма историчес...   \n",
       "3  Грета Тунберг поиска \"радикален обрат в борбат...   \n",
       "4  Путин пред посланици: Илюзорни сметки за побед...   \n",
       "\n",
       "                                               pred1  pred2  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...      0  \n",
       "1  [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      2  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      0  \n",
       "3  [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      2  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...      0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['pred1']=list(test_preds)\n",
    "df3['pred2']=parent_pred\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a27e6bd0-e7eb-4112-9547-f9d28e7a7e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>art_name</th>\n",
       "      <th>entity</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>label1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BG</td>\n",
       "      <td>A5_CC_BG_10689.txt</td>\n",
       "      <td>па</td>\n",
       "      <td>107</td>\n",
       "      <td>108</td>\n",
       "      <td>Китай: Западните страни носят голяма историчес...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Antagonist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BG</td>\n",
       "      <td>A5_CC_BG_10689.txt</td>\n",
       "      <td>Китай</td>\n",
       "      <td>907</td>\n",
       "      <td>911</td>\n",
       "      <td>Китай: Западните страни носят голяма историчес...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Protagonist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BG</td>\n",
       "      <td>A5_CC_BG_10689.txt</td>\n",
       "      <td>ЕС</td>\n",
       "      <td>4144</td>\n",
       "      <td>4145</td>\n",
       "      <td>Китай: Западните страни носят голяма историчес...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Antagonist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BG</td>\n",
       "      <td>A6_CC_BG_10457.txt</td>\n",
       "      <td>Грета Тунберг</td>\n",
       "      <td>125</td>\n",
       "      <td>137</td>\n",
       "      <td>Грета Тунберг поиска \"радикален обрат в борбат...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Protagonist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BG</td>\n",
       "      <td>A4_URW_BG_14024.txt</td>\n",
       "      <td>Запада</td>\n",
       "      <td>463</td>\n",
       "      <td>468</td>\n",
       "      <td>Путин пред посланици: Илюзорни сметки за побед...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Antagonist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang             art_name         entity start   end  \\\n",
       "0   BG   A5_CC_BG_10689.txt             па   107   108   \n",
       "1   BG   A5_CC_BG_10689.txt          Китай   907   911   \n",
       "2   BG   A5_CC_BG_10689.txt             ЕС  4144  4145   \n",
       "3   BG   A6_CC_BG_10457.txt  Грета Тунберг   125   137   \n",
       "4   BG  A4_URW_BG_14024.txt         Запада   463   468   \n",
       "\n",
       "                                                text  \\\n",
       "0  Китай: Западните страни носят голяма историчес...   \n",
       "1  Китай: Западните страни носят голяма историчес...   \n",
       "2  Китай: Западните страни носят голяма историчес...   \n",
       "3  Грета Тунберг поиска \"радикален обрат в борбат...   \n",
       "4  Путин пред посланици: Илюзорни сметки за побед...   \n",
       "\n",
       "                                               pred1  pred2       label1  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...      0   Antagonist  \n",
       "1  [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      2  Protagonist  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      0   Antagonist  \n",
       "3  [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      2  Protagonist  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...      0   Antagonist  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def labelText(row):\n",
    "    if row['pred2'] == 0:\n",
    "        return 'Antagonist'\n",
    "    if row['pred2'] == 1:\n",
    "        return 'Innocent'\n",
    "    if row['pred2'] == 2:\n",
    "        return 'Protagonist'\n",
    "df3['label1'] = df3.apply(labelText,axis=1)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd1be87c-43af-45ef-97cc-c9b2740f4dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>art_name</th>\n",
       "      <th>entity</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BG</td>\n",
       "      <td>A5_CC_BG_10689.txt</td>\n",
       "      <td>па</td>\n",
       "      <td>107</td>\n",
       "      <td>108</td>\n",
       "      <td>Китай: Западните страни носят голяма историчес...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Tyrant]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BG</td>\n",
       "      <td>A5_CC_BG_10689.txt</td>\n",
       "      <td>Китай</td>\n",
       "      <td>907</td>\n",
       "      <td>911</td>\n",
       "      <td>Китай: Западните страни носят голяма историчес...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Protagonist</td>\n",
       "      <td>[Peacemaker, Virtuous]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BG</td>\n",
       "      <td>A5_CC_BG_10689.txt</td>\n",
       "      <td>ЕС</td>\n",
       "      <td>4144</td>\n",
       "      <td>4145</td>\n",
       "      <td>Китай: Западните страни носят голяма историчес...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Deceiver]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BG</td>\n",
       "      <td>A6_CC_BG_10457.txt</td>\n",
       "      <td>Грета Тунберг</td>\n",
       "      <td>125</td>\n",
       "      <td>137</td>\n",
       "      <td>Грета Тунберг поиска \"радикален обрат в борбат...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Protagonist</td>\n",
       "      <td>[Rebel, Virtuous]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BG</td>\n",
       "      <td>A4_URW_BG_14024.txt</td>\n",
       "      <td>Запада</td>\n",
       "      <td>463</td>\n",
       "      <td>468</td>\n",
       "      <td>Путин пред посланици: Илюзорни сметки за побед...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Foreign Adversary, Incompetent]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang             art_name         entity start   end  \\\n",
       "0   BG   A5_CC_BG_10689.txt             па   107   108   \n",
       "1   BG   A5_CC_BG_10689.txt          Китай   907   911   \n",
       "2   BG   A5_CC_BG_10689.txt             ЕС  4144  4145   \n",
       "3   BG   A6_CC_BG_10457.txt  Грета Тунберг   125   137   \n",
       "4   BG  A4_URW_BG_14024.txt         Запада   463   468   \n",
       "\n",
       "                                                text  \\\n",
       "0  Китай: Западните страни носят голяма историчес...   \n",
       "1  Китай: Западните страни носят голяма историчес...   \n",
       "2  Китай: Западните страни носят голяма историчес...   \n",
       "3  Грета Тунберг поиска \"радикален обрат в борбат...   \n",
       "4  Путин пред посланици: Илюзорни сметки за побед...   \n",
       "\n",
       "                                               pred1  pred2       label1  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...      0   Antagonist   \n",
       "1  [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      2  Protagonist   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      0   Antagonist   \n",
       "3  [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      2  Protagonist   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...      0   Antagonist   \n",
       "\n",
       "                             label2  \n",
       "0                          [Tyrant]  \n",
       "1            [Peacemaker, Virtuous]  \n",
       "2                        [Deceiver]  \n",
       "3                 [Rebel, Virtuous]  \n",
       "4  [Foreign Adversary, Incompetent]  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def num2Label(row):\n",
    "    # Define the mapping of indices to class names\n",
    "    index_to_class = [\n",
    "        'Guardian', 'Martyr', 'Peacemaker', 'Rebel', 'Underdog', 'Virtuous',  # Indices 0-5\n",
    "        'Instigator', 'Conspirator', 'Tyrant', 'Foreign Adversary', 'Traitor', 'Spy', 'Saboteur', \n",
    "        'Corrupt', 'Incompetent', 'Terrorist', 'Deceiver', 'Bigot',              # Indices 6-17\n",
    "        'Forgotten', 'Exploited', 'Victim', 'Scapegoat'                          # Indices 18-21\n",
    "    ]\n",
    "    \n",
    "    # Get the prediction row as a list of integers\n",
    "    pred = row['pred1']  # Assumes row['pred1'] is a list or 1D numpy array\n",
    "    \n",
    "    # Generate a list of class names corresponding to indices with value 1\n",
    "    classes = [index_to_class[i] for i in range(len(pred)) if pred[i] == 1]\n",
    "    \n",
    "    return classes\n",
    "df3['label2'] = df3.apply(num2Label,axis=1)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4817129e-7102-4fa5-b2a2-75d961e5adc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_en = df3[df3['lang'] == 'EN']\n",
    "sdf_en = sdf_en.loc[ : ,['art_name','entity','start','end','label1','label2']]\n",
    "sdf_en.head()\n",
    "with open('Submissions/en_sub.txt', 'w') as f:\n",
    "    for row in sdf_en.itertuples(index=False):\n",
    "        flattened_row = []\n",
    "        for value in row:\n",
    "            # If the value is a list, extend the row with its items\n",
    "            if isinstance(value, list):\n",
    "                for z in value:\n",
    "                    flattened_row.append(z)\n",
    "            else:\n",
    "                flattened_row.append(value)\n",
    "        r = str()\n",
    "        for v in flattened_row:\n",
    "            r += v+'\\t'\n",
    "        r+='\\n'\n",
    "        f.write(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8ca5dd9d-cd7e-47ae-b755-5cd3d0848398",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_bg = df3[df3['lang'] == 'BG']\n",
    "sdf_bg = sdf_bg.loc[ : ,['art_name','entity','start','end','label1','label2']]\n",
    "sdf_bg.head()\n",
    "with open('Submissions/bg_sub.txt', 'w') as f:\n",
    "    for row in sdf_bg.itertuples(index=False):\n",
    "        flattened_row = []\n",
    "        for value in row:\n",
    "            # If the value is a list, extend the row with its items\n",
    "            if isinstance(value, list):\n",
    "                for z in value:\n",
    "                    flattened_row.append(z)\n",
    "            else:\n",
    "                flattened_row.append(value)\n",
    "        r = str()\n",
    "        for v in flattened_row:\n",
    "            r += v+'\\t'\n",
    "        r+='\\n'\n",
    "        f.write(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd7d32d0-dcd2-4cbb-a340-839dc8107ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_hi = df3[df3['lang'] == 'HI']\n",
    "sdf_hi = sdf_hi.loc[ : ,['art_name','entity','start','end','label1','label2']]\n",
    "sdf_hi.head()\n",
    "with open('Submissions/hi_sub.txt', 'w') as f:\n",
    "    for row in sdf_hi.itertuples(index=False):\n",
    "        flattened_row = []\n",
    "        for value in row:\n",
    "            # If the value is a list, extend the row with its items\n",
    "            if isinstance(value, list):\n",
    "                for z in value:\n",
    "                    flattened_row.append(z)\n",
    "            else:\n",
    "                flattened_row.append(value)\n",
    "        r = str()\n",
    "        for v in flattened_row:\n",
    "            r += v+'\\t'\n",
    "        r+='\\n'\n",
    "        f.write(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6e676f21-b7d6-4c28-b064-d933b7a1c6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_pt = df3[df3['lang'] == 'PT']\n",
    "sdf_pt = sdf_pt.loc[ : ,['art_name','entity','start','end','label1','label2']]\n",
    "sdf_pt.head()\n",
    "with open('Submissions/pt_sub.txt', 'w') as f:\n",
    "    for row in sdf_pt.itertuples(index=False):\n",
    "        flattened_row = []\n",
    "        for value in row:\n",
    "            # If the value is a list, extend the row with its items\n",
    "            if isinstance(value, list):\n",
    "                for z in value:\n",
    "                    flattened_row.append(z)\n",
    "            else:\n",
    "                flattened_row.append(value)\n",
    "        r = str()\n",
    "        for v in flattened_row:\n",
    "            r += v+'\\t'\n",
    "        r+='\\n'\n",
    "        f.write(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c8efcee9-1859-49d0-8f9e-91560f914a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_ru = df3[df3['lang'] == 'RU']\n",
    "sdf_ru = sdf_ru.loc[ : ,['art_name','entity','start','end','label1','label2']]\n",
    "sdf_ru.head()\n",
    "with open('Submissions/ru_sub.txt', 'w') as f:\n",
    "    for row in sdf_ru.itertuples(index=False):\n",
    "        flattened_row = []\n",
    "        for value in row:\n",
    "            # If the value is a list, extend the row with its items\n",
    "            if isinstance(value, list):\n",
    "                for z in value:\n",
    "                    flattened_row.append(z)\n",
    "            else:\n",
    "                flattened_row.append(value)\n",
    "        r = str()\n",
    "        for v in flattened_row:\n",
    "            r += v+'\\t'\n",
    "        r+='\\n'\n",
    "        f.write(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
