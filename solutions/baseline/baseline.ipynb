{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1dcb9da-abd9-4b4b-aaf1-1f3864ac9775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/matijak/Documents/programiranje/projects/semeval/merged_data/subtask1.parquet\n",
      "/home/matijak/Documents/programiranje/projects/semeval/merged_data/subtask1_test.parquet\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "wd = Path.cwd()\n",
    "wd = wd.parent.parent\n",
    "wd = wd / 'merged_data'\n",
    "sub1 = str(wd) + '/subtask1.parquet'\n",
    "sub2 = str(wd) + '/subtask1_test.parquet'\n",
    "print(sub1)\n",
    "print(sub2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c80c0592-207a-4607-80c9-7a30d7dbdfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    lang         art_name      entity start   end      class1  \\\n",
      "599   RU  RU-URW-1139.txt      Запада   212   217  Antagonist   \n",
      "600   RU  RU-URW-1139.txt      России   631   636    Innocent   \n",
      "601   RU  RU-URW-1139.txt        НАТО   993   996  Antagonist   \n",
      "602   RU  RU-URW-1139.txt  Зеленского  2181  2190  Antagonist   \n",
      "603   RU  RU-URW-1139.txt       Киеву  2414  2418  Antagonist   \n",
      "\n",
      "                classes2                                               text  \n",
      "599        [Conspirator]  Битва за воздух как проба стойкости русских\\n2...  \n",
      "600             [Victim]  Битва за воздух как проба стойкости русских\\n2...  \n",
      "601  [Foreign Adversary]  Битва за воздух как проба стойкости русских\\n2...  \n",
      "602  [Foreign Adversary]  Битва за воздух как проба стойкости русских\\n2...  \n",
      "603         [Instigator]  Битва за воздух как проба стойкости русских\\n2...  \n",
      "     lang         art_name           entity start   end       class1  \\\n",
      "2897   RU  RU-URW-1156.txt          Россией   559   565  Protagonist   \n",
      "2898   RU  RU-URW-1156.txt           Москва  1005  1010  Protagonist   \n",
      "2899   RU  RU-URW-1156.txt             НАТО  1298  1301   Antagonist   \n",
      "2900   RU  RU-URW-1156.txt           Киевом  1948  1953   Antagonist   \n",
      "2901   RU  RU-URW-1113.txt  Дмитрия Гордона   133   147   Antagonist   \n",
      "\n",
      "                 classes2                                               text  \n",
      "2897         [Peacemaker]  Медведев: Даже в случае признания поражения Ки...  \n",
      "2898           [Guardian]  Медведев: Даже в случае признания поражения Ки...  \n",
      "2899  [Foreign Adversary]  Медведев: Даже в случае признания поражения Ки...  \n",
      "2900          [Terrorist]  Медведев: Даже в случае признания поражения Ки...  \n",
      "2901         [Instigator]  Эпизоды с призывами «убить Путина» нашли в дел...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(sub1)\n",
    "df2 = pd.read_parquet(sub2)\n",
    "print(df2.tail())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5fd66dd-f991-454f-8684-4bd0a6cc41b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>art_name</th>\n",
       "      <th>entity</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>class1</th>\n",
       "      <th>classes2</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3501</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1139.txt</td>\n",
       "      <td>Запада</td>\n",
       "      <td>212</td>\n",
       "      <td>217</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Conspirator]</td>\n",
       "      <td>Битва за воздух как проба стойкости русских\\n2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3502</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1139.txt</td>\n",
       "      <td>России</td>\n",
       "      <td>631</td>\n",
       "      <td>636</td>\n",
       "      <td>Innocent</td>\n",
       "      <td>[Victim]</td>\n",
       "      <td>Битва за воздух как проба стойкости русских\\n2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3503</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1139.txt</td>\n",
       "      <td>НАТО</td>\n",
       "      <td>993</td>\n",
       "      <td>996</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Foreign Adversary]</td>\n",
       "      <td>Битва за воздух как проба стойкости русских\\n2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3504</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1139.txt</td>\n",
       "      <td>Зеленского</td>\n",
       "      <td>2181</td>\n",
       "      <td>2190</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Foreign Adversary]</td>\n",
       "      <td>Битва за воздух как проба стойкости русских\\n2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3505</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1139.txt</td>\n",
       "      <td>Киеву</td>\n",
       "      <td>2414</td>\n",
       "      <td>2418</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Instigator]</td>\n",
       "      <td>Битва за воздух как проба стойкости русских\\n2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lang         art_name      entity start   end      class1  \\\n",
       "3501   RU  RU-URW-1139.txt      Запада   212   217  Antagonist   \n",
       "3502   RU  RU-URW-1139.txt      России   631   636    Innocent   \n",
       "3503   RU  RU-URW-1139.txt        НАТО   993   996  Antagonist   \n",
       "3504   RU  RU-URW-1139.txt  Зеленского  2181  2190  Antagonist   \n",
       "3505   RU  RU-URW-1139.txt       Киеву  2414  2418  Antagonist   \n",
       "\n",
       "                 classes2                                               text  \n",
       "3501        [Conspirator]  Битва за воздух как проба стойкости русских\\n2...  \n",
       "3502             [Victim]  Битва за воздух как проба стойкости русских\\n2...  \n",
       "3503  [Foreign Adversary]  Битва за воздух как проба стойкости русских\\n2...  \n",
       "3504  [Foreign Adversary]  Битва за воздух как проба стойкости русских\\n2...  \n",
       "3505         [Instigator]  Битва за воздух как проба стойкости русских\\n2...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df, df2], ignore_index=True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e86fc621-83e0-4a5e-83a0-2ed0d0b31dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelNum(row):\n",
    "    if row['class1'] == 'Antagonist':\n",
    "        return int(0)\n",
    "    if row['class1'] == 'Innocent':\n",
    "        return int(1)\n",
    "    if row['class1'] == 'Protagonist':\n",
    "        return int(2)\n",
    "\n",
    "def textCon(row):\n",
    "    text1 = \"Consider the role of \" + row['entity'] + \" in the text.\"\n",
    "    text = text1 + \" \" + row['text']\n",
    "    return text\n",
    "\n",
    "df['label1'] = df.apply(labelNum,axis=1)\n",
    "#print(df['label'].value_counts(),\n",
    "#df['class1'].value_counts())\n",
    "df['input'] = df.apply(textCon,axis=1)\n",
    "#print(df['input'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f104700-1cb2-488a-9ae7-21ea8bda4361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelNum2(row):\n",
    "    labels2 = [0 for _ in range(22)]\n",
    "    if row['label1'] == 2:\n",
    "        #labels2 = [0 for _ in range(6)]\n",
    "        if 'Guardian' in row['classes2']:\n",
    "            labels2[0] = 1\n",
    "        if 'Martyr' in row['classes2']:\n",
    "            labels2[1] = 1\n",
    "        if 'Peacemaker' in row['classes2']:\n",
    "            labels2[2] = 1\n",
    "        if 'Rebel' in row['classes2']:\n",
    "            labels2[3] = 1\n",
    "        if 'Underdog' in row['classes2']:\n",
    "            labels2[4] = 1\n",
    "        if 'Virtuous' in row['classes2']:\n",
    "            labels2[5] = 1\n",
    "    elif row['label1'] == 0:\n",
    "        #labels2 = [0 for _ in range(12)]\n",
    "        if 'Instigator' in row['classes2']:\n",
    "           labels2[6] = 1\n",
    "        if 'Conspirator' in row['classes2']:\n",
    "            labels2[7] = 1\n",
    "        if 'Tyrant' in row['classes2']:\n",
    "            labels2[8] = 1\n",
    "        if  'Foreign Adversary' in row['classes2']:\n",
    "            labels2[9] = 1\n",
    "        if 'Traitor' in row['classes2']:\n",
    "            labels2[10] = 1\n",
    "        if 'Spy' in row['classes2']:\n",
    "            labels2[11] = 1\n",
    "        if 'Saboteur' in row['classes2']:\n",
    "            labels2[12] = 1\n",
    "        if 'Corrupt' in row['classes2']:\n",
    "            labels2[13] = 1\n",
    "        if 'Incompetent' in row['classes2']:\n",
    "            labels2[14] = 1\n",
    "        if 'Terrorist' in row['classes2']:\n",
    "            labels2[15] = 1\n",
    "        if 'Deceiver' in row['classes2']:\n",
    "            labels2[16] = 1\n",
    "        if 'Bigot' in row['classes2']:\n",
    "            labels2[17] = 1\n",
    "    elif row['label1'] == 1:\n",
    "        #labels2 = [0 for _ in range(4)]\n",
    "        if 'Forgotten' in row['classes2']:\n",
    "            labels2[18] = 1\n",
    "        if 'Exploited' in row['classes2']:\n",
    "            labels2[19] = 1\n",
    "        if 'Victim' in row['classes2']:\n",
    "            labels2[20] = 1\n",
    "        if 'Scapegoat' in row['classes2']:\n",
    "            labels2[21] = 1\n",
    "    return labels2\n",
    "\n",
    "df['label2'] = df.apply(labelNum2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7df1b46-d7eb-4d62-85a2-2c28c7f4fcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.aggregate of                                                   input  \\\n",
       "0     Consider the role of Запад in the text. Опитът...   \n",
       "1     Consider the role of САЩ in the text. Опитът н...   \n",
       "2     Consider the role of НАТО in the text. Опитът ...   \n",
       "3     Consider the role of Украйна in the text. Опит...   \n",
       "4     Consider the role of украински войници in the ...   \n",
       "...                                                 ...   \n",
       "3501  Consider the role of Запада in the text. Битва...   \n",
       "3502  Consider the role of России in the text. Битва...   \n",
       "3503  Consider the role of НАТО in the text. Битва з...   \n",
       "3504  Consider the role of Зеленского in the text. Б...   \n",
       "3505  Consider the role of Киеву in the text. Битва ...   \n",
       "\n",
       "                                                 label2  label1  \n",
       "0     [0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, ...       0  \n",
       "1     [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...       0  \n",
       "2     [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...       0  \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...       0  \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       1  \n",
       "...                                                 ...     ...  \n",
       "3501  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...       0  \n",
       "3502  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       1  \n",
       "3503  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...       0  \n",
       "3504  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...       0  \n",
       "3505  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...       0  \n",
       "\n",
       "[3506 rows x 3 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.loc[ : , ['input','label2','label1']]\n",
    "data.aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "576757dc-4d90-41b7-848f-38741d103564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(721     Consider the role of ICJ in the text. Israel t...\n",
       " 761     Consider the role of Vladimir Putin in the tex...\n",
       " 631     Consider the role of Germany in the text. How ...\n",
       " 1565    Consider the role of भारत in the text. प्रधानम...\n",
       " 2750    Consider the role of ФСБ in the text. В пыль и...\n",
       " Name: input, dtype: object,\n",
       " 3272    Consider the role of पश्चिमी देशों in the text...\n",
       " 315     Consider the role of САЩ in the text. Призивит...\n",
       " 2179    Consider the role of Hungria in the text. Ucrâ...\n",
       " 3359    Consider the role of Caatinga in the text. Na ...\n",
       " 430     Consider the role of Европа in the text. Боян ...\n",
       " Name: input, dtype: object,\n",
       " 721     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...\n",
       " 761     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       " 631     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...\n",
       " 1565    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       " 2750    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       " Name: label2, dtype: object,\n",
       " 3272    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...\n",
       " 315     [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...\n",
       " 2179    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       " 3359    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       " 430     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       " Name: label2, dtype: object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "X = data['input']\n",
    "y = data[\"label2\"]\n",
    "par = data[\"label1\"]\n",
    "lang = df['lang'].tolist()\n",
    "lang = np.array(lang)\n",
    "X_train, X_test, y_train, y_test,lang_train,lang_test,par_train,par_test = train_test_split(\n",
    "    X, y,lang,par, test_size=0.2, random_state=42\n",
    ")\n",
    "X_train.head(), X_test.head(), y_train.head(), y_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e03cf61-a696-4620-9e26-d107bd9b03b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1d13a99-5f0d-4c0d-b733-acdbeb43f9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1b38560-7053-45e2-9d42-c323963611f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizer\n",
    "\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-base\", num_labels=22,problem_type=\"multi_label_classification\").to(device)\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19270409-f532-42e6-a101-f255b228e77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Convert pandas DataFrame/Series to Hugging Face Dataset\n",
    "train_data = pd.DataFrame({'text': X_train, 'label': y_train,'par':par_train})\n",
    "test_data = pd.DataFrame({'text': X_test, 'label': y_test,'par':par_test})\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "test_dataset = Dataset.from_pandas(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8ca0c4d-bf53-44ec-9059-ad0ee7293815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe6d78866cce483792491ff5516ffa14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2804 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7761fc65eec14b86912f17a8de9d01b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/702 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['text'], padding=True, truncation=True, max_length=128)\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "test_dataset = test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad36295b-2e87-4f51-972d-208050efda7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Consider the role of ICJ in the text. Israel to respond to genocide charges at UN’s top court06:35 \\n\\n Israel to respond to genocide charges at UN’s top court\\n\\nIsrael will respond to charges of genocide at the United Nations’ top court on Friday after South Africa filed an urgent request with the court to order a ceasefire in Gaza.\\n\\nIt is the third time the International Court of Justice (ICJ) has held hearings on the Israel-Hamas war since South Africa filed proceedings at The Hague court in December.\\n\\nOn Thursday, South Africa told the court the situation in Gaza has reached “a new and horrific stage”, and urged the 15 judges to take urgent action.\\n\\nIsrael must “totally and unconditionally withdraw” from the Gaza Strip, said Vusimuzi Madonsela, South Africa’s ambassador to the Netherlands.\\n\\nSouth Africa has submitted four requests for the ICJ to investigate Israel. According to the latest request, the country says Israel’s military incursion in Rafah threatens the “very survival of Palestinians in Gaza”.\\n\\nDuring hearings earlier this year, Israel strongly denied committing genocide in Gaza, saying it does all it can to spare civilians and is only targeting Hamas militants. Israel says Rafah is the last stronghold of the militant group.\\n\\nIn January, judges ordered Israel to do all it can to prevent death, destruction and any acts of genocide in Gaza, but the panel stopped short of ordering an end to the military offensive.\\n\\nThe court has already found that there is a “real and imminent risk” to the Palestinian people in Gaza by Israel’s military operations.\\n\\n“This may well be the last chance for the court to act,” said Irish lawyer Blinne Ni Ghralaigh, who is part of South Africa’s legal team.\\n\\nICJ judges have broad powers to order a ceasefire and other measures, though the court does not have its own enforcement apparatus.\\n\\nA 2022 order by the court demanding that Russia halt its full-scale invasion of Ukraine has so far gone unheeded.\\n\\nMost of Gaza’s population of 2.3 million people have been displaced since fighting began.\\n\\nThe war began with a Hamas attack on southern Israel on October 7 in which Palestinian militants killed around 1,200 people and took about 250 hostages.\\n\\nGaza’s Health Ministry says more than 35,000 Palestinians have been killed in the war without distinguishing between civilians and combatants in its count.\\n\\nSouth Africa initiated proceedings in December 2023 and sees the legal campaign as rooted in issues central to its identity. Its governing party, the African National Congress, has long compared Israel’s policies in Gaza and the occupied West Bank to its own history under the apartheid regime of white minority rule, which restricted most Blacks to “homelands”. Apartheid ended in 1994.\\n\\nOn Sunday, Egypt announced it plans to join the case. Several countries have also indicated they plan to intervene, but only Libya, Nicaragua and Colombia have filed formal requests to do so.\\n\\nJoin the Belfast Telegraph WhatsApp channel\\n\\nStay up to date with some of Northern Ireland's biggest stories\",\n",
       " 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " 'par': 0,\n",
       " '__index_level_0__': 721,\n",
       " 'input_ids': [0,\n",
       "  137399,\n",
       "  70,\n",
       "  31486,\n",
       "  111,\n",
       "  69010,\n",
       "  1375,\n",
       "  23,\n",
       "  70,\n",
       "  7986,\n",
       "  5,\n",
       "  8254,\n",
       "  47,\n",
       "  35644,\n",
       "  47,\n",
       "  159372,\n",
       "  13,\n",
       "  124666,\n",
       "  99,\n",
       "  8274,\n",
       "  26,\n",
       "  7,\n",
       "  2663,\n",
       "  29685,\n",
       "  9016,\n",
       "  27144,\n",
       "  8254,\n",
       "  47,\n",
       "  35644,\n",
       "  47,\n",
       "  159372,\n",
       "  13,\n",
       "  124666,\n",
       "  99,\n",
       "  8274,\n",
       "  26,\n",
       "  7,\n",
       "  2663,\n",
       "  29685,\n",
       "  8254,\n",
       "  1221,\n",
       "  35644,\n",
       "  47,\n",
       "  124666,\n",
       "  111,\n",
       "  159372,\n",
       "  13,\n",
       "  99,\n",
       "  70,\n",
       "  14098,\n",
       "  145704,\n",
       "  26,\n",
       "  2663,\n",
       "  29685,\n",
       "  98,\n",
       "  41626,\n",
       "  7103,\n",
       "  25134,\n",
       "  36941,\n",
       "  11435,\n",
       "  71,\n",
       "  142,\n",
       "  89014,\n",
       "  50336,\n",
       "  678,\n",
       "  70,\n",
       "  29685,\n",
       "  47,\n",
       "  12989,\n",
       "  10,\n",
       "  8360,\n",
       "  184,\n",
       "  73702,\n",
       "  23,\n",
       "  68666,\n",
       "  5,\n",
       "  1650,\n",
       "  83,\n",
       "  70,\n",
       "  50960,\n",
       "  1733,\n",
       "  70,\n",
       "  8357,\n",
       "  52341,\n",
       "  111,\n",
       "  117400,\n",
       "  15,\n",
       "  16259,\n",
       "  1375,\n",
       "  16,\n",
       "  1556,\n",
       "  34658,\n",
       "  129271,\n",
       "  7,\n",
       "  98,\n",
       "  70,\n",
       "  8254,\n",
       "  9,\n",
       "  6495,\n",
       "  1510,\n",
       "  1631,\n",
       "  16792,\n",
       "  25134,\n",
       "  36941,\n",
       "  11435,\n",
       "  71,\n",
       "  172337,\n",
       "  5180,\n",
       "  99,\n",
       "  581,\n",
       "  1391,\n",
       "  6261,\n",
       "  29685,\n",
       "  23,\n",
       "  14487,\n",
       "  5,\n",
       "  2161,\n",
       "  103616,\n",
       "  4,\n",
       "  25134,\n",
       "  36941,\n",
       "  30745,\n",
       "  70,\n",
       "  29685,\n",
       "  70,\n",
       "  16648,\n",
       "  23,\n",
       "  2],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df3f9328-4662-462b-b385-65cf4f9cadec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label', 'par', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 2804\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label','par'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label','par'])\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2b0314d-ee2a-4340-9918-b621ebd0072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32,shuffle=True)\n",
    "optimizer = AdamW(model.parameters(), lr=4e-5)\n",
    "final_preds = np.empty((0, 22), dtype=np.int8)\n",
    "final_labels = np.empty((0, 22), dtype=np.int8)\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcfc6363-7f64-4c59-b06e-7b0cf7a907ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 88/88 [00:36<00:00,  2.40it/s, loss=0.209]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Training loss: 0.2653, Training accuracy: 0.0364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 1/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:02<00:00,  8.48it/s, loss=0.176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent Test accuracy: 0.2379\n",
      "Test loss: 0.1811, Test accuracy: 0.1937\n",
      "Test Micro Precision: 0.2009, Recall: 0.1829, F1: 0.1914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 88/88 [00:36<00:00,  2.41it/s, loss=0.152]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "Training loss: 0.1779, Training accuracy: 0.0870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 2/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:02<00:00,  8.48it/s, loss=0.162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent Test accuracy: 0.2379\n",
      "Test loss: 0.1789, Test accuracy: 0.1937\n",
      "Test Micro Precision: 0.2009, Recall: 0.1829, F1: 0.1914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 88/88 [00:36<00:00,  2.39it/s, loss=0.164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "Training loss: 0.1763, Training accuracy: 0.0710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 3/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:02<00:00,  8.55it/s, loss=0.165]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent Test accuracy: 0.2379\n",
      "Test loss: 0.1781, Test accuracy: 0.0556\n",
      "Test Micro Precision: 0.2320, Recall: 0.0545, F1: 0.0882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 88/88 [00:36<00:00,  2.39it/s, loss=0.182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "Training loss: 0.1748, Training accuracy: 0.0867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 4/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:02<00:00,  8.63it/s, loss=0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent Test accuracy: 0.4558\n",
      "Test loss: 0.1761, Test accuracy: 0.0499\n",
      "Test Micro Precision: 0.2210, Recall: 0.1855, F1: 0.2017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/10: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 88/88 [00:37<00:00,  2.38it/s, loss=0.18]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "Training loss: 0.1726, Training accuracy: 0.0499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 5/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:02<00:00,  8.50it/s, loss=0.178]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent Test accuracy: 0.3974\n",
      "Test loss: 0.1730, Test accuracy: 0.0085\n",
      "Test Micro Precision: 0.2039, Recall: 0.1920, F1: 0.1977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 88/88 [00:37<00:00,  2.38it/s, loss=0.153]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "Training loss: 0.1702, Training accuracy: 0.0756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 6/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:02<00:00,  8.64it/s, loss=0.175]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent Test accuracy: 0.4929\n",
      "Test loss: 0.1725, Test accuracy: 0.0413\n",
      "Test Micro Precision: 0.2172, Recall: 0.2036, F1: 0.2102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 88/88 [00:37<00:00,  2.36it/s, loss=0.153]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "Training loss: 0.1643, Training accuracy: 0.0856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 7/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:02<00:00,  8.83it/s, loss=0.159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent Test accuracy: 0.5983\n",
      "Test loss: 0.1622, Test accuracy: 0.1425\n",
      "Test Micro Precision: 0.2751, Recall: 0.3904, F1: 0.3228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 88/88 [00:36<00:00,  2.39it/s, loss=0.148]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "Training loss: 0.1554, Training accuracy: 0.1494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 8/10: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:02<00:00,  8.68it/s, loss=0.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent Test accuracy: 0.5826\n",
      "Test loss: 0.1597, Test accuracy: 0.1838\n",
      "Test Micro Precision: 0.2821, Recall: 0.4073, F1: 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 88/88 [00:36<00:00,  2.41it/s, loss=0.128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "Training loss: 0.1468, Training accuracy: 0.2036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 9/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:02<00:00,  8.57it/s, loss=0.146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent Test accuracy: 0.6296\n",
      "Test loss: 0.1583, Test accuracy: 0.1538\n",
      "Test Micro Precision: 0.2716, Recall: 0.4449, F1: 0.3373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/10: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 88/88 [00:36<00:00,  2.38it/s, loss=0.156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "Training loss: 0.1372, Training accuracy: 0.2261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 10/10: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [00:02<00:00,  8.63it/s, loss=0.144]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent Test accuracy: 0.6652\n",
      "Test loss: 0.1526, Test accuracy: 0.2137\n",
      "Test Micro Precision: 0.3174, Recall: 0.4565, F1: 0.3745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    # Initialize tqdm progress bar for training\n",
    "    train_progress_bar = tqdm(train_dataloader, desc=f\"Training Epoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    for batch in train_progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels.float())\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        preds = (torch.sigmoid(logits) > 0.15).int()\n",
    "        #print(preds)\n",
    "        correct_predictions += ((preds == labels.int()).all(dim=1)).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "        \n",
    "        # Update tqdm description with current loss\n",
    "        train_progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    print(f\"Training loss: {avg_train_loss:.4f}, Training accuracy: {train_accuracy:.4f}\")\n",
    "    \n",
    "    # Test phase\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct_test_predictions = 0\n",
    "    total_test_predictions = 0\n",
    "    total_parents = 0\n",
    "    correct_parents = 0\n",
    "    test_preds = np.empty((0, 22), dtype=np.int8)\n",
    "    test_labels = np.empty((0, 22), dtype=np.int8)\n",
    "    # Initialize tqdm progress bar for test\n",
    "    test_progress_bar = tqdm(test_dataloader, desc=f\"Test Epoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_progress_bar:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            parents = batch['par'].to(device)\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels.float())\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Calculate test accuracy\n",
    "            preds = (torch.sigmoid(logits) > 0.15).int()\n",
    "            correct_test_predictions += ((preds == labels.int()).all(dim=1)).sum().item()\n",
    "            total_test_predictions += labels.size(0)\n",
    "            argmax_indices = torch.argmax(logits, dim=-1)\n",
    "            parent_preds = torch.where(\n",
    "                argmax_indices <= 5, \n",
    "                torch.tensor(2),  # Set to 2 for indices 0-5\n",
    "                torch.where(\n",
    "                argmax_indices <= 17, \n",
    "                torch.tensor(0),  # Set to 0 for indices 6-17\n",
    "                torch.tensor(1)   # Set to 1 for indices 18-21\n",
    "                )\n",
    "            )\n",
    "            correct_parents += (parent_preds == parents).sum().item()\n",
    "            total_parents += labels.size(0)\n",
    "            \n",
    "            if epoch == num_epochs-1:\n",
    "                final_preds = np.vstack([final_preds,preds.cpu().numpy()])\n",
    "                final_labels = np.vstack([final_labels,labels.cpu().numpy()])\n",
    "\n",
    "            test_preds = np.vstack([test_preds,preds.cpu().numpy()])\n",
    "            test_labels = np.vstack([test_labels,labels.cpu().numpy()])\n",
    "            \n",
    "            # Update tqdm description with current loss\n",
    "            test_progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    avg_test_loss = test_loss / len(test_dataloader)\n",
    "    test_accuracy = correct_test_predictions / total_test_predictions\n",
    "    parent_test_accuracy = correct_parents / total_parents\n",
    "    print(f\"Parent Test accuracy: {parent_test_accuracy:.4f}\")\n",
    "    print(f\"Test loss: {avg_test_loss:.4f}, Test accuracy: {test_accuracy:.4f}\")\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(test_labels, test_preds, average='micro')\n",
    "    print(f\"Test Micro Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fce440a-d356-4853-91a1-bdfb7f407450",
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_mask = lang_test == 'BG'\n",
    "hi_mask = lang_test == 'HI'\n",
    "en_mask = lang_test == 'EN'\n",
    "pt_mask = lang_test == 'PT'\n",
    "ru_mask = lang_test == 'RU'\n",
    "#print(bg_mask,hi_mask,en_mask,pt_mask,ru_mask)\n",
    "bg_pred = final_preds[bg_mask]\n",
    "bg_labels = final_labels[bg_mask]\n",
    "hi_pred = final_preds[hi_mask]\n",
    "hi_labels = final_labels[hi_mask]\n",
    "en_pred = final_preds[en_mask]\n",
    "en_labels = final_labels[en_mask]\n",
    "pt_pred = final_preds[pt_mask]\n",
    "pt_labels = final_labels[pt_mask]\n",
    "ru_pred = final_preds[ru_mask]\n",
    "ru_labels = final_labels[ru_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85df72de-dd2a-4f06-ba19-1bc697286045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN Micro Precision: 0.3648,Micro Recall: 0.5321,Micro F1: 0.4328\n",
      "EN accuracy: 0.2421\n",
      "BG Micro Precision: 0.2926,Micro Recall: 0.4231,Micro F1: 0.3459\n",
      "BG accuracy: 0.1983\n",
      "HI Micro Precision: 0.2850,Micro Recall: 0.4303,Micro F1: 0.3429\n",
      "HI accuracy: 0.1747\n",
      "PT Micro Precision: 0.3373,Micro Recall: 0.4526,Micro F1: 0.3865\n",
      "PT accuracy: 0.2428\n",
      "RU Micro Precision: 0.3516,Micro Recall: 0.4945,Micro F1: 0.4110\n",
      "RU accuracy: 0.2500\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1, _ = precision_recall_fscore_support(en_labels, en_pred, average='micro')\n",
    "print(f\"EN Micro Precision: {precision:.4f},Micro Recall: {recall:.4f},Micro F1: {f1:.4f}\")\n",
    "en_correct = np.sum(np.all(en_labels == en_pred,axis=1))\n",
    "en_total = en_labels.shape[0]\n",
    "total_acc = en_correct/en_total\n",
    "print(f\"EN accuracy: {total_acc:.4f}\")\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(bg_labels, bg_pred, average='micro')\n",
    "print(f\"BG Micro Precision: {precision:.4f},Micro Recall: {recall:.4f},Micro F1: {f1:.4f}\")\n",
    "bg_correct = np.sum(np.all(bg_labels == bg_pred,axis=1))\n",
    "bg_total = bg_labels.shape[0]\n",
    "total_acc = bg_correct/bg_total\n",
    "print(f\"BG accuracy: {total_acc:.4f}\")\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(hi_labels, hi_pred, average='micro')\n",
    "print(f\"HI Micro Precision: {precision:.4f},Micro Recall: {recall:.4f},Micro F1: {f1:.4f}\")\n",
    "hi_correct = np.sum(np.all(hi_labels == hi_pred,axis=1))\n",
    "hi_total = hi_labels.shape[0]\n",
    "total_acc = hi_correct/hi_total\n",
    "print(f\"HI accuracy: {total_acc:.4f}\")\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(pt_labels, pt_pred, average='micro')\n",
    "print(f\"PT Micro Precision: {precision:.4f},Micro Recall: {recall:.4f},Micro F1: {f1:.4f}\")\n",
    "pt_correct = np.sum(np.all(pt_labels == pt_pred,axis=1))\n",
    "pt_total = pt_labels.shape[0]\n",
    "total_acc = pt_correct/pt_total\n",
    "print(f\"PT accuracy: {total_acc:.4f}\")\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(ru_labels, ru_pred, average='micro')\n",
    "print(f\"RU Micro Precision: {precision:.4f},Micro Recall: {recall:.4f},Micro F1: {f1:.4f}\")\n",
    "ru_correct = np.sum(np.all(ru_labels == ru_pred,axis=1))\n",
    "ru_total = ru_labels.shape[0]\n",
    "total_acc = ru_correct/ru_total\n",
    "print(f\"RU accuracy: {total_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40197486-436b-4f14-a6a4-e4026b27c7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 1, 0, 2, 1, 0, 2, 0, 2, 2, 0, 2, 1, 0, 2, 0, 2, 0, 0, 0, 2, 1,\n",
      "        0, 0, 0, 0, 2, 0], device='cuda:0')\n",
      "tensor([1, 1, 2, 1, 1, 0, 2, 0, 0, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 0, 0, 2, 2, 1,\n",
      "        0, 0, 0, 0, 2, 0], device='cuda:0')\n",
      "0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(parents)\n",
    "print(parent_preds)\n",
    "correct_parents = (parent_preds == parents).sum().item()\n",
    "print(correct_parents/len(parents))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
