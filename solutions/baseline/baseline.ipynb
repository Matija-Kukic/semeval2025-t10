{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1dcb9da-abd9-4b4b-aaf1-1f3864ac9775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/matijak/Documents/programiranje/projects/semeval/merged_data/subtask1.parquet\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "wd = Path.cwd()\n",
    "wd = wd.parent.parent\n",
    "wd = wd / 'merged_data' \n",
    "sub1 = str(wd) + '/subtask1.parquet'\n",
    "print(sub1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5fd66dd-f991-454f-8684-4bd0a6cc41b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.aggregate of      lang         art_name             entity start   end       class1  \\\n",
       "0      BG       BG_670.txt              Запад   152   156   Antagonist   \n",
       "1      BG       BG_670.txt                САЩ   530   532   Antagonist   \n",
       "2      BG       BG_670.txt               НАТО   535   538   Antagonist   \n",
       "3      BG       BG_670.txt            Украйна   578   584   Antagonist   \n",
       "4      BG       BG_670.txt  украински войници   633   649     Innocent   \n",
       "...   ...              ...                ...   ...   ...          ...   \n",
       "2897   RU  RU-URW-1156.txt            Россией   559   565  Protagonist   \n",
       "2898   RU  RU-URW-1156.txt             Москва  1005  1010  Protagonist   \n",
       "2899   RU  RU-URW-1156.txt               НАТО  1298  1301   Antagonist   \n",
       "2900   RU  RU-URW-1156.txt             Киевом  1948  1953   Antagonist   \n",
       "2901   RU  RU-URW-1113.txt    Дмитрия Гордона   133   147   Antagonist   \n",
       "\n",
       "                                          classes2  \\\n",
       "0     [Conspirator, Instigator, Foreign Adversary]   \n",
       "1                                     [Instigator]   \n",
       "2                                     [Instigator]   \n",
       "3                              [Foreign Adversary]   \n",
       "4                                         [Victim]   \n",
       "...                                            ...   \n",
       "2897                                  [Peacemaker]   \n",
       "2898                                    [Guardian]   \n",
       "2899                           [Foreign Adversary]   \n",
       "2900                                   [Terrorist]   \n",
       "2901                                  [Instigator]   \n",
       "\n",
       "                                                   text  \n",
       "0     Опитът на колективния Запад да „обезкърви Руси...  \n",
       "1     Опитът на колективния Запад да „обезкърви Руси...  \n",
       "2     Опитът на колективния Запад да „обезкърви Руси...  \n",
       "3     Опитът на колективния Запад да „обезкърви Руси...  \n",
       "4     Опитът на колективния Запад да „обезкърви Руси...  \n",
       "...                                                 ...  \n",
       "2897  Медведев: Даже в случае признания поражения Ки...  \n",
       "2898  Медведев: Даже в случае признания поражения Ки...  \n",
       "2899  Медведев: Даже в случае признания поражения Ки...  \n",
       "2900  Медведев: Даже в случае признания поражения Ки...  \n",
       "2901  Эпизоды с призывами «убить Путина» нашли в дел...  \n",
       "\n",
       "[2902 rows x 8 columns]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(sub1)\n",
    "#df.head(n=20)\n",
    "df.aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e86fc621-83e0-4a5e-83a0-2ed0d0b31dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelNum(row):\n",
    "    if row['class1'] == 'Antagonist':\n",
    "        return int(0)\n",
    "    if row['class1'] == 'Innocent':\n",
    "        return int(1)\n",
    "    if row['class1'] == 'Protagonist':\n",
    "        return int(2)\n",
    "\n",
    "def textCon(row):\n",
    "    text1 = \"Consider the role of \" + row['entity'] + \" in the text.\"\n",
    "    text = text1 + \" \" + row['text']\n",
    "    return text\n",
    "\n",
    "df['label1'] = df.apply(labelNum,axis=1)\n",
    "#print(df['label'].value_counts(),\n",
    "#df['class1'].value_counts())\n",
    "df['input'] = df.apply(textCon,axis=1)\n",
    "#print(df['input'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f104700-1cb2-488a-9ae7-21ea8bda4361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelNum2(row):\n",
    "    labels2 = [0 for _ in range(22)]\n",
    "    if row['label1'] == 2:\n",
    "        #labels2 = [0 for _ in range(6)]\n",
    "        if 'Guardian' in row['classes2']:\n",
    "            labels2[0] = 1\n",
    "        if 'Martyr' in row['classes2']:\n",
    "            labels2[1] = 1\n",
    "        if 'Peacemaker' in row['classes2']:\n",
    "            labels2[2] = 1\n",
    "        if 'Rebel' in row['classes2']:\n",
    "            labels2[3] = 1\n",
    "        if 'Underdog' in row['classes2']:\n",
    "            labels2[4] = 1\n",
    "        if 'Virtuous' in row['classes2']:\n",
    "            labels2[5] = 1\n",
    "    elif row['label1'] == 0:\n",
    "        #labels2 = [0 for _ in range(12)]\n",
    "        if 'Instigator' in row['classes2']:\n",
    "           labels2[6] = 1\n",
    "        if 'Conspirator' in row['classes2']:\n",
    "            labels2[7] = 1\n",
    "        if 'Tyrant' in row['classes2']:\n",
    "            labels2[8] = 1\n",
    "        if  'Foreign Adversary' in row['classes2']:\n",
    "            labels2[9] = 1\n",
    "        if 'Traitor' in row['classes2']:\n",
    "            labels2[10] = 1\n",
    "        if 'Spy' in row['classes2']:\n",
    "            labels2[11] = 1\n",
    "        if 'Saboteur' in row['classes2']:\n",
    "            labels2[12] = 1\n",
    "        if 'Corrupt' in row['classes2']:\n",
    "            labels2[13] = 1\n",
    "        if 'Incompetent' in row['classes2']:\n",
    "            labels2[14] = 1\n",
    "        if 'Terrorist' in row['classes2']:\n",
    "            labels2[15] = 1\n",
    "        if 'Deceiver' in row['classes2']:\n",
    "            labels2[16] = 1\n",
    "        if 'Bigot' in row['classes2']:\n",
    "            labels2[17] = 1\n",
    "    elif row['label1'] == 1:\n",
    "        #labels2 = [0 for _ in range(4)]\n",
    "        if 'Forgotten' in row['classes2']:\n",
    "            labels2[18] = 1\n",
    "        if 'Exploited' in row['classes2']:\n",
    "            labels2[19] = 1\n",
    "        if 'Victim' in row['classes2']:\n",
    "            labels2[20] = 1\n",
    "        if 'Scapegoat' in row['classes2']:\n",
    "            labels2[21] = 1\n",
    "    return labels2\n",
    "\n",
    "df['label2'] = df.apply(labelNum2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7df1b46-d7eb-4d62-85a2-2c28c7f4fcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.aggregate of                                                   input  \\\n",
       "0     Consider the role of Запад in the text. Опитът...   \n",
       "1     Consider the role of САЩ in the text. Опитът н...   \n",
       "2     Consider the role of НАТО in the text. Опитът ...   \n",
       "3     Consider the role of Украйна in the text. Опит...   \n",
       "4     Consider the role of украински войници in the ...   \n",
       "...                                                 ...   \n",
       "2897  Consider the role of Россией in the text. Медв...   \n",
       "2898  Consider the role of Москва in the text. Медве...   \n",
       "2899  Consider the role of НАТО in the text. Медведе...   \n",
       "2900  Consider the role of Киевом in the text. Медве...   \n",
       "2901  Consider the role of Дмитрия Гордона in the te...   \n",
       "\n",
       "                                                 label2  \n",
       "0     [0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "1     [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2     [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                 ...  \n",
       "2897  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2898  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2899  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "2900  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2901  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[2902 rows x 2 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.loc[ : , ['input','label2']]\n",
    "data.aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "576757dc-4d90-41b7-848f-38741d103564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1913    Consider the role of Hungria in the text. Hung...\n",
       " 163     Consider the role of КНДР in the text. Военния...\n",
       " 2054    Consider the role of Forças Armadas da Ucrânia...\n",
       " 252     Consider the role of Дагестан in the text. В Д...\n",
       " 1873    Consider the role of República Popular de Done...\n",
       " Name: input, dtype: object,\n",
       " 141     Consider the role of Зеленски in the text. Лоу...\n",
       " 819     Consider the role of NATO in the text. How the...\n",
       " 486     Consider the role of London in the text. “A De...\n",
       " 1717    Consider the role of जर्मनी in the text. Russi...\n",
       " 1200    Consider the role of अरब in the text. संयुक्त ...\n",
       " Name: input, dtype: object,\n",
       " 1913    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       " 163     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       " 2054    [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...\n",
       " 252     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       " 1873    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       " Name: label2, dtype: object,\n",
       " 141     [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...\n",
       " 819     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...\n",
       " 486     [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...\n",
       " 1717    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       " 1200    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       " Name: label2, dtype: object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data[\"input\"]\n",
    "y = data[\"label2\"]\n",
    "lang = df['lang'].tolist()\n",
    "lang = np.array(lang)\n",
    "X_train, X_test, y_train, y_test,lang_train,lang_test = train_test_split(\n",
    "    X, y,lang, test_size=0.2, random_state=42\n",
    ")\n",
    "X_train.head(), X_test.head(), y_train.head(), y_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e03cf61-a696-4620-9e26-d107bd9b03b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1d13a99-5f0d-4c0d-b733-acdbeb43f9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1b38560-7053-45e2-9d42-c323963611f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizer\n",
    "\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-base\", num_labels=22,problem_type=\"multi_label_classification\").to(device)\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19270409-f532-42e6-a101-f255b228e77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Convert pandas DataFrame/Series to Hugging Face Dataset\n",
    "train_data = pd.DataFrame({'text': X_train, 'label': y_train})\n",
    "test_data = pd.DataFrame({'text': X_test, 'label': y_test})\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "test_dataset = Dataset.from_pandas(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8ca0c4d-bf53-44ec-9059-ad0ee7293815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7867c716114943b89a69618c27cc7d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c542f51fb31f45e5bd051780536f69e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/581 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['text'], padding=True, truncation=True, max_length=128)\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "test_dataset = test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad36295b-2e87-4f51-972d-208050efda7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Consider the role of Hungria in the text. Hungria mantém veto de fundos da UE a Kyiv (se bloqueio continuar)\\n\\nA decisão foi anunciada pelo ministro dos Negócios Estrangeiros húngaro, Péter Szijjártó, em entrevista à televisão privada ATV, numa alusão ao fundo europeu que Budapeste bloqueia desde maio.\\n\\n\"Enquanto a Ucrânia não resolver esta questão, que todos se esqueçam do pagamento dos 6,6 mil milhões de euros\", afirmou.\\n\\nA Hungria e a Eslováquia solicitaram na segunda-feira à Comissão Europeia a mediação com a Ucrânia, após Kiev ter incluído a petrolífera Lukoil na sua lista de sanções, implicando o fim do trânsito de petróleo para os dois países através do oleoduto Druzhba (Amizade).\\n\\nO ministro sublinhou que a Hungria não apoiará o financiamento da União Europeia (UE) para o envio de armamento à Ucrânia enquanto permanecer em risco a segurança energética do país centro-europeu, que atualmente assume a presidência semestral rotativa do Conselho da UE.\\n\\n\"A decisão da Ucrânia de não permitir à Lukoil o trânsito de petróleo através da Ucrânia implica uma ameaça fundamental para a segurança dos fornecimentos energéticos à Hungria e à Eslováquia\", afirmou, na segunda-feira, o porta-voz do Governo húngaro, Zoltan Kovacs, na rede social X.\\n\\nA Hungria e a Eslováquia dependem essencialmente das importações de petróleo russo, e apesar das sanções à Lukoil terem afetado o intercâmbio, os dois países continuam a receber fornecimentos de outras empresas russas.\\n\\nO primeiro-ministro húngaro, Viktor Orbán, e o seu homólogo eslovaco, Robert Fico, ambos definidos de \"pró-russos\", têm-se oposto ao apoio militar à Ucrânia na sequência da invasão russa e defendem uma solução negociada para terminar com o conflito.\\n\\nA ofensiva militar russa no território ucraniano, lançada a 24 de fevereiro de 2022, mergulhou a Europa naquela que é considerada a crise de segurança mais grave desde a Segunda Guerra Mundial (1939-1945).\\n\\nA Ucrânia tem contado com ajuda financeira e em armamento dos aliados ocidentais, que também têm decretado sanções contra setores-chave da economia russa para tentar diminuir a capacidade de Moscovo de financiar o esforço de guerra.\\n\\nOs últimos meses foram marcados por ataques aéreos em grande escala da Rússia contra cidades e infraestruturas ucranianas, ao passo que as forças de Kiev têm visado alvos em território russo próximos da fronteira e na península da Crimeia, ilegalmente anexada em 2014.\\n\\nJá no terceiro ano de guerra, as Forças Armadas ucranianas têm-se confrontado com falta de soldados e de armamento e munições, apesar das reiteradas promessas de ajuda dos aliados ocidentais, que começaram entretanto a concretizar-se.',\n",
       " 'label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " '__index_level_0__': 1913,\n",
       " 'input_ids': [0,\n",
       "  137399,\n",
       "  70,\n",
       "  31486,\n",
       "  111,\n",
       "  145422,\n",
       "  1651,\n",
       "  23,\n",
       "  70,\n",
       "  7986,\n",
       "  5,\n",
       "  145422,\n",
       "  1651,\n",
       "  203668,\n",
       "  118624,\n",
       "  8,\n",
       "  77665,\n",
       "  7,\n",
       "  48,\n",
       "  23068,\n",
       "  10,\n",
       "  8667,\n",
       "  4371,\n",
       "  15,\n",
       "  184,\n",
       "  54856,\n",
       "  846,\n",
       "  32429,\n",
       "  16,\n",
       "  62,\n",
       "  77283,\n",
       "  1715,\n",
       "  69626,\n",
       "  85,\n",
       "  3487,\n",
       "  28789,\n",
       "  655,\n",
       "  799,\n",
       "  9991,\n",
       "  44737,\n",
       "  111576,\n",
       "  449,\n",
       "  18313,\n",
       "  18827,\n",
       "  1970,\n",
       "  31,\n",
       "  4,\n",
       "  72248,\n",
       "  159,\n",
       "  53458,\n",
       "  48998,\n",
       "  5627,\n",
       "  4,\n",
       "  352,\n",
       "  31334,\n",
       "  253,\n",
       "  226410,\n",
       "  53647,\n",
       "  144342,\n",
       "  4,\n",
       "  31099,\n",
       "  56519,\n",
       "  3680,\n",
       "  940,\n",
       "  77665,\n",
       "  128655,\n",
       "  41,\n",
       "  15828,\n",
       "  13,\n",
       "  54856,\n",
       "  399,\n",
       "  3287,\n",
       "  32737,\n",
       "  5,\n",
       "  44,\n",
       "  7768,\n",
       "  44764,\n",
       "  31,\n",
       "  10,\n",
       "  345,\n",
       "  238,\n",
       "  68165,\n",
       "  1174,\n",
       "  1027,\n",
       "  58061,\n",
       "  1642,\n",
       "  76305,\n",
       "  4,\n",
       "  41,\n",
       "  2194,\n",
       "  40,\n",
       "  66660,\n",
       "  2968,\n",
       "  39,\n",
       "  54,\n",
       "  29903,\n",
       "  655,\n",
       "  6,\n",
       "  140447,\n",
       "  2717,\n",
       "  46014,\n",
       "  8,\n",
       "  10012,\n",
       "  830,\n",
       "  87538,\n",
       "  5,\n",
       "  62,\n",
       "  145422,\n",
       "  1651,\n",
       "  28,\n",
       "  10,\n",
       "  1184,\n",
       "  62092,\n",
       "  46449,\n",
       "  61520,\n",
       "  302,\n",
       "  24,\n",
       "  14141,\n",
       "  9,\n",
       "  12228,\n",
       "  253,\n",
       "  148331,\n",
       "  109792,\n",
       "  11,\n",
       "  10,\n",
       "  2450,\n",
       "  1156,\n",
       "  2],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df3f9328-4662-462b-b385-65cf4f9cadec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 2321\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2b0314d-ee2a-4340-9918-b621ebd0072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64,shuffle=True)\n",
    "optimizer = AdamW(model.parameters(), lr=4e-5)\n",
    "final_preds = np.empty((0, 22), dtype=np.int8)\n",
    "final_labels = np.empty((0, 22), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcfc6363-7f64-4c59-b06e-7b0cf7a907ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:29<00:00,  1.26it/s, loss=0.231]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Training loss: 0.3731, Training accuracy: 0.0177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 1/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.40it/s, loss=0.199]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2101, Test accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:29<00:00,  1.26it/s, loss=0.207]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "Training loss: 0.1962, Training accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 2/10: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.39it/s, loss=0.17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.1805, Test accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:29<00:00,  1.26it/s, loss=0.179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "Training loss: 0.1809, Training accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 3/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.44it/s, loss=0.197]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.1795, Test accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:29<00:00,  1.25it/s, loss=0.179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "Training loss: 0.1777, Training accuracy: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 4/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.43it/s, loss=0.145]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.1734, Test accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:29<00:00,  1.27it/s, loss=0.187]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "Training loss: 0.1770, Training accuracy: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 5/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.45it/s, loss=0.196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.1778, Test accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:29<00:00,  1.27it/s, loss=0.205]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "Training loss: 0.1772, Training accuracy: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 6/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.44it/s, loss=0.168]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.1751, Test accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:29<00:00,  1.25it/s, loss=0.198]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "Training loss: 0.1766, Training accuracy: 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 7/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.40it/s, loss=0.197]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.1774, Test accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:29<00:00,  1.27it/s, loss=0.162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "Training loss: 0.1759, Training accuracy: 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 8/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.44it/s, loss=0.185]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.1759, Test accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:28<00:00,  1.28it/s, loss=0.146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "Training loss: 0.1745, Training accuracy: 0.0108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 9/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.49it/s, loss=0.185]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.1757, Test accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:28<00:00,  1.28it/s, loss=0.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "Training loss: 0.1739, Training accuracy: 0.0646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 10/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.42it/s, loss=0.18]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.1733, Test accuracy: 0.0792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    # Initialize tqdm progress bar for training\n",
    "    train_progress_bar = tqdm(train_dataloader, desc=f\"Training Epoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    for batch in train_progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels.float())\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        preds = (torch.sigmoid(logits) > 0.15).int()\n",
    "        #print(preds)\n",
    "        correct_predictions += ((preds == labels.int()).all(dim=1)).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "        \n",
    "        # Update tqdm description with current loss\n",
    "        train_progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    print(f\"Training loss: {avg_train_loss:.4f}, Training accuracy: {train_accuracy:.4f}\")\n",
    "    \n",
    "    # Test phase\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct_test_predictions = 0\n",
    "    total_test_predictions = 0\n",
    "    \n",
    "    # Initialize tqdm progress bar for test\n",
    "    test_progress_bar = tqdm(test_dataloader, desc=f\"Test Epoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_progress_bar:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels.float())\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Calculate test accuracy\n",
    "            preds = (torch.sigmoid(logits) > 0.15).int()\n",
    "            correct_test_predictions += ((preds == labels.int()).all(dim=1)).sum().item()\n",
    "            total_test_predictions += labels.size(0)\n",
    "\n",
    "            if epoch == num_epochs-1:\n",
    "                final_preds = np.vstack([final_preds,preds.cpu().numpy()])\n",
    "                final_labels = np.vstack([final_labels,labels.cpu().numpy()])\n",
    "            \n",
    "            # Update tqdm description with current loss\n",
    "            test_progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    avg_test_loss = test_loss / len(test_dataloader)\n",
    "    test_accuracy = correct_test_predictions / total_test_predictions\n",
    "    \n",
    "    print(f\"Test loss: {avg_test_loss:.4f}, Test accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fce440a-d356-4853-91a1-bdfb7f407450",
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_mask = lang_test == 'BG'\n",
    "hi_mask = lang_test == 'HI'\n",
    "en_mask = lang_test == 'EN'\n",
    "pt_mask = lang_test == 'PT'\n",
    "ru_mask = lang_test == 'RU'\n",
    "#print(bg_mask,hi_mask,en_mask,pt_mask,ru_mask)\n",
    "bg_pred = final_preds[bg_mask]\n",
    "bg_labels = final_labels[bg_mask]\n",
    "hi_pred = final_preds[hi_mask]\n",
    "hi_labels = final_labels[hi_mask]\n",
    "en_pred = final_preds[en_mask]\n",
    "en_labels = final_labels[en_mask]\n",
    "pt_pred = final_preds[pt_mask]\n",
    "pt_labels = final_labels[pt_mask]\n",
    "ru_pred = final_preds[ru_mask]\n",
    "ru_labels = final_labels[ru_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85df72de-dd2a-4f06-ba19-1bc697286045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN Micro Precision: 0.1316,Micro Recall: 0.0515,Micro F1: 0.0741\n",
      "EN accuracy: 0.0549\n",
      "BG Micro Precision: 0.1389,Micro Recall: 0.0476,Micro F1: 0.0709\n",
      "BG accuracy: 0.0521\n",
      "HI Micro Precision: 0.2500,Micro Recall: 0.0697,Micro F1: 0.1089\n",
      "HI accuracy: 0.0773\n",
      "PT Micro Precision: 0.3409,Micro Recall: 0.1064,Micro F1: 0.1622\n",
      "PT accuracy: 0.1128\n",
      "RU Micro Precision: 0.2692,Micro Recall: 0.0824,Micro F1: 0.1261\n",
      "RU accuracy: 0.0875\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1, _ = precision_recall_fscore_support(en_labels, en_pred, average='micro')\n",
    "print(f\"EN Micro Precision: {precision:.4f},Micro Recall: {recall:.4f},Micro F1: {f1:.4f}\")\n",
    "en_correct = np.sum(np.all(en_labels == en_pred,axis=1))\n",
    "en_total = en_labels.shape[0]\n",
    "total_acc = en_correct/en_total\n",
    "print(f\"EN accuracy: {total_acc:.4f}\")\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(bg_labels, bg_pred, average='micro')\n",
    "print(f\"BG Micro Precision: {precision:.4f},Micro Recall: {recall:.4f},Micro F1: {f1:.4f}\")\n",
    "bg_correct = np.sum(np.all(bg_labels == bg_pred,axis=1))\n",
    "bg_total = bg_labels.shape[0]\n",
    "total_acc = bg_correct/bg_total\n",
    "print(f\"BG accuracy: {total_acc:.4f}\")\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(hi_labels, hi_pred, average='micro')\n",
    "print(f\"HI Micro Precision: {precision:.4f},Micro Recall: {recall:.4f},Micro F1: {f1:.4f}\")\n",
    "hi_correct = np.sum(np.all(hi_labels == hi_pred,axis=1))\n",
    "hi_total = hi_labels.shape[0]\n",
    "total_acc = hi_correct/hi_total\n",
    "print(f\"HI accuracy: {total_acc:.4f}\")\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(pt_labels, pt_pred, average='micro')\n",
    "print(f\"PT Micro Precision: {precision:.4f},Micro Recall: {recall:.4f},Micro F1: {f1:.4f}\")\n",
    "pt_correct = np.sum(np.all(pt_labels == pt_pred,axis=1))\n",
    "pt_total = pt_labels.shape[0]\n",
    "total_acc = pt_correct/pt_total\n",
    "print(f\"PT accuracy: {total_acc:.4f}\")\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(ru_labels, ru_pred, average='micro')\n",
    "print(f\"RU Micro Precision: {precision:.4f},Micro Recall: {recall:.4f},Micro F1: {f1:.4f}\")\n",
    "ru_correct = np.sum(np.all(ru_labels == ru_pred,axis=1))\n",
    "ru_total = ru_labels.shape[0]\n",
    "total_acc = ru_correct/ru_total\n",
    "print(f\"RU accuracy: {total_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
