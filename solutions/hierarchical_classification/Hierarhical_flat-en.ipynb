{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfQVFtXBiMWy"
   },
   "source": [
    "### Flat model with hierarchical constrains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jYvFwavZiMW0",
    "outputId": "cc0e5456-9b60-4b97-e0a8-613f98e5cfe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/matijak/Documents/programiranje/projects/semeval/merged_data/subtask1.parquet\n",
      "/home/matijak/Documents/programiranje/projects/semeval/merged_data/subtask1_test.parquet\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# sub1 = 'drive/My Drive/Colab Notebooks/semeval_data/subtask1.parquet'\n",
    "# print(sub1)\n",
    "\n",
    "from pathlib import Path\n",
    "wd = Path.cwd()\n",
    "wd = wd.parent.parent\n",
    "wd = wd / 'merged_data'\n",
    "sub1 = str(wd) + '/subtask1.parquet'\n",
    "sub2 = str(wd) + '/subtask1_test.parquet'\n",
    "print(sub1)\n",
    "print(sub2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BMEITI9CiMW2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index lang          art_name        entity start   end       class1  \\\n",
      "0    448   EN  EN_UA_103861.txt       Chinese   791   797   Antagonist   \n",
      "1    449   EN  EN_UA_103861.txt         China  1516  1520   Antagonist   \n",
      "2    450   EN  EN_UA_103861.txt         Hamas  2121  2125   Antagonist   \n",
      "3    451   EN  EN_UA_103861.txt  Donald Trump  4909  4920  Protagonist   \n",
      "4    452   EN  EN_UA_021270.txt        Yermak   667   672   Antagonist   \n",
      "\n",
      "                 classes2                                               text  \n",
      "0                   [Spy]  The World Needs Peacemaker Trump Again \\n\\n by...  \n",
      "1            [Instigator]  The World Needs Peacemaker Trump Again \\n\\n by...  \n",
      "2             [Terrorist]  The World Needs Peacemaker Trump Again \\n\\n by...  \n",
      "3  [Peacemaker, Guardian]  The World Needs Peacemaker Trump Again \\n\\n by...  \n",
      "4           [Incompetent]  Ukraine's Fate Will Be Decided In Coming Year,...  \n",
      "     index lang          art_name               entity start   end  \\\n",
      "409    857   EN  EN_UA_027787.txt    the United States   105   121   \n",
      "410    858   EN  EN_UA_027787.txt              Kremlin  1864  1870   \n",
      "411    859   EN  EN_UA_027787.txt      Dmitry Medvedev  1970  1984   \n",
      "412    860   EN  EN_UA_027787.txt  U.S. administration  2269  2287   \n",
      "413    861   EN  EN_UA_027787.txt    Ukrainian leaders  2290  2306   \n",
      "\n",
      "          class1      classes2  \\\n",
      "409   Antagonist  [Instigator]   \n",
      "410  Protagonist    [Guardian]   \n",
      "411  Protagonist    [Guardian]   \n",
      "412   Antagonist   [Terrorist]   \n",
      "413   Antagonist   [Terrorist]   \n",
      "\n",
      "                                                  text  \n",
      "409  Russia Says US Is Responsible for Deadly Ukrai...  \n",
      "410  Russia Says US Is Responsible for Deadly Ukrai...  \n",
      "411  Russia Says US Is Responsible for Deadly Ukrai...  \n",
      "412  Russia Says US Is Responsible for Deadly Ukrai...  \n",
      "413  Russia Says US Is Responsible for Deadly Ukrai...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(sub1)\n",
    "df2 = pd.read_parquet(sub2)\n",
    "df = df[ df['lang'] == 'EN'].reset_index()\n",
    "df2 = df2[ df2['lang'] == 'EN'].reset_index()\n",
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lang</th>\n",
       "      <th>art_name</th>\n",
       "      <th>entity</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>class1</th>\n",
       "      <th>classes2</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>117</td>\n",
       "      <td>EN</td>\n",
       "      <td>EN_UA_DEV_100002.txt</td>\n",
       "      <td>Zelensky</td>\n",
       "      <td>657</td>\n",
       "      <td>664</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Corrupt, Tyrant]</td>\n",
       "      <td>Ukrainian nationalism, Ukrainian patriotism wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>118</td>\n",
       "      <td>EN</td>\n",
       "      <td>EN_UA_DEV_100002.txt</td>\n",
       "      <td>Ukraine</td>\n",
       "      <td>672</td>\n",
       "      <td>678</td>\n",
       "      <td>Innocent</td>\n",
       "      <td>[Exploited]</td>\n",
       "      <td>Ukrainian nationalism, Ukrainian patriotism wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>119</td>\n",
       "      <td>EN</td>\n",
       "      <td>EN_UA_DEV_100002.txt</td>\n",
       "      <td>West</td>\n",
       "      <td>725</td>\n",
       "      <td>728</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Conspirator]</td>\n",
       "      <td>Ukrainian nationalism, Ukrainian patriotism wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>120</td>\n",
       "      <td>EN</td>\n",
       "      <td>EN_UA_DEV_100002.txt</td>\n",
       "      <td>NATO</td>\n",
       "      <td>1027</td>\n",
       "      <td>1030</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Conspirator, Foreign Adversary]</td>\n",
       "      <td>Ukrainian nationalism, Ukrainian patriotism wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>121</td>\n",
       "      <td>EN</td>\n",
       "      <td>EN_UA_DEV_100002.txt</td>\n",
       "      <td>Russia</td>\n",
       "      <td>1200</td>\n",
       "      <td>1205</td>\n",
       "      <td>Protagonist</td>\n",
       "      <td>[Guardian]</td>\n",
       "      <td>Ukrainian nationalism, Ukrainian patriotism wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index lang              art_name    entity start   end       class1  \\\n",
       "500    117   EN  EN_UA_DEV_100002.txt  Zelensky   657   664   Antagonist   \n",
       "501    118   EN  EN_UA_DEV_100002.txt   Ukraine   672   678     Innocent   \n",
       "502    119   EN  EN_UA_DEV_100002.txt      West   725   728   Antagonist   \n",
       "503    120   EN  EN_UA_DEV_100002.txt      NATO  1027  1030   Antagonist   \n",
       "504    121   EN  EN_UA_DEV_100002.txt    Russia  1200  1205  Protagonist   \n",
       "\n",
       "                             classes2  \\\n",
       "500                 [Corrupt, Tyrant]   \n",
       "501                       [Exploited]   \n",
       "502                     [Conspirator]   \n",
       "503  [Conspirator, Foreign Adversary]   \n",
       "504                        [Guardian]   \n",
       "\n",
       "                                                  text  \n",
       "500  Ukrainian nationalism, Ukrainian patriotism wi...  \n",
       "501  Ukrainian nationalism, Ukrainian patriotism wi...  \n",
       "502  Ukrainian nationalism, Ukrainian patriotism wi...  \n",
       "503  Ukrainian nationalism, Ukrainian patriotism wi...  \n",
       "504  Ukrainian nationalism, Ukrainian patriotism wi...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df, df2], ignore_index=True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ozEIv93FiMW3"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def labelNum(row):\n",
    "    if row['class1'] == 'Antagonist':\n",
    "        return int(0)\n",
    "    if row['class1'] == 'Innocent':\n",
    "        return int(1)\n",
    "    if row['class1'] == 'Protagonist':\n",
    "        return int(2)\n",
    "def cleanText(row):\n",
    "    text = str(row['text'])\n",
    "    #text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = text.replace('\\n',' ').replace('  ', ' ')\n",
    "    return text\n",
    "df['label1'] = df.apply(labelNum,axis=1)\n",
    "df['input'] = df.apply(cleanText,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelNum2(row):\n",
    "    labels2 = [0 for _ in range(22)]\n",
    "    if row['label1'] == 2:\n",
    "        #labels2 = [0 for _ in range(6)]\n",
    "        if 'Guardian' in row['classes2']:\n",
    "            labels2[0] = 1\n",
    "        if 'Martyr' in row['classes2']:\n",
    "            labels2[1] = 1\n",
    "        if 'Peacemaker' in row['classes2']:\n",
    "            labels2[2] = 1\n",
    "        if 'Rebel' in row['classes2']:\n",
    "            labels2[3] = 1\n",
    "        if 'Underdog' in row['classes2']:\n",
    "            labels2[4] = 1\n",
    "        if 'Virtuous' in row['classes2']:\n",
    "            labels2[5] = 1\n",
    "    elif row['label1'] == 0:\n",
    "        #labels2 = [0 for _ in range(12)]\n",
    "        if 'Instigator' in row['classes2']:\n",
    "           labels2[6] = 1\n",
    "        if 'Conspirator' in row['classes2']:\n",
    "            labels2[7] = 1\n",
    "        if 'Tyrant' in row['classes2']:\n",
    "            labels2[8] = 1\n",
    "        if  'Foreign Adversary' in row['classes2']:\n",
    "            labels2[9] = 1\n",
    "        if 'Traitor' in row['classes2']:\n",
    "            labels2[10] = 1\n",
    "        if 'Spy' in row['classes2']:\n",
    "            labels2[11] = 1\n",
    "        if 'Saboteur' in row['classes2']:\n",
    "            labels2[12] = 1\n",
    "        if 'Corrupt' in row['classes2']:\n",
    "            labels2[13] = 1\n",
    "        if 'Incompetent' in row['classes2']:\n",
    "            labels2[14] = 1\n",
    "        if 'Terrorist' in row['classes2']:\n",
    "            labels2[15] = 1\n",
    "        if 'Deceiver' in row['classes2']:\n",
    "            labels2[16] = 1\n",
    "        if 'Bigot' in row['classes2']:\n",
    "            labels2[17] = 1\n",
    "    elif row['label1'] == 1:\n",
    "        #labels2 = [0 for _ in range(4)]\n",
    "        if 'Forgotten' in row['classes2']:\n",
    "            labels2[18] = 1\n",
    "        if 'Exploited' in row['classes2']:\n",
    "            labels2[19] = 1\n",
    "        if 'Victim' in row['classes2']:\n",
    "            labels2[20] = 1\n",
    "        if 'Scapegoat' in row['classes2']:\n",
    "            labels2[21] = 1\n",
    "    return labels2\n",
    "\n",
    "df['label2'] = df.apply(labelNum2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bnshZfqsiMW4",
    "outputId": "e015f9b0-eeb1-478c-a33d-5113d8680da3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index                                                          448\n",
      "lang                                                            EN\n",
      "art_name                                          EN_UA_103861.txt\n",
      "entity                                                     Chinese\n",
      "start                                                          791\n",
      "end                                                            797\n",
      "class1                                                  Antagonist\n",
      "classes2                                                     [Spy]\n",
      "text             The World Needs Peacemaker Trump Again \\n\\n by...\n",
      "label1                                                           0\n",
      "input            The World Needs Peacemaker Trump Again  by Jef...\n",
      "label2           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...\n",
      "new_start_end                                           (785, 792)\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def find_all_substring_start_end(text, substring):\n",
    "    # Use re.finditer to find all occurrences of the substring in the text\n",
    "    matches = re.finditer(re.escape(substring), text)\n",
    "\n",
    "    # Collect the start and end indices of all matches\n",
    "    positions = [(match.start(), match.end()) for match in matches]\n",
    "\n",
    "    return positions\n",
    "def adjust_start_end(row):\n",
    "    org_text,cl_text,start,end,entity = str(row['text']),str(row['input']),int(row['start']),int(row['end']),str(row['entity'])\n",
    "    ss1 = find_all_substring_start_end(org_text,entity)\n",
    "    ss2 = find_all_substring_start_end(cl_text,entity)\n",
    "    #print(ss1,ss2)\n",
    "    #print(row['text'][start:end])\n",
    "    a = 0\n",
    "    for i in range(len(ss1)):\n",
    "        if abs((ss1[i][0] - start) + (ss1[i][1] - end) ) <= 2:\n",
    "            a = i\n",
    "            break\n",
    "    if org_text[ss1[a][0]:ss1[a][1]] != cl_text[ss2[a][0]:ss2[a][1]]:\n",
    "        print(\"ERROR!\")\n",
    "    return ss2[a][0],ss2[a][1]\n",
    "df['new_start_end'] = df.apply(adjust_start_end,axis=1)\n",
    "print(df.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "s-PdTAcViMW5"
   },
   "outputs": [],
   "source": [
    "def addTokensToInput(row):\n",
    "    inp = row['input']\n",
    "    start,end = row['new_start_end']\n",
    "    #print(start,end)\n",
    "    start = int(start)\n",
    "    end = int(end)\n",
    "    token_input = inp[:start] + \"[SPAN_START] \" + inp[start:end] + \" [SPAN_END]\" + inp[end:]\n",
    "    return token_input\n",
    "\n",
    "df['span_input'] = df.apply(addTokensToInput,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yobaQPRoiMW5"
   },
   "outputs": [],
   "source": [
    "def upStartEnd(row):\n",
    "    start,end = row['new_start_end']\n",
    "    start += len(\"[SPAN_START] \")\n",
    "    end += len(\"[SPAN_START] \")\n",
    "    return start,end\n",
    "\n",
    "df['new_start_end'] = df.apply(upStartEnd,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PwT_XHKmiMW5",
    "outputId": "c8b74e35-d801-4f20-cfaa-f169f2a70b4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from transformers import RobertaForSequenceClassification \n",
    "from transformers import RobertaTokenizerFast\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=22,problem_type=\"multi_label_classification\").to(device)\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['span_input'], padding=True, truncation=True,max_length=8192,return_offsets_mapping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nZDwWW9hiMW6",
    "outputId": "69cabf38-59df-407c-f1a6-a1958141b124"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(50267, 768, padding_idx=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraTokens = {\n",
    "    \"additional_special_tokens\": [\"[SPAN_START]\", \"[SPAN_END]\"]\n",
    "}\n",
    "num_added_toks = tokenizer.add_special_tokens(extraTokens)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "gMWI8j1ZiMW6"
   },
   "outputs": [],
   "source": [
    "data = df.loc[ : , ['span_input', 'label1', 'label2', 'new_start_end', 'entity']]\n",
    "data['tokenized']=data.apply(preprocess_function,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cBcBQZegiMW7"
   },
   "outputs": [],
   "source": [
    "def indexes(row):\n",
    "    off_mask = row['tokenized']['offset_mapping']\n",
    "    start,end = row['new_start_end'][0],row['new_start_end'][1]\n",
    "    inds = list()\n",
    "    for p in range(len(off_mask)):\n",
    "        if off_mask[p][0] >= start and off_mask[p][1] <= end:\n",
    "            if p != len(off_mask)-1:\n",
    "                inds.append(p)\n",
    "    #if len(inds) > 1:\n",
    "        #print(\"GREATER THAN 1\")\n",
    "    if len(inds) == 0:\n",
    "        print(start,end)\n",
    "    return inds\n",
    "data['indexes'] = data.apply(indexes,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uwd1VtkRiMW8",
    "outputId": "b7bbad5b-44bf-4b93-a5cf-f5557c57d8ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505 505 505\n"
     ]
    }
   ],
   "source": [
    "data['list'] = data['tokenized'].apply(lambda x: x['input_ids'])\n",
    "data['attention'] = data['tokenized'].apply(lambda x: x['attention_mask'])\n",
    "ids = data['list']\n",
    "att = data['attention']\n",
    "indexes = data['indexes']\n",
    "tids = list()\n",
    "tatt = list()\n",
    "print(len(ids),len(att),len(indexes))\n",
    "for i in range(len(ids)):\n",
    "    tids.append(torch.tensor(ids[i]))\n",
    "    tatt.append(torch.tensor(att[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Hawj2WEWiMW8"
   },
   "outputs": [],
   "source": [
    "sliced_ids = list()\n",
    "sliced_ntids = list()\n",
    "sliced_att = list()\n",
    "key_inds = list()\n",
    "key_ids = list()\n",
    "\n",
    "def slices(index,size,context_size):\n",
    "    if (size<context_size):\n",
    "        return 0,size\n",
    "    lower_c = int(context_size/2-1)\n",
    "    upper_c = int(context_size/2)\n",
    "    #print(lower_c,upper_c)\n",
    "    if index < lower_c:\n",
    "        return 0,context_size\n",
    "    elif index >= lower_c:\n",
    "        if index + upper_c > size:\n",
    "            return index-(context_size-(size-index)), size\n",
    "        else:\n",
    "            return index-lower_c,index+upper_c+1\n",
    "\n",
    "\n",
    "for i in range(len(tids)):\n",
    "    slower,supper = slices(indexes[i][0],len(tids[i]),510)\n",
    "    #key_tid = tids[i][indexes[i][0]]\n",
    "    pid = ids[i][slower:supper]\n",
    "    key_inds.append([])\n",
    "    for j in indexes[i]:\n",
    "        key_id = ids[i][j]\n",
    "        if key_id not in pid:\n",
    "           print(len(ids[i]),key_id,slower,supper,indexes[i])\n",
    "        key_inds[i].append(pid.index(key_id))\n",
    "    apid = tids[i][slower:supper]\n",
    "    apatt = tatt[i][slower:supper]\n",
    "    if 0 not in pid:\n",
    "        apid = torch.cat((torch.tensor([0]),apid),dim=0)\n",
    "        apatt = torch.cat((torch.tensor([1]),apatt),dim=0)\n",
    "    if 2 not in pid:\n",
    "        apid = torch.cat((apid,torch.tensor([2])),dim=0)\n",
    "        apatt = torch.cat((apatt,torch.tensor([1])),dim=0)\n",
    "    sliced_ids.append(apid)\n",
    "    sliced_att.append(apatt)\n",
    "\n",
    "Min = 10000\n",
    "Max = 0\n",
    "ind2 = 0\n",
    "for i in range(len(indexes)):\n",
    "    if len(sliced_ids[i]) < Min:\n",
    "        Min = len(sliced_ids[i])\n",
    "        ind2 = i\n",
    "\n",
    "    if len(sliced_ids[i]) > Max:\n",
    "        Max = len(sliced_ids[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "xFCUO_GXiMW8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "input_ids = list()\n",
    "att_mask = list()\n",
    "for ten,att in zip(sliced_ids,sliced_att):\n",
    "    if len(ten) < 512:\n",
    "        padding_length = 512 - len(ten)\n",
    "        padding_tensor = torch.full((padding_length,), tokenizer.pad_token_id, dtype=ten.dtype)\n",
    "        padding_tensor2 = torch.full((padding_length,), 0, dtype=att.dtype)\n",
    "        ten = torch.cat((ten,padding_tensor),dim=0)\n",
    "        att = torch.cat((att,padding_tensor2),dim=0)\n",
    "    input_ids.append(ten)\n",
    "    att_mask.append(att)\n",
    "inputIds = torch.stack(input_ids)\n",
    "attMask = torch.stack(att_mask)\n",
    "\n",
    "inputIds_np = inputIds.numpy()\n",
    "attMask_np = attMask.numpy()\n",
    "y1 = data['label1'].values\n",
    "y2 = data['label2'].values\n",
    "lang = df['lang'].tolist()\n",
    "lang = np.array(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "sZvBhiA-iMW8"
   },
   "outputs": [],
   "source": [
    "X_train_ids = inputIds_np[:414]\n",
    "X_test_ids = inputIds_np[414:]\n",
    "#print(len(X_train_ids),len(X_test_ids))\n",
    "X_train_mask = attMask_np[:414]\n",
    "X_test_mask = attMask_np[414:]\n",
    "\n",
    "y1_train = y1[:414]\n",
    "y1_test = y1[414:]\n",
    "\n",
    "y2_train = y2[:414]\n",
    "y2_test = y2[414:]\n",
    "\n",
    "lang_train = lang[:414]\n",
    "lang_test = lang[414:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y2_train = np.array(y2_train.tolist(), dtype=np.int8)\n",
    "y2_test = np.array(y2_test.tolist(), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "2Nos0gEBiMW8"
   },
   "outputs": [],
   "source": [
    "X_train_ids = torch.tensor(X_train_ids, dtype=torch.long).to(device)\n",
    "X_test_ids = torch.tensor(X_test_ids, dtype=torch.long).to(device)\n",
    "X_train_mask = torch.tensor(X_train_mask, dtype=torch.long).to(device)\n",
    "X_test_mask = torch.tensor(X_test_mask, dtype=torch.long).to(device)\n",
    "y1_train = torch.tensor(y1_train, dtype=torch.long).to(device)\n",
    "y1_test = torch.tensor(y1_test, dtype=torch.long).to(device)\n",
    "y2_train = torch.tensor(y2_train, dtype=torch.long).to(device)\n",
    "y2_test = torch.tensor(y2_test, dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "GTxQJLCliMW9"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(X_train_ids, X_train_mask, y1_train, y2_train)\n",
    "test_dataset = TensorDataset(X_test_ids, X_test_mask, y1_test, y2_test )\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True) #shuffle=True provides data shuffle for batches in different epochs\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class HierarchicalNN(nn.Module):\n",
    "    def __init__(self, input_dim, num_parent_classes, num_subcategory_classes,hidden_size):\n",
    "        super(HierarchicalNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_size)\n",
    "        \n",
    "\n",
    "        # Parent class output head\n",
    "        self.parent_fc = nn.Linear(hidden_size, num_parent_classes)\n",
    "\n",
    "        # Subcategory output head (conditional on parent class)\n",
    "        self.subcategory_fc = nn.Linear(hidden_size, num_subcategory_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        gelu = nn.GELU()\n",
    "        x = self.fc1(x)\n",
    "        x = gelu(x)\n",
    "\n",
    "        #parent_output = self.parent_fc(x)  # Parent class logits\n",
    "        subcategory_output = self.subcategory_fc(x)  # Subcategory logits\n",
    "\n",
    "        return subcategory_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "YES435MWiMW9"
   },
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "#classifier = nn.Linear(model.config.hidden_size * 2, 22).to(device)\n",
    "#classifier = HierarchicalNN(model.config.hidden_size * 2,3,22, model.config.hidden_size * 2).to(device)\n",
    "#optimizer = AdamW([\n",
    "#    {'params': model.parameters(),'lr':2e-5},  # Lower learning rate for XLM-RoBERTa\n",
    "#    {'params': classifier.parameters(),'lr':1e-3}     # Higher learning rate for the classifier\n",
    "#])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion2 = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: tensor([False, False, False, False, False, False,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True]), 0: tensor([ True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True,  True,\n",
      "         True,  True]), 1: tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "        False, False])}\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "test_batch= torch.Tensor([\n",
    "    #1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22\n",
    "    [1,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0],\n",
    "    [1,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "    [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1]\n",
    "])\n",
    "test_parent = torch.Tensor([\n",
    "    [2],\n",
    "    [0],\n",
    "    [1]\n",
    "])\n",
    "mask = {}\n",
    "mask[2] = torch.cat([torch.zeros(6, dtype=torch.bool), torch.ones(16, dtype=torch.bool)])\n",
    "mask[0] = torch.cat([torch.ones(6, dtype=torch.bool), torch.zeros(12, dtype=torch.bool), torch.ones(4, dtype=torch.bool)])\n",
    "mask[1] = torch.cat([torch.ones(18, dtype=torch.bool), torch.zeros(4, dtype=torch.bool)])\n",
    "print(mask)\n",
    "def apply_mask(labels,parent,mask):\n",
    "    \n",
    "    # Create an empty tensor to store the results\n",
    "    result = labels.clone()\n",
    "\n",
    "    # Loop through the batch and apply the corresponding tensor from result_dict\n",
    "    for i in range(labels.shape[0]):\n",
    "        idx = parent[i].item()  # Get the index (0, 1, or 2)\n",
    "        mask2 = mask[idx]  # Apply the corresponding tensor from result_dict\n",
    "\n",
    "        result[i][~mask2] = 0 \n",
    "\n",
    "    return result\n",
    "print(apply_mask(test_batch,test_parent,mask))\n",
    "zero_ten = torch.zeros((16, 22), dtype=torch.float32).to(device)\n",
    "print(zero_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "VxX8jmCe-p8a"
   },
   "outputs": [],
   "source": [
    "# for the confusion matrix in the end\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "final_preds = np.empty((0, 22), dtype=np.int8)\n",
    "final_labels = np.empty((0, 22), dtype=np.int8)\n",
    "span_start_token_id = tokenizer.convert_tokens_to_ids('[SPAN_START]')\n",
    "span_end_token_id = tokenizer.convert_tokens_to_ids('[SPAN_END]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_epochs = 10\n",
    "debug = 0\n",
    "pred_list = list()\n",
    "labels_list = list()\n",
    "log_list =list()\n",
    "\n",
    "best_params = {\n",
    "    'treshold' : 0,\n",
    "    'scalar' : 0,\n",
    "}\n",
    "best_acc = 0\n",
    "sig_tresholds = [0.15,0.2,0.25,0.3]\n",
    "scalars = [2,4,5]\n",
    "\n",
    "\n",
    "\n",
    "for tresh in sig_tresholds:\n",
    "    for scalar in scalars:\n",
    "        print(f\"Testing parameters tresh {tresh}, scalar {scalar}\")\n",
    "        model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=22,problem_type=\"multi_label_classification\").to(device)\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "        classifier = HierarchicalNN(model.config.hidden_size * 2,3,22, model.config.hidden_size * 2).to(device)\n",
    "        optimizer = AdamW([\n",
    "            {'params': model.parameters(),'lr':2e-5},  # Lower learning rate for XLM-RoBERTa\n",
    "            {'params': classifier.parameters(),'lr':1e-3}     # Higher learning rate for the classifier\n",
    "        ])     \n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            \n",
    "            model.train()\n",
    "            classifier.train()\n",
    "            total_loss = 0\n",
    "            correct_parents = 0\n",
    "            total_parents = 0\n",
    "            correct_predictions = 0\n",
    "            total_predictions = 0\n",
    "        \n",
    "            train_preds = np.empty((0, 22), dtype=np.int8)\n",
    "            train_labels = np.empty((0, 22), dtype=np.int8)\n",
    "            \n",
    "            train_progress_bar = tqdm(train_dataloader, desc=f\"Training Epoch {epoch + 1}/{num_epochs}\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            for batch in train_progress_bar:\n",
    "                optimizer.zero_grad()\n",
    "                input_ids = batch[0].to(device)\n",
    "                attention_mask = batch[1].to(device)\n",
    "                parents = batch[2].to(device)\n",
    "                labels = batch[3].to(device)\n",
    "                batch_size = input_ids.size(0)\n",
    "        \n",
    "                \n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels.float(), output_hidden_states=True)\n",
    "        \n",
    "                hidden_states = outputs.hidden_states[-1]\n",
    "        \n",
    "                entity_representations = []\n",
    "        \n",
    "                for i in range(batch_size):\n",
    "                    ind_start = torch.nonzero(input_ids[i] == span_start_token_id).squeeze()\n",
    "                    ind_end = torch.nonzero(input_ids[i] == span_end_token_id).squeeze()\n",
    "                    start_ten = hidden_states[i,ind_start]\n",
    "                    end_ten = hidden_states[i,ind_end]\n",
    "                    #if debug == 0:\n",
    "                        #print (ind_start,ind_end)\n",
    "                        #print(start_ten.shape,end_ten.shape)\n",
    "                    rep = torch.cat((hidden_states[i,ind_start],hidden_states[i,ind_end]),dim=0)\n",
    "                    entity_representations.append(rep)\n",
    "                \n",
    "        \n",
    "                #entity_representations = []\n",
    "        \n",
    "                #start_indices = start_mask.nonzero(as_tuple=True)[1]\n",
    "                #end_indices = end_mask.nonzero(as_tuple=True)[1]\n",
    "        \n",
    "                # check that span is valid and has non-zero length\n",
    "                #valid_spans = (start_indices != -1) & (end_indices != -1) & (start_indices <= end_indices)\n",
    "        \n",
    "                #valid_start_indices = start_indices[valid_spans]\n",
    "                #valid_end_indices = end_indices[valid_spans]\n",
    "        \n",
    "                \n",
    "                \n",
    "                # extract entity tokens for every sample in batch\n",
    "                #for i in range(batch_size):\n",
    "                    #entity_tokens = hidden_states[i, valid_start_indices[i]]\n",
    "                    #entity_representations.append(entity_tokens)\n",
    "                \n",
    "                #if epoch == 0:\n",
    "                #    print(entity_representations)\n",
    "                \n",
    "                entity_representations = torch.stack(entity_representations, dim=0)\n",
    "                \n",
    "                \n",
    "                #parent_log,\n",
    "                child_log = classifier(entity_representations)\n",
    "                child_log2 = apply_mask(child_log,parents,mask)\n",
    "                zero_ten = torch.zeros((input_ids.size(0), 22), dtype=torch.float32).to(device)\n",
    "                #if debug == 0:\n",
    "                    #print(child_log,zero_ten,input_ids.size(0))\n",
    "                    #print(entity_representations.shape)\n",
    "                    #debug+=1\n",
    "                \n",
    "                #loss = criterion(parent_log, parents) + criterion2(child_log,labels.float()) + 2 * criterion2(child_log2,zero_ten) \n",
    "                loss = criterion2(child_log,labels.float()) + scalar * criterion2(child_log2,zero_ten)\n",
    "                total_loss += loss.item()\n",
    "        \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Calculate accuracy\n",
    "                preds = (torch.sigmoid(child_log) > tresh).int()\n",
    "                train_preds = np.vstack([train_preds,preds.cpu().numpy()])\n",
    "                train_labels = np.vstack([train_labels,labels.cpu().numpy()])\n",
    "                correct_predictions += ((preds == labels.int()).all(dim=1)).sum().item()\n",
    "                total_predictions += labels.size(0)\n",
    "                #if debug == 0:\n",
    "                    #print(parent_log,child_log,preds,labels)\n",
    "                    #debug+=1\n",
    "                #preds_parents = torch.argmax(parent_log, dim=-1)\n",
    "                #correct_parents += (preds_parents == parents).sum().item()\n",
    "                #total_parents += labels.size(0)\n",
    "        \n",
    "                train_progress_bar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "            avg_train_loss = total_loss / len(train_dataloader)\n",
    "            train_accuracy = correct_predictions / total_predictions\n",
    "            #parent_train_acc = correct_parents / total_parents\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "            #print(f\"Training loss: {avg_train_loss:.4f}, Training accuracy: {train_accuracy:.4f}, Parent Train acc: {parent_train_acc:.4f}\")\n",
    "            print(f\"Training loss: {avg_train_loss:.4f}, Training accuracy: {train_accuracy:.4f}\")\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(train_labels, train_preds, average='micro')\n",
    "            print(f\"Train Micro Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "            \n",
    "            model.eval()\n",
    "            classifier.eval()\n",
    "            test_loss = 0\n",
    "            correct_predictions = 0\n",
    "            total_predictions = 0\n",
    "            correct_parents = 0\n",
    "            total_parents = 0\n",
    "            test_progress_bar = tqdm(test_dataloader, desc=f\"Test Epoch {epoch + 1}/{num_epochs}\")\n",
    "        \n",
    "            test_preds = np.empty((0, 22), dtype=np.int8)\n",
    "            test_labels = np.empty((0, 22), dtype=np.int8)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch in test_progress_bar:\n",
    "        \n",
    "                    input_ids = batch[0].to(device)\n",
    "                    attention_mask = batch[1].to(device)\n",
    "                    parents = batch[2].to(device)\n",
    "                    labels = batch[3].to(device)\n",
    "        \n",
    "                    batch_size = input_ids.size(0)\n",
    "        \n",
    "                    outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels.float(), output_hidden_states=True)\n",
    "        \n",
    "                    hidden_states = outputs.hidden_states[-1]\n",
    "        \n",
    "                    entity_representations = []\n",
    "        \n",
    "                    for i in range(batch_size):\n",
    "                        ind_start = torch.nonzero(input_ids[i] == span_start_token_id).squeeze()\n",
    "                        ind_end = torch.nonzero(input_ids[i] == span_end_token_id).squeeze()\n",
    "                        start_ten = hidden_states[i,ind_start]\n",
    "                        end_ten = hidden_states[i,ind_end]\n",
    "                        rep = torch.cat((hidden_states[i,ind_start],hidden_states[i,ind_end]),dim=0)\n",
    "                        entity_representations.append(rep)\n",
    "                    \n",
    "                    #start_mask = (input_ids == span_start_token_id)\n",
    "                    #end_mask = (input_ids == span_end_token_id)\n",
    "        \n",
    "                    #entity_representations = []\n",
    "        \n",
    "                    #start_indices = start_mask.nonzero(as_tuple=True)[1]\n",
    "                    #end_indices = end_mask.nonzero(as_tuple=True)[1]\n",
    "        \n",
    "                    #valid_spans = (start_indices != -1) & (end_indices != -1) & (start_indices <= end_indices)\n",
    "        \n",
    "                    #valid_start_indices = start_indices[valid_spans]\n",
    "                    #valid_end_indices = end_indices[valid_spans]\n",
    "        \n",
    "                    # extract entity tokens for every sample in batch\n",
    "                    #for i in range(batch_size):\n",
    "                    #    entity_tokens = hidden_states[i, valid_start_indices[i]]\n",
    "                    #    entity_representations.append(entity_tokens)\n",
    "        \n",
    "                    entity_representations = torch.stack(entity_representations, dim=0)\n",
    "        \n",
    "                    #parent_log,\n",
    "                    child_log = classifier(entity_representations)\n",
    "                    child_log2 = apply_mask(child_log,parents,mask)\n",
    "                    #loss = criterion(parent_log, parents) + criterion2(child_log,labels.float()) + criterion2(child_log2,labels.float()) \n",
    "                    loss = criterion2(child_log,labels.float()) + scalar * criterion2(child_log2,labels.float()) \n",
    "                    test_loss += loss.item()\n",
    "                    \n",
    "                    preds = (torch.sigmoid(child_log) > tresh).int()\n",
    "                    correct_predictions += ((preds == labels.int()).all(dim=1)).sum().item()\n",
    "                    total_predictions += labels.size(0)\n",
    "        \n",
    "                    test_preds = np.vstack([test_preds,preds.cpu().numpy()])\n",
    "                    test_labels = np.vstack([test_labels,labels.cpu().numpy()])\n",
    "                    \n",
    "                    #preds_parents = torch.argmax(parent_log, dim=-1)\n",
    "                    #correct_parents += (preds_parents == parents).sum().item()\n",
    "                    #total_parents += labels.size(0)\n",
    "        \n",
    "                    test_progress_bar.set_postfix({'loss': loss.item()})\n",
    "                    if epoch == num_epochs-1:\n",
    "                        final_preds = np.vstack([final_preds,preds.cpu().numpy()])\n",
    "                        final_labels = np.vstack([final_labels,labels.cpu().numpy()])\n",
    "                        \n",
    "            \n",
    "            avg_test_loss = test_loss / len(test_dataloader)\n",
    "            test_accuracy = correct_predictions / total_predictions\n",
    "            #parent_test_accuracy = correct_parents / total_parents\n",
    "            #print(f\"Test loss: {avg_test_loss:.4f}, Test accuracy: {test_accuracy:.4f}, Parent Test accuracy: {parent_test_accuracy:.4f}\")\n",
    "            print(f\"Test loss: {avg_test_loss:.4f}, Test accuracy: {test_accuracy:.4f}\")\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(test_labels, test_preds, average='micro')\n",
    "            print(f\"Test Micro Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "        if test_accuracy > best_acc:\n",
    "            best_params['scalar']=scalar\n",
    "            best_params['treshold']=tresh\n",
    "            best_acc=test_accuracy\n",
    "        print(f\"current test result {test_accuracy}:{best_acc}\")\n",
    "        del model\n",
    "        del classifier\n",
    "        del optimizer\n",
    "print(f\"Best params {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 2.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:23<00:00,  1.11it/s, loss=0.981]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Training loss: 1.1345, Training accuracy: 0.0000\n",
      "Train Micro Precision: 0.0444, Recall: 0.0979, F1: 0.0611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 1/10: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  3.67it/s, loss=1.02]\n",
      "/home/matijak/anaconda3/envs/ml-nlp/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0591, Test accuracy: 0.0000\n",
      "Test Micro Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:23<00:00,  1.10it/s, loss=0.909]\n",
      "/home/matijak/anaconda3/envs/ml-nlp/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "Training loss: 0.9841, Training accuracy: 0.0000\n",
      "Train Micro Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 2/10: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  3.82it/s, loss=1.01]\n",
      "/home/matijak/anaconda3/envs/ml-nlp/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0602, Test accuracy: 0.0000\n",
      "Test Micro Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/10: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:23<00:00,  1.12it/s, loss=1.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "Training loss: 0.9560, Training accuracy: 0.0386\n",
      "Train Micro Precision: 0.3913, Recall: 0.0410, F1: 0.0742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 3/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  3.85it/s, loss=0.981]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0465, Test accuracy: 0.0220\n",
      "Test Micro Precision: 0.1628, Recall: 0.0700, F1: 0.0979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:23<00:00,  1.10it/s, loss=0.882]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "Training loss: 0.9160, Training accuracy: 0.2053\n",
      "Train Micro Precision: 0.3952, Recall: 0.3007, F1: 0.3415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 4/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  3.87it/s, loss=0.961]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0249, Test accuracy: 0.1429\n",
      "Test Micro Precision: 0.3214, Recall: 0.1800, F1: 0.2308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:23<00:00,  1.11it/s, loss=0.893]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "Training loss: 0.8698, Training accuracy: 0.2995\n",
      "Train Micro Precision: 0.5700, Recall: 0.5376, F1: 0.5533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 5/10: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  3.88it/s, loss=1.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.1102, Test accuracy: 0.1099\n",
      "Test Micro Precision: 0.2427, Recall: 0.2500, F1: 0.2463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:23<00:00,  1.12it/s, loss=0.708]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "Training loss: 0.8270, Training accuracy: 0.5290\n",
      "Train Micro Precision: 0.6794, Recall: 0.7677, F1: 0.7209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 6/10: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  3.82it/s, loss=1.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0806, Test accuracy: 0.2418\n",
      "Test Micro Precision: 0.3846, Recall: 0.3000, F1: 0.3371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:23<00:00,  1.10it/s, loss=0.863]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "Training loss: 0.8022, Training accuracy: 0.6522\n",
      "Train Micro Precision: 0.7699, Recall: 0.8610, F1: 0.8129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 7/10: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  3.85it/s, loss=1.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0831, Test accuracy: 0.2198\n",
      "Test Micro Precision: 0.3947, Recall: 0.3000, F1: 0.3409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:23<00:00,  1.11it/s, loss=0.818]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "Training loss: 0.7799, Training accuracy: 0.8261\n",
      "Train Micro Precision: 0.8663, Recall: 0.9590, F1: 0.9103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 8/10: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  3.75it/s, loss=1.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.1079, Test accuracy: 0.2088\n",
      "Test Micro Precision: 0.3611, Recall: 0.2600, F1: 0.3023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:23<00:00,  1.11it/s, loss=0.819]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "Training loss: 0.7718, Training accuracy: 0.8961\n",
      "Train Micro Precision: 0.9242, Recall: 0.9727, F1: 0.9478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 9/10: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  3.88it/s, loss=1.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.1094, Test accuracy: 0.1978\n",
      "Test Micro Precision: 0.3281, Recall: 0.2100, F1: 0.2561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/10: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:23<00:00,  1.12it/s, loss=0.763]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "Training loss: 0.7651, Training accuracy: 0.9348\n",
      "Train Micro Precision: 0.9515, Recall: 0.9841, F1: 0.9675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 10/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  3.84it/s, loss=1.06]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.1222, Test accuracy: 0.2308\n",
      "Test Micro Precision: 0.3797, Recall: 0.3000, F1: 0.3352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=22,problem_type=\"multi_label_classification\").to(device)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "classifier = HierarchicalNN(model.config.hidden_size * 2,3,22, model.config.hidden_size * 2).to(device)\n",
    "optimizer = AdamW([\n",
    "    {'params': model.parameters(),'lr':2e-5},  # Lower learning rate for XLM-RoBERTa\n",
    "    {'params': classifier.parameters(),'lr':1e-3}     # Higher learning rate for the classifier\n",
    "])     \n",
    "tresh = 0.25\n",
    "scalar = 2.5\n",
    "print(tresh,scalar)\n",
    "num_epochs=10\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    \n",
    "    model.train()\n",
    "    classifier.train()\n",
    "    total_loss = 0\n",
    "    correct_parents = 0\n",
    "    total_parents = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    train_preds = np.empty((0, 22), dtype=np.int8)\n",
    "    train_labels = np.empty((0, 22), dtype=np.int8)\n",
    "    \n",
    "    train_progress_bar = tqdm(train_dataloader, desc=f\"Training Epoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    for batch in train_progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        parents = batch[2].to(device)\n",
    "        labels = batch[3].to(device)\n",
    "        batch_size = input_ids.size(0)\n",
    "\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels.float(), output_hidden_states=True)\n",
    "\n",
    "        hidden_states = outputs.hidden_states[-1]\n",
    "\n",
    "        entity_representations = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            ind_start = torch.nonzero(input_ids[i] == span_start_token_id).squeeze()\n",
    "            ind_end = torch.nonzero(input_ids[i] == span_end_token_id).squeeze()\n",
    "            start_ten = hidden_states[i,ind_start]\n",
    "            end_ten = hidden_states[i,ind_end]\n",
    "            #if debug == 0:\n",
    "                #print (ind_start,ind_end)\n",
    "                #print(start_ten.shape,end_ten.shape)\n",
    "            rep = torch.cat((hidden_states[i,ind_start],hidden_states[i,ind_end]),dim=0)\n",
    "            entity_representations.append(rep)\n",
    "        \n",
    "\n",
    "        #entity_representations = []\n",
    "\n",
    "        #start_indices = start_mask.nonzero(as_tuple=True)[1]\n",
    "        #end_indices = end_mask.nonzero(as_tuple=True)[1]\n",
    "\n",
    "        # check that span is valid and has non-zero length\n",
    "        #valid_spans = (start_indices != -1) & (end_indices != -1) & (start_indices <= end_indices)\n",
    "\n",
    "        #valid_start_indices = start_indices[valid_spans]\n",
    "        #valid_end_indices = end_indices[valid_spans]\n",
    "\n",
    "        \n",
    "        \n",
    "        # extract entity tokens for every sample in batch\n",
    "        #for i in range(batch_size):\n",
    "            #entity_tokens = hidden_states[i, valid_start_indices[i]]\n",
    "            #entity_representations.append(entity_tokens)\n",
    "        \n",
    "        #if epoch == 0:\n",
    "        #    print(entity_representations)\n",
    "        \n",
    "        entity_representations = torch.stack(entity_representations, dim=0)\n",
    "        \n",
    "        \n",
    "        #parent_log,\n",
    "        child_log = classifier(entity_representations)\n",
    "        child_log2 = apply_mask(child_log,parents,mask)\n",
    "        zero_ten = torch.zeros((input_ids.size(0), 22), dtype=torch.float32).to(device)\n",
    "        #if debug == 0:\n",
    "            #print(child_log,zero_ten,input_ids.size(0))\n",
    "            #print(entity_representations.shape)\n",
    "            #debug+=1\n",
    "        \n",
    "        #loss = criterion(parent_log, parents) + criterion2(child_log,labels.float()) + 2 * criterion2(child_log2,zero_ten) \n",
    "        loss = criterion2(child_log,labels.float()) + scalar * criterion2(child_log2,zero_ten)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        preds = (torch.sigmoid(child_log) > tresh).int()\n",
    "        train_preds = np.vstack([train_preds,preds.cpu().numpy()])\n",
    "        train_labels = np.vstack([train_labels,labels.cpu().numpy()])\n",
    "        correct_predictions += ((preds == labels.int()).all(dim=1)).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "        #if debug == 0:\n",
    "            #print(parent_log,child_log,preds,labels)\n",
    "            #debug+=1\n",
    "        #preds_parents = torch.argmax(parent_log, dim=-1)\n",
    "        #correct_parents += (preds_parents == parents).sum().item()\n",
    "        #total_parents += labels.size(0)\n",
    "\n",
    "        train_progress_bar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "    #parent_train_acc = correct_parents / total_parents\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    #print(f\"Training loss: {avg_train_loss:.4f}, Training accuracy: {train_accuracy:.4f}, Parent Train acc: {parent_train_acc:.4f}\")\n",
    "    print(f\"Training loss: {avg_train_loss:.4f}, Training accuracy: {train_accuracy:.4f}\")\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(train_labels, train_preds, average='micro')\n",
    "    print(f\"Train Micro Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "    \n",
    "    model.eval()\n",
    "    classifier.eval()\n",
    "    test_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    correct_parents = 0\n",
    "    total_parents = 0\n",
    "    test_progress_bar = tqdm(test_dataloader, desc=f\"Test Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "    test_preds = np.empty((0, 22), dtype=np.int8)\n",
    "    test_labels = np.empty((0, 22), dtype=np.int8)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_progress_bar:\n",
    "\n",
    "            input_ids = batch[0].to(device)\n",
    "            attention_mask = batch[1].to(device)\n",
    "            parents = batch[2].to(device)\n",
    "            labels = batch[3].to(device)\n",
    "\n",
    "            batch_size = input_ids.size(0)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels.float(), output_hidden_states=True)\n",
    "\n",
    "            hidden_states = outputs.hidden_states[-1]\n",
    "\n",
    "            entity_representations = []\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                ind_start = torch.nonzero(input_ids[i] == span_start_token_id).squeeze()\n",
    "                ind_end = torch.nonzero(input_ids[i] == span_end_token_id).squeeze()\n",
    "                start_ten = hidden_states[i,ind_start]\n",
    "                end_ten = hidden_states[i,ind_end]\n",
    "                rep = torch.cat((hidden_states[i,ind_start],hidden_states[i,ind_end]),dim=0)\n",
    "                entity_representations.append(rep)\n",
    "            \n",
    "            #start_mask = (input_ids == span_start_token_id)\n",
    "            #end_mask = (input_ids == span_end_token_id)\n",
    "\n",
    "            #entity_representations = []\n",
    "\n",
    "            #start_indices = start_mask.nonzero(as_tuple=True)[1]\n",
    "            #end_indices = end_mask.nonzero(as_tuple=True)[1]\n",
    "\n",
    "            #valid_spans = (start_indices != -1) & (end_indices != -1) & (start_indices <= end_indices)\n",
    "\n",
    "            #valid_start_indices = start_indices[valid_spans]\n",
    "            #valid_end_indices = end_indices[valid_spans]\n",
    "\n",
    "            # extract entity tokens for every sample in batch\n",
    "            #for i in range(batch_size):\n",
    "            #    entity_tokens = hidden_states[i, valid_start_indices[i]]\n",
    "            #    entity_representations.append(entity_tokens)\n",
    "\n",
    "            entity_representations = torch.stack(entity_representations, dim=0)\n",
    "\n",
    "            #parent_log,\n",
    "            child_log = classifier(entity_representations)\n",
    "            child_log2 = apply_mask(child_log,parents,mask)\n",
    "            #loss = criterion(parent_log, parents) + criterion2(child_log,labels.float()) + criterion2(child_log2,labels.float()) \n",
    "            loss = criterion2(child_log,labels.float()) + scalar * criterion2(child_log2,labels.float()) \n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            preds = (torch.sigmoid(child_log) > tresh).int()\n",
    "            correct_predictions += ((preds == labels.int()).all(dim=1)).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "\n",
    "            test_preds = np.vstack([test_preds,preds.cpu().numpy()])\n",
    "            test_labels = np.vstack([test_labels,labels.cpu().numpy()])\n",
    "            \n",
    "            #preds_parents = torch.argmax(parent_log, dim=-1)\n",
    "            #correct_parents += (preds_parents == parents).sum().item()\n",
    "            #total_parents += labels.size(0)\n",
    "\n",
    "            test_progress_bar.set_postfix({'loss': loss.item()})\n",
    "            if epoch == num_epochs-1:\n",
    "                final_preds = np.vstack([final_preds,preds.cpu().numpy()])\n",
    "                final_labels = np.vstack([final_labels,labels.cpu().numpy()])\n",
    "                \n",
    "    \n",
    "    avg_test_loss = test_loss / len(test_dataloader)\n",
    "    test_accuracy = correct_predictions / total_predictions\n",
    "    #parent_test_accuracy = correct_parents / total_parents\n",
    "    #print(f\"Test loss: {avg_test_loss:.4f}, Test accuracy: {test_accuracy:.4f}, Parent Test accuracy: {parent_test_accuracy:.4f}\")\n",
    "    print(f\"Test loss: {avg_test_loss:.4f}, Test accuracy: {test_accuracy:.4f}\")\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(test_labels, test_preds, average='micro')\n",
    "    print(f\"Test Micro Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions()  # Reset to default settings\n",
    "np.set_printoptions(precision=3,  # Set the precision of floating point numbers\n",
    "                    suppress=True,  # Suppress smfinal floating point numbers (like 1e-10)\n",
    "                    threshold=np.inf,  # Do not truncate elements (show final columns)\n",
    "                    edgeitems=3,  # Show 3 rows from the beginning and end\n",
    "                    linewidth=np.inf)  # Ensure no wrapping of rows\n",
    "print(final_preds[:30])\n",
    "print(final_labels[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
