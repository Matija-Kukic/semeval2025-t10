{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfQVFtXBiMWy"
   },
   "source": [
    "### Flat model with hierarchical constrains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jYvFwavZiMW0",
    "outputId": "cc0e5456-9b60-4b97-e0a8-613f98e5cfe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/matijak/Documents/programiranje/projects/semeval/merged_data/subtask1.parquet\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# sub1 = 'drive/My Drive/Colab Notebooks/semeval_data/subtask1.parquet'\n",
    "# print(sub1)\n",
    "\n",
    "from pathlib import Path\n",
    "wd = Path.cwd()\n",
    "wd = wd.parent.parent\n",
    "wd = wd / 'merged_data'\n",
    "sub1 = str(wd) + '/subtask1.parquet'\n",
    "print(sub1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BMEITI9CiMW2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(sub1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ozEIv93FiMW3"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def labelNum(row):\n",
    "    if row['class1'] == 'Antagonist':\n",
    "        return int(0)\n",
    "    if row['class1'] == 'Innocent':\n",
    "        return int(1)\n",
    "    if row['class1'] == 'Protagonist':\n",
    "        return int(2)\n",
    "def cleanText(row):\n",
    "    text = str(row['text'])\n",
    "    #text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = text.replace('\\n',' ').replace('  ', ' ')\n",
    "    return text\n",
    "df['label1'] = df.apply(labelNum,axis=1)\n",
    "df['input'] = df.apply(cleanText,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelNum2(row):\n",
    "    labels2 = [0 for _ in range(22)]\n",
    "    if row['label1'] == 2:\n",
    "        #labels2 = [0 for _ in range(6)]\n",
    "        if 'Guardian' in row['classes2']:\n",
    "            labels2[0] = 1\n",
    "        if 'Martyr' in row['classes2']:\n",
    "            labels2[1] = 1\n",
    "        if 'Peacemaker' in row['classes2']:\n",
    "            labels2[2] = 1\n",
    "        if 'Rebel' in row['classes2']:\n",
    "            labels2[3] = 1\n",
    "        if 'Underdog' in row['classes2']:\n",
    "            labels2[4] = 1\n",
    "        if 'Virtuous' in row['classes2']:\n",
    "            labels2[5] = 1\n",
    "    elif row['label1'] == 0:\n",
    "        #labels2 = [0 for _ in range(12)]\n",
    "        if 'Instigator' in row['classes2']:\n",
    "           labels2[6] = 1\n",
    "        if 'Conspirator' in row['classes2']:\n",
    "            labels2[7] = 1\n",
    "        if 'Tyrant' in row['classes2']:\n",
    "            labels2[8] = 1\n",
    "        if  'Foreign Adversary' in row['classes2']:\n",
    "            labels2[9] = 1\n",
    "        if 'Traitor' in row['classes2']:\n",
    "            labels2[10] = 1\n",
    "        if 'Spy' in row['classes2']:\n",
    "            labels2[11] = 1\n",
    "        if 'Saboteur' in row['classes2']:\n",
    "            labels2[12] = 1\n",
    "        if 'Corrupt' in row['classes2']:\n",
    "            labels2[13] = 1\n",
    "        if 'Incompetent' in row['classes2']:\n",
    "            labels2[14] = 1\n",
    "        if 'Terrorist' in row['classes2']:\n",
    "            labels2[15] = 1\n",
    "        if 'Deceiver' in row['classes2']:\n",
    "            labels2[16] = 1\n",
    "        if 'Bigot' in row['classes2']:\n",
    "            labels2[17] = 1\n",
    "    elif row['label1'] == 1:\n",
    "        #labels2 = [0 for _ in range(4)]\n",
    "        if 'Forgotten' in row['classes2']:\n",
    "            labels2[18] = 1\n",
    "        if 'Exploited' in row['classes2']:\n",
    "            labels2[19] = 1\n",
    "        if 'Victim' in row['classes2']:\n",
    "            labels2[20] = 1\n",
    "        if 'Scapegoat' in row['classes2']:\n",
    "            labels2[21] = 1\n",
    "    return labels2\n",
    "\n",
    "df['label2'] = df.apply(labelNum2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bnshZfqsiMW4",
    "outputId": "e015f9b0-eeb1-478c-a33d-5113d8680da3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang                                                            BG\n",
      "art_name                                                BG_670.txt\n",
      "entity                                                       Запад\n",
      "start                                                          152\n",
      "end                                                            156\n",
      "class1                                                  Antagonist\n",
      "classes2              [Conspirator, Instigator, Foreign Adversary]\n",
      "text             Опитът на колективния Запад да „обезкърви Руси...\n",
      "label1                                                           0\n",
      "input            Опитът на колективния Запад да „обезкърви Руси...\n",
      "label2           [0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, ...\n",
      "new_start_end                                           (151, 156)\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def find_all_substring_start_end(text, substring):\n",
    "    # Use re.finditer to find all occurrences of the substring in the text\n",
    "    matches = re.finditer(re.escape(substring), text)\n",
    "\n",
    "    # Collect the start and end indices of all matches\n",
    "    positions = [(match.start(), match.end()) for match in matches]\n",
    "\n",
    "    return positions\n",
    "def adjust_start_end(row):\n",
    "    org_text,cl_text,start,end,entity = str(row['text']),str(row['input']),int(row['start']),int(row['end']),str(row['entity'])\n",
    "    ss1 = find_all_substring_start_end(org_text,entity)\n",
    "    ss2 = find_all_substring_start_end(cl_text,entity)\n",
    "    #print(ss1,ss2)\n",
    "    #print(row['text'][start:end])\n",
    "    a = 0\n",
    "    for i in range(len(ss1)):\n",
    "        if abs((ss1[i][0] - start) + (ss1[i][1] - end) ) <= 2:\n",
    "            a = i\n",
    "            break\n",
    "    if org_text[ss1[a][0]:ss1[a][1]] != cl_text[ss2[a][0]:ss2[a][1]]:\n",
    "        print(\"ERROR!\")\n",
    "    return ss2[a][0],ss2[a][1]\n",
    "df['new_start_end'] = df.apply(adjust_start_end,axis=1)\n",
    "print(df.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "s-PdTAcViMW5"
   },
   "outputs": [],
   "source": [
    "def addTokensToInput(row):\n",
    "    inp = row['input']\n",
    "    start,end = row['new_start_end']\n",
    "    #print(start,end)\n",
    "    start = int(start)\n",
    "    end = int(end)\n",
    "    token_input = inp[:start] + \"[SPAN_START] \" + inp[start:end] + \" [SPAN_END]\" + inp[end:]\n",
    "    return token_input\n",
    "\n",
    "df['span_input'] = df.apply(addTokensToInput,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yobaQPRoiMW5"
   },
   "outputs": [],
   "source": [
    "def upStartEnd(row):\n",
    "    start,end = row['new_start_end']\n",
    "    start += len(\"[SPAN_START] \")\n",
    "    end += len(\"[SPAN_START] \")\n",
    "    return start,end\n",
    "\n",
    "df['new_start_end'] = df.apply(upStartEnd,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PwT_XHKmiMW5",
    "outputId": "c8b74e35-d801-4f20-cfaa-f169f2a70b4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizerFast\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-base\", num_labels=3).to(device)\n",
    "tokenizer = XLMRobertaTokenizerFast.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['span_input'], padding=True, truncation=True,max_length=8192,return_offsets_mapping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nZDwWW9hiMW6",
    "outputId": "69cabf38-59df-407c-f1a6-a1958141b124"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(250004, 768, padding_idx=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraTokens = {\n",
    "    \"additional_special_tokens\": [\"[SPAN_START]\", \"[SPAN_END]\"]\n",
    "}\n",
    "num_added_toks = tokenizer.add_special_tokens(extraTokens)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gMWI8j1ZiMW6"
   },
   "outputs": [],
   "source": [
    "data = df.loc[ : , ['span_input', 'label1', 'label2', 'new_start_end', 'entity']]\n",
    "data['tokenized']=data.apply(preprocess_function,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cBcBQZegiMW7"
   },
   "outputs": [],
   "source": [
    "def indexes(row):\n",
    "    off_mask = row['tokenized']['offset_mapping']\n",
    "    start,end = row['new_start_end'][0],row['new_start_end'][1]\n",
    "    inds = list()\n",
    "    for p in range(len(off_mask)):\n",
    "        if off_mask[p][0] >= start and off_mask[p][1] <= end:\n",
    "            if p != len(off_mask)-1:\n",
    "                inds.append(p)\n",
    "    #if len(inds) > 1:\n",
    "        #print(\"GREATER THAN 1\")\n",
    "    if len(inds) == 0:\n",
    "        print(start,end)\n",
    "    return inds\n",
    "data['indexes'] = data.apply(indexes,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uwd1VtkRiMW8",
    "outputId": "b7bbad5b-44bf-4b93-a5cf-f5557c57d8ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2902 2902 2902\n"
     ]
    }
   ],
   "source": [
    "data['list'] = data['tokenized'].apply(lambda x: x['input_ids'])\n",
    "data['attention'] = data['tokenized'].apply(lambda x: x['attention_mask'])\n",
    "ids = data['list']\n",
    "att = data['attention']\n",
    "indexes = data['indexes']\n",
    "tids = list()\n",
    "tatt = list()\n",
    "print(len(ids),len(att),len(indexes))\n",
    "for i in range(len(ids)):\n",
    "    tids.append(torch.tensor(ids[i]))\n",
    "    tatt.append(torch.tensor(att[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Hawj2WEWiMW8"
   },
   "outputs": [],
   "source": [
    "sliced_ids = list()\n",
    "sliced_ntids = list()\n",
    "sliced_att = list()\n",
    "key_inds = list()\n",
    "key_ids = list()\n",
    "\n",
    "def slices(index,size,context_size):\n",
    "    if (size<context_size):\n",
    "        return 0,size\n",
    "    lower_c = int(context_size/2-1)\n",
    "    upper_c = int(context_size/2)\n",
    "    #print(lower_c,upper_c)\n",
    "    if index < lower_c:\n",
    "        return 0,context_size\n",
    "    elif index >= lower_c:\n",
    "        if index + upper_c > size:\n",
    "            return index-(context_size-(size-index)), size\n",
    "        else:\n",
    "            return index-lower_c,index+upper_c+1\n",
    "\n",
    "\n",
    "for i in range(len(tids)):\n",
    "    slower,supper = slices(indexes[i][0],len(tids[i]),510)\n",
    "    #key_tid = tids[i][indexes[i][0]]\n",
    "    pid = ids[i][slower:supper]\n",
    "    key_inds.append([])\n",
    "    for j in indexes[i]:\n",
    "        key_id = ids[i][j]\n",
    "        if key_id not in pid:\n",
    "           print(len(ids[i]),key_id,slower,supper,indexes[i])\n",
    "        key_inds[i].append(pid.index(key_id))\n",
    "    apid = tids[i][slower:supper]\n",
    "    apatt = tatt[i][slower:supper]\n",
    "    if 0 not in pid:\n",
    "        apid = torch.cat((torch.tensor([0]),apid),dim=0)\n",
    "        apatt = torch.cat((torch.tensor([1]),apatt),dim=0)\n",
    "    if 2 not in pid:\n",
    "        apid = torch.cat((apid,torch.tensor([2])),dim=0)\n",
    "        apatt = torch.cat((apatt,torch.tensor([1])),dim=0)\n",
    "    sliced_ids.append(apid)\n",
    "    sliced_att.append(apatt)\n",
    "\n",
    "Min = 10000\n",
    "Max = 0\n",
    "ind2 = 0\n",
    "for i in range(len(indexes)):\n",
    "    if len(sliced_ids[i]) < Min:\n",
    "        Min = len(sliced_ids[i])\n",
    "        ind2 = i\n",
    "\n",
    "    if len(sliced_ids[i]) > Max:\n",
    "        Max = len(sliced_ids[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "xFCUO_GXiMW8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "input_ids = list()\n",
    "att_mask = list()\n",
    "for ten,att in zip(sliced_ids,sliced_att):\n",
    "    if len(ten) < 512:\n",
    "        padding_length = 512 - len(ten)\n",
    "        padding_tensor = torch.full((padding_length,), tokenizer.pad_token_id, dtype=ten.dtype)\n",
    "        padding_tensor2 = torch.full((padding_length,), 0, dtype=att.dtype)\n",
    "        ten = torch.cat((ten,padding_tensor),dim=0)\n",
    "        att = torch.cat((att,padding_tensor2),dim=0)\n",
    "    input_ids.append(ten)\n",
    "    att_mask.append(att)\n",
    "inputIds = torch.stack(input_ids)\n",
    "attMask = torch.stack(att_mask)\n",
    "\n",
    "inputIds_np = inputIds.numpy()\n",
    "attMask_np = attMask.numpy()\n",
    "y1 = data['label1'].values\n",
    "y2 = data['label2'].values\n",
    "lang = df['lang'].tolist()\n",
    "lang = np.array(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "sZvBhiA-iMW8"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_ids, X_test_ids, X_train_mask, X_test_mask, y1_train, y1_test, y2_train, y2_test = train_test_split(\n",
    "    inputIds_np, attMask_np, y1, y2, test_size=0.2, random_state=42, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y2_train = np.array(y2_train.tolist(), dtype=np.int8)\n",
    "y2_test = np.array(y2_test.tolist(), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2Nos0gEBiMW8"
   },
   "outputs": [],
   "source": [
    "X_train_ids = torch.tensor(X_train_ids, dtype=torch.long).to(device)\n",
    "X_test_ids = torch.tensor(X_test_ids, dtype=torch.long).to(device)\n",
    "X_train_mask = torch.tensor(X_train_mask, dtype=torch.long).to(device)\n",
    "X_test_mask = torch.tensor(X_test_mask, dtype=torch.long).to(device)\n",
    "y1_train = torch.tensor(y1_train, dtype=torch.long).to(device)\n",
    "y1_test = torch.tensor(y1_test, dtype=torch.long).to(device)\n",
    "y2_train = torch.tensor(y2_train, dtype=torch.long).to(device)\n",
    "y2_test = torch.tensor(y2_test, dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "GTxQJLCliMW9"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(X_train_ids, X_train_mask, y1_train, y2_train)\n",
    "test_dataset = TensorDataset(X_test_ids, X_test_mask, y1_test, y2_test )\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True) #shuffle=True provides data shuffle for batches in different epochs\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class HierarchicalNN(nn.Module):\n",
    "    def __init__(self, input_dim, num_parent_classes, num_subcategory_classes,hidden_size):\n",
    "        super(HierarchicalNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_size)\n",
    "        \n",
    "\n",
    "        # Parent class output head\n",
    "        self.parent_fc = nn.Linear(hidden_size, num_parent_classes)\n",
    "\n",
    "        # Subcategory output head (conditional on parent class)\n",
    "        self.subcategory_fc = nn.Linear(hidden_size, num_subcategory_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        gelu = nn.GELU()\n",
    "        x = self.fc1(x)\n",
    "        x = gelu(x)\n",
    "\n",
    "        #parent_output = self.parent_fc(x)  # Parent class logits\n",
    "        subcategory_output = self.subcategory_fc(x)  # Subcategory logits\n",
    "\n",
    "        return subcategory_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "YES435MWiMW9"
   },
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "#classifier = nn.Linear(model.config.hidden_size * 2, 22).to(device)\n",
    "classifier = HierarchicalNN(model.config.hidden_size * 2,3,22, model.config.hidden_size * 2).to(device)\n",
    "optimizer = AdamW([\n",
    "    {'params': model.parameters(),'lr':2e-5},  # Lower learning rate for XLM-RoBERTa\n",
    "    {'params': classifier.parameters(),'lr':1e-3}     # Higher learning rate for the classifier\n",
    "])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion2 = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: tensor([False, False, False, False, False, False,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True]), 0: tensor([ True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True,  True,\n",
      "         True,  True]), 1: tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "        False, False])}\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "test_batch= torch.Tensor([\n",
    "    #1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22\n",
    "    [1,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0],\n",
    "    [1,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "    [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1]\n",
    "])\n",
    "test_parent = torch.Tensor([\n",
    "    [2],\n",
    "    [0],\n",
    "    [1]\n",
    "])\n",
    "mask = {}\n",
    "mask[2] = torch.cat([torch.zeros(6, dtype=torch.bool), torch.ones(16, dtype=torch.bool)])\n",
    "mask[0] = torch.cat([torch.ones(6, dtype=torch.bool), torch.zeros(12, dtype=torch.bool), torch.ones(4, dtype=torch.bool)])\n",
    "mask[1] = torch.cat([torch.ones(18, dtype=torch.bool), torch.zeros(4, dtype=torch.bool)])\n",
    "print(mask)\n",
    "def apply_mask(labels,parent,mask):\n",
    "    \n",
    "    # Create an empty tensor to store the results\n",
    "    result = labels.clone()\n",
    "\n",
    "    # Loop through the batch and apply the corresponding tensor from result_dict\n",
    "    for i in range(labels.shape[0]):\n",
    "        idx = parent[i].item()  # Get the index (0, 1, or 2)\n",
    "        mask2 = mask[idx]  # Apply the corresponding tensor from result_dict\n",
    "\n",
    "        result[i][~mask2] = 0 \n",
    "\n",
    "    return result\n",
    "print(apply_mask(test_batch,test_parent,mask))\n",
    "zero_ten = torch.zeros((16, 22), dtype=torch.float32).to(device)\n",
    "print(zero_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "VxX8jmCe-p8a"
   },
   "outputs": [],
   "source": [
    "# for the confusion matrix in the end\n",
    "all_preds = np.array([], dtype=np.int8)\n",
    "all_labels = np.array([], dtype=np.int8)\n",
    "span_start_token_id = tokenizer.convert_tokens_to_ids('[SPAN_START]')\n",
    "span_end_token_id = tokenizer.convert_tokens_to_ids('[SPAN_END]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ms3jToMlm-4I",
    "outputId": "560b3f27-74f3-4a8e-dd9b-d0bcd36235c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10:   0%|                                                                                                                           | 0/146 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-5.4540e-02,  1.1123e-01, -2.8956e-01, -1.6007e-01, -1.3801e-01,\n",
      "          9.7667e-02, -2.9231e-02, -1.5882e-01, -2.6659e-01,  1.5990e-01,\n",
      "          1.2031e-01, -6.1279e-02,  1.8254e-01,  7.5425e-02,  3.9941e-02,\n",
      "         -2.3222e-02,  3.1860e-02,  1.8412e-01,  1.4770e-01,  2.6212e-02,\n",
      "          1.4420e-01, -4.8389e-02],\n",
      "        [-4.7304e-02,  9.4679e-02, -2.7728e-01, -1.3905e-01, -1.3617e-01,\n",
      "          8.5651e-02,  3.8640e-02, -1.8043e-01, -2.5902e-01,  1.3378e-01,\n",
      "          7.2237e-02, -1.0502e-01,  1.9130e-01,  4.1513e-02,  1.2780e-02,\n",
      "         -1.3025e-02,  1.7708e-02,  1.9229e-01,  1.5768e-01,  7.0323e-03,\n",
      "          1.3266e-01, -4.2427e-02],\n",
      "        [-4.8867e-02,  1.2189e-01, -2.8705e-01, -1.0559e-01, -1.5748e-01,\n",
      "          1.0654e-01,  2.7181e-02, -1.8786e-01, -2.5695e-01,  1.4113e-01,\n",
      "          6.9346e-02, -8.7934e-02,  1.9371e-01,  8.4952e-02,  1.6204e-02,\n",
      "          3.8364e-02,  2.2985e-02,  1.8315e-01,  1.4513e-01, -1.9230e-03,\n",
      "          1.2909e-01, -7.1682e-03],\n",
      "        [-5.5093e-02,  1.2436e-01, -3.0181e-01, -1.4188e-01, -1.4494e-01,\n",
      "          1.0265e-01,  2.8192e-03, -1.7368e-01, -2.5957e-01,  1.5843e-01,\n",
      "          1.0278e-01, -6.8174e-02,  1.9675e-01,  6.3937e-02,  2.9492e-02,\n",
      "         -3.7842e-03,  5.4704e-03,  1.9474e-01,  1.5021e-01, -2.6010e-02,\n",
      "          1.3848e-01, -2.3773e-02],\n",
      "        [-2.7894e-01, -9.3638e-02, -5.8131e-02, -1.1462e-01,  3.7997e-02,\n",
      "         -1.1479e-02,  1.3373e-01,  1.5009e-02, -1.4155e-01,  1.6354e-01,\n",
      "          7.1324e-02, -2.6874e-01,  2.5065e-01,  1.4467e-01,  2.7417e-02,\n",
      "         -1.9950e-01,  1.2592e-01,  1.6498e-01,  8.5104e-02, -1.3505e-01,\n",
      "          1.2469e-01,  1.9589e-01],\n",
      "        [-5.8126e-02,  1.3376e-01, -3.1989e-01, -1.2988e-01, -1.2745e-01,\n",
      "          9.9347e-02,  1.9632e-02, -1.7976e-01, -2.6949e-01,  1.5963e-01,\n",
      "          1.0808e-01, -7.8949e-02,  2.1044e-01,  4.7444e-02,  2.4067e-02,\n",
      "         -7.5517e-03,  6.4669e-03,  1.9599e-01,  1.3148e-01,  3.4374e-04,\n",
      "          1.4145e-01, -4.0619e-02],\n",
      "        [-3.6681e-02,  1.2286e-01, -2.9836e-01, -1.5060e-01, -1.2641e-01,\n",
      "          9.0689e-02,  2.4065e-02, -1.3734e-01, -2.3903e-01,  1.5613e-01,\n",
      "          1.1070e-01, -9.8790e-02,  2.0822e-01,  5.0004e-02,  4.7093e-02,\n",
      "          3.4600e-03,  6.9616e-02,  2.0530e-01,  1.5911e-01, -1.2689e-04,\n",
      "          1.4354e-01, -3.1300e-02],\n",
      "        [-7.6883e-02,  1.2984e-01, -2.9554e-01, -1.1104e-01, -1.4632e-01,\n",
      "          1.0456e-01,  3.9542e-03, -1.6528e-01, -2.6567e-01,  1.7030e-01,\n",
      "          1.2556e-01, -7.6966e-02,  1.8147e-01,  5.7329e-02,  3.5327e-02,\n",
      "          1.0030e-02,  3.3975e-02,  1.5656e-01,  1.4469e-01, -7.5562e-03,\n",
      "          1.3915e-01, -3.6694e-02],\n",
      "        [-4.6553e-02,  1.3696e-01, -2.8965e-01, -1.2704e-01, -1.5888e-01,\n",
      "          8.8390e-02,  1.7284e-02, -1.6933e-01, -2.8030e-01,  1.3433e-01,\n",
      "          8.7125e-02, -8.1928e-02,  2.0721e-01,  8.2136e-02,  3.3014e-02,\n",
      "          1.3104e-02,  2.7669e-02,  1.7896e-01,  1.7071e-01, -4.0465e-03,\n",
      "          1.3000e-01, -2.5104e-02],\n",
      "        [-5.5520e-02,  1.5544e-01, -2.8295e-01, -1.6635e-01, -1.1355e-01,\n",
      "          8.6144e-02, -3.8127e-03, -1.4706e-01, -2.6384e-01,  1.5210e-01,\n",
      "          9.7538e-02, -7.6422e-02,  2.2102e-01,  2.5413e-02,  4.3205e-02,\n",
      "         -1.1743e-02,  9.6943e-02,  2.0087e-01,  1.9138e-01, -3.1523e-02,\n",
      "          1.5148e-01, -5.0684e-03],\n",
      "        [-3.8253e-02,  1.0860e-01, -2.8140e-01, -1.5380e-01, -1.3238e-01,\n",
      "          7.8981e-02,  1.1286e-03, -1.3333e-01, -2.9709e-01,  1.6487e-01,\n",
      "          1.2356e-01, -7.4688e-02,  1.9716e-01,  3.7949e-02,  3.1671e-02,\n",
      "         -3.5943e-02,  2.7773e-02,  1.8521e-01,  1.6557e-01, -2.0127e-02,\n",
      "          1.2580e-01, -5.8303e-02],\n",
      "        [-4.7433e-02,  1.1374e-01, -2.9237e-01, -1.3576e-01, -1.3780e-01,\n",
      "          1.0880e-01,  1.1956e-02, -1.7574e-01, -2.4988e-01,  1.7113e-01,\n",
      "          9.8595e-02, -1.0185e-01,  1.8273e-01,  6.7441e-02,  3.0291e-02,\n",
      "          7.5102e-03,  6.9825e-03,  1.9921e-01,  1.3108e-01, -3.1738e-04,\n",
      "          1.3795e-01, -2.3487e-02],\n",
      "        [-1.3468e-01, -5.4827e-02, -8.4213e-02, -8.7134e-02, -6.0943e-03,\n",
      "         -2.3766e-02,  4.3049e-02,  2.5621e-02, -1.2293e-01,  2.0575e-01,\n",
      "          3.4659e-02, -2.0239e-01,  2.6838e-01,  1.0024e-01,  3.5214e-02,\n",
      "         -1.1618e-01,  8.4866e-02,  2.0769e-01,  1.8854e-01, -9.0901e-02,\n",
      "          1.0877e-01,  1.8531e-01],\n",
      "        [-1.8427e-01, -4.8096e-02, -4.4720e-02, -3.6874e-02,  6.0322e-02,\n",
      "          9.8805e-02,  1.0550e-01,  1.8716e-02, -2.3570e-01,  1.8127e-01,\n",
      "          1.0695e-01, -1.6979e-01,  1.8653e-01,  4.5085e-02, -5.9916e-03,\n",
      "         -5.4754e-02,  8.7085e-02,  1.1656e-01,  1.4260e-01, -1.2257e-01,\n",
      "          1.7266e-01,  1.8549e-01],\n",
      "        [-7.9067e-02,  1.1677e-01, -2.7922e-01, -1.4520e-01, -1.3329e-01,\n",
      "          1.0794e-01,  1.5094e-02, -1.6579e-01, -2.6120e-01,  1.3618e-01,\n",
      "          1.0411e-01, -6.6909e-02,  1.7326e-01,  5.6422e-02,  2.9076e-02,\n",
      "          9.8798e-03,  2.5060e-02,  1.6385e-01,  1.5291e-01, -1.8874e-02,\n",
      "          1.2038e-01, -4.3236e-02],\n",
      "        [-4.3415e-02,  1.0033e-01, -2.8217e-01, -1.3687e-01, -1.3936e-01,\n",
      "          1.0712e-01, -2.2236e-02, -1.6707e-01, -2.7583e-01,  1.2435e-01,\n",
      "          1.1171e-01, -1.2751e-01,  1.9754e-01,  6.9888e-02,  2.5783e-02,\n",
      "         -3.8448e-03,  5.3078e-02,  1.7919e-01,  1.5202e-01, -1.2536e-02,\n",
      "          1.1391e-01, -4.4936e-02]], device='cuda:0', grad_fn=<AddmmBackward0>) tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0') 16\n",
      "torch.Size([16, 1536])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 146/146 [02:16<00:00,  1.07it/s, loss=0.746]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Training loss: 0.7539, Training accuracy: 0.1456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 1/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:09<00:00,  3.74it/s, loss=0.786]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6945, Test accuracy: 0.1979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 146/146 [02:17<00:00,  1.07it/s, loss=0.829]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "Training loss: 0.6835, Training accuracy: 0.2693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 2/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:09<00:00,  3.75it/s, loss=0.773]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6842, Test accuracy: 0.2169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 146/146 [02:23<00:00,  1.02it/s, loss=0.956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "Training loss: 0.6498, Training accuracy: 0.3473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 3/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:09<00:00,  3.74it/s, loss=0.806]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6805, Test accuracy: 0.2444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 146/146 [02:17<00:00,  1.06it/s, loss=0.768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "Training loss: 0.6256, Training accuracy: 0.4218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 4/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:09<00:00,  3.72it/s, loss=0.821]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6824, Test accuracy: 0.3305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 146/146 [02:16<00:00,  1.07it/s, loss=0.993]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "Training loss: 0.5985, Training accuracy: 0.5480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 5/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:09<00:00,  3.74it/s, loss=0.873]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.7084, Test accuracy: 0.3150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 146/146 [02:15<00:00,  1.08it/s, loss=0.413]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "Training loss: 0.5807, Training accuracy: 0.6514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 6/10: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:09<00:00,  3.75it/s, loss=0.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.7425, Test accuracy: 0.3683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 146/146 [02:15<00:00,  1.08it/s, loss=0.687]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "Training loss: 0.5725, Training accuracy: 0.7281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 7/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:09<00:00,  3.74it/s, loss=0.859]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.7347, Test accuracy: 0.4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 146/146 [02:15<00:00,  1.08it/s, loss=0.378]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "Training loss: 0.5640, Training accuracy: 0.7790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 8/10: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:09<00:00,  3.75it/s, loss=1.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.7908, Test accuracy: 0.4217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 146/146 [02:16<00:00,  1.07it/s, loss=0.308]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "Training loss: 0.5530, Training accuracy: 0.8587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 9/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:09<00:00,  3.74it/s, loss=0.957]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.7840, Test accuracy: 0.4079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/10: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 146/146 [02:16<00:00,  1.07it/s, loss=0.252]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "Training loss: 0.5497, Training accuracy: 0.8944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 10/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:09<00:00,  3.76it/s, loss=1.01]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.8290, Test accuracy: 0.4303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "debug = 0\n",
    "pred_list = list()\n",
    "labels_list = list()\n",
    "log_list =list()\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model.train()\n",
    "    classifier.train()\n",
    "    total_loss = 0\n",
    "    correct_parents = 0\n",
    "    total_parents = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    train_progress_bar = tqdm(train_dataloader, desc=f\"Training Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "    \n",
    "    \n",
    "    for batch in train_progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        parents = batch[2].to(device)\n",
    "        labels = batch[3].to(device)\n",
    "        batch_size = input_ids.size(0)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=parents, output_hidden_states=True)\n",
    "\n",
    "        hidden_states = outputs.hidden_states[-1]\n",
    "\n",
    "        entity_representations = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            ind_start = torch.nonzero(input_ids[i] == span_start_token_id).squeeze()\n",
    "            ind_end = torch.nonzero(input_ids[i] == span_end_token_id).squeeze()\n",
    "            start_ten = hidden_states[i,ind_start]\n",
    "            end_ten = hidden_states[i,ind_end]\n",
    "            #if debug == 0:\n",
    "                #print (ind_start,ind_end)\n",
    "                #print(start_ten.shape,end_ten.shape)\n",
    "            rep = torch.cat((hidden_states[i,ind_start],hidden_states[i,ind_end]),dim=0)\n",
    "            entity_representations.append(rep)\n",
    "        \n",
    "\n",
    "        #entity_representations = []\n",
    "\n",
    "        #start_indices = start_mask.nonzero(as_tuple=True)[1]\n",
    "        #end_indices = end_mask.nonzero(as_tuple=True)[1]\n",
    "\n",
    "        # check that span is valid and has non-zero length\n",
    "        #valid_spans = (start_indices != -1) & (end_indices != -1) & (start_indices <= end_indices)\n",
    "\n",
    "        #valid_start_indices = start_indices[valid_spans]\n",
    "        #valid_end_indices = end_indices[valid_spans]\n",
    "\n",
    "        \n",
    "        \n",
    "        # extract entity tokens for every sample in batch\n",
    "        #for i in range(batch_size):\n",
    "            #entity_tokens = hidden_states[i, valid_start_indices[i]]\n",
    "            #entity_representations.append(entity_tokens)\n",
    "        \n",
    "        #if epoch == 0:\n",
    "        #    print(entity_representations)\n",
    "        \n",
    "        entity_representations = torch.stack(entity_representations, dim=0)\n",
    "        \n",
    "        \n",
    "        #parent_log,\n",
    "        child_log = classifier(entity_representations)\n",
    "        child_log2 = apply_mask(child_log,parents,mask)\n",
    "        zero_ten = torch.zeros((input_ids.size(0), 22), dtype=torch.float32).to(device)\n",
    "        if debug == 0:\n",
    "            print(child_log,zero_ten,input_ids.size(0))\n",
    "            print(entity_representations.shape)\n",
    "            debug+=1\n",
    "        \n",
    "        #loss = criterion(parent_log, parents) + criterion2(child_log,labels.float()) + 2 * criterion2(child_log2,zero_ten) \n",
    "        loss = criterion2(child_log,labels.float()) + 2 * criterion2(child_log2,zero_ten)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        preds = (torch.sigmoid(child_log) > 0.15).int()\n",
    "        correct_predictions += ((preds == labels.int()).all(dim=1)).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "        #if debug == 0:\n",
    "            #print(parent_log,child_log,preds,labels)\n",
    "            #debug+=1\n",
    "        #preds_parents = torch.argmax(parent_log, dim=-1)\n",
    "        #correct_parents += (preds_parents == parents).sum().item()\n",
    "        #total_parents += labels.size(0)\n",
    "\n",
    "        train_progress_bar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "    #parent_train_acc = correct_parents / total_parents\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    #print(f\"Training loss: {avg_train_loss:.4f}, Training accuracy: {train_accuracy:.4f}, Parent Train acc: {parent_train_acc:.4f}\")\n",
    "    print(f\"Training loss: {avg_train_loss:.4f}, Training accuracy: {train_accuracy:.4f}\")\n",
    "    model.eval()\n",
    "    classifier.eval()\n",
    "    test_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    correct_parents = 0\n",
    "    total_parents = 0\n",
    "    test_progress_bar = tqdm(test_dataloader, desc=f\"Test Epoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_progress_bar:\n",
    "\n",
    "            input_ids = batch[0].to(device)\n",
    "            attention_mask = batch[1].to(device)\n",
    "            parents = batch[2].to(device)\n",
    "            labels = batch[3].to(device)\n",
    "\n",
    "            batch_size = input_ids.size(0)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=parents, output_hidden_states=True)\n",
    "\n",
    "            hidden_states = outputs.hidden_states[-1]\n",
    "\n",
    "            entity_representations = []\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                ind_start = torch.nonzero(input_ids[i] == span_start_token_id).squeeze()\n",
    "                ind_end = torch.nonzero(input_ids[i] == span_end_token_id).squeeze()\n",
    "                start_ten = hidden_states[i,ind_start]\n",
    "                end_ten = hidden_states[i,ind_end]\n",
    "                rep = torch.cat((hidden_states[i,ind_start],hidden_states[i,ind_end]),dim=0)\n",
    "                entity_representations.append(rep)\n",
    "            \n",
    "            #start_mask = (input_ids == span_start_token_id)\n",
    "            #end_mask = (input_ids == span_end_token_id)\n",
    "\n",
    "            #entity_representations = []\n",
    "\n",
    "            #start_indices = start_mask.nonzero(as_tuple=True)[1]\n",
    "            #end_indices = end_mask.nonzero(as_tuple=True)[1]\n",
    "\n",
    "            #valid_spans = (start_indices != -1) & (end_indices != -1) & (start_indices <= end_indices)\n",
    "\n",
    "            #valid_start_indices = start_indices[valid_spans]\n",
    "            #valid_end_indices = end_indices[valid_spans]\n",
    "\n",
    "            # extract entity tokens for every sample in batch\n",
    "            #for i in range(batch_size):\n",
    "            #    entity_tokens = hidden_states[i, valid_start_indices[i]]\n",
    "            #    entity_representations.append(entity_tokens)\n",
    "\n",
    "            entity_representations = torch.stack(entity_representations, dim=0)\n",
    "\n",
    "            #parent_log,\n",
    "            child_log = classifier(entity_representations)\n",
    "            child_log2 = apply_mask(child_log,parents,mask)\n",
    "            #loss = criterion(parent_log, parents) + criterion2(child_log,labels.float()) + criterion2(child_log2,labels.float()) \n",
    "            loss = criterion2(child_log,labels.float()) + 2 * criterion2(child_log2,labels.float()) \n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            preds = (torch.sigmoid(child_log) > 0.15).int()\n",
    "            correct_predictions += ((preds == labels.int()).all(dim=1)).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "\n",
    "            #preds_parents = torch.argmax(parent_log, dim=-1)\n",
    "            #correct_parents += (preds_parents == parents).sum().item()\n",
    "            #total_parents += labels.size(0)\n",
    "\n",
    "            test_progress_bar.set_postfix({'loss': loss.item()})\n",
    "            if epoch == num_epochs-1:\n",
    "                pred_list.append(preds)\n",
    "                labels_list.append(labels)\n",
    "                log_list.append(child_log)\n",
    "    \n",
    "    avg_test_loss = test_loss / len(test_dataloader)\n",
    "    test_accuracy = correct_predictions / total_predictions\n",
    "    #parent_test_accuracy = correct_parents / total_parents\n",
    "    #print(f\"Test loss: {avg_test_loss:.4f}, Test accuracy: {test_accuracy:.4f}, Parent Test accuracy: {parent_test_accuracy:.4f}\")\n",
    "    print(f\"Test loss: {avg_test_loss:.4f}, Test accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]],\n",
      "       device='cuda:0', dtype=torch.int32) tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]],\n",
      "       device='cuda:0') tensor([[-12.5301,  -8.7682, -14.7073,  -4.9099,  -9.6066,  -6.7725, -21.3646,\n",
      "         -20.9086, -13.1772, -16.6272, -12.3573, -14.4775, -15.2063, -10.4466,\n",
      "          -5.4714, -12.9967,  -3.9103, -10.7046, -11.4568, -13.2704,  -6.4669,\n",
      "          -6.6233],\n",
      "        [  2.3838, -16.1186,  -1.7525, -12.2320, -18.3047,  -3.1337, -27.4929,\n",
      "         -19.9483, -28.5764, -27.3952, -18.8542, -16.9432, -26.0950, -22.2715,\n",
      "         -25.2290, -26.9119, -25.9842, -22.2615, -24.2868, -25.5331, -17.7121,\n",
      "         -16.4041],\n",
      "        [-25.7810, -27.6654, -30.1007, -31.0613, -37.3662, -31.3366, -34.4681,\n",
      "         -21.7341, -26.9636, -26.8814, -32.2262, -36.9433, -27.9882, -36.2400,\n",
      "         -32.7626, -31.8081, -30.4692, -23.5096, -19.5012, -14.0356,  16.6161,\n",
      "         -29.8235],\n",
      "        [-17.8005, -17.6445, -13.5685, -16.5762, -12.4617, -13.2707, -10.7901,\n",
      "          -5.6205, -12.9268,   1.6031,  -6.0891, -10.0206, -12.7569,  -3.0051,\n",
      "         -10.8050, -11.0743,  -3.9175, -15.5985,  -9.1648, -11.2952, -12.5745,\n",
      "          -9.5467],\n",
      "        [ -8.7404, -14.4441,  -9.8659, -17.6213, -21.4137,  -7.6500, -27.3492,\n",
      "          -8.5914,  -4.6518, -12.1827, -13.4324,   6.7382, -19.9114, -12.6949,\n",
      "         -15.5194, -10.4930, -11.2062, -11.8689, -19.2143, -12.4209, -11.5954,\n",
      "         -11.3803],\n",
      "        [-13.8149, -24.4508,  10.4776, -16.4509, -13.6049, -11.6020, -24.3589,\n",
      "         -26.0369, -23.8048,  -8.2721, -20.0003, -24.8291, -31.4518, -22.0307,\n",
      "         -25.6824, -32.7422, -26.6807, -33.1771, -25.8188, -25.7037, -21.7983,\n",
      "         -20.1214],\n",
      "        [ -9.3168, -13.3734, -14.4739, -14.4971, -10.1474,  -6.8302, -13.4340,\n",
      "         -11.2248,  -8.8687, -12.0966,  -3.5174,  -8.7130,  -1.1159, -12.3971,\n",
      "          -2.6847,  -7.6426,  -6.7228,  -7.4376, -14.7578, -17.4228, -18.9826,\n",
      "         -13.9801],\n",
      "        [ -4.1596,  -8.2157,  -7.7486,  -4.9047,  -1.3624,  -4.4867, -10.1109,\n",
      "         -16.9209,  -6.3022, -10.2069, -11.9397, -12.8709,  -9.0459, -12.9608,\n",
      "          -7.3521, -11.1750,  -9.1606,  -8.1851, -11.6302, -10.9700,  -3.1708,\n",
      "          -6.3157],\n",
      "        [-19.0443, -21.8137, -25.8157, -26.0041, -27.1730, -18.9991, -13.1813,\n",
      "           8.9437,  -5.8778, -12.5835, -13.3972, -17.1508, -10.2629, -14.7355,\n",
      "         -15.8973, -20.4044, -18.6139, -25.1896, -23.7544, -24.5036, -35.4898,\n",
      "         -28.6306],\n",
      "        [-25.1712, -16.2430, -17.9268, -15.7118, -25.3882, -24.8184, -19.9944,\n",
      "         -20.5437, -19.9670, -20.4768, -24.0952, -19.4794, -24.3737, -18.6412,\n",
      "         -25.7990, -21.3369, -23.0679, -20.5044, -14.1724,   7.5845,  -1.5485,\n",
      "         -15.4609],\n",
      "        [ -5.5829, -28.6042, -14.7339, -10.1142, -30.9320,   5.5920, -32.1899,\n",
      "         -27.0733, -34.1183, -32.3233, -30.3088, -29.0558, -37.4280, -37.2665,\n",
      "         -50.4974, -34.9591, -26.0200, -33.4695, -31.7810, -32.7939, -23.8238,\n",
      "         -17.7583],\n",
      "        [ -5.8157, -11.5319,  -2.6721, -12.6276,  -0.8077,   0.6034, -16.7242,\n",
      "         -13.1481, -12.5315,  -9.0791,  -8.1460, -11.9689, -13.6808, -14.6754,\n",
      "          -6.0002, -17.6352,  -8.2839, -11.1945, -14.3933, -10.0286, -10.0537,\n",
      "          -9.2282],\n",
      "        [  1.3353, -26.8811,   3.5568, -18.2392, -25.2095,  -4.9659, -39.3783,\n",
      "         -33.7903, -35.4242, -34.2749, -33.1720, -34.3863, -37.1826, -34.0478,\n",
      "         -37.3273, -44.2235, -38.0808, -32.6924, -35.2503, -36.3559, -28.5254,\n",
      "         -27.3400],\n",
      "        [ -7.1916,  -8.2060, -12.1378, -15.6525, -13.1569, -12.3706,  -5.0248,\n",
      "          -8.2910,  -1.6773, -10.6365, -14.4239, -10.3734, -13.5639, -13.5749,\n",
      "         -14.6464,   0.9375, -11.9994, -10.6859, -14.5416,  -8.7179, -10.7900,\n",
      "         -12.1066],\n",
      "        [  6.4825, -13.1651, -13.5825, -18.0197, -14.7530, -15.8191, -22.8937,\n",
      "         -21.6818, -15.2931, -19.1063, -19.7872, -19.7239, -18.2636, -23.5676,\n",
      "         -16.3329,  -9.0256, -16.9995, -19.8706, -16.8794, -22.6627, -16.3582,\n",
      "         -12.7591],\n",
      "        [-30.2676, -30.8264, -33.4994, -35.1633, -38.6181, -31.8339, -41.3016,\n",
      "         -34.0723, -28.2903, -31.0672, -40.2919, -41.7483, -41.1872, -41.8766,\n",
      "         -40.7822, -36.8397, -37.9943, -33.1515, -25.4534, -13.9953,  17.1197,\n",
      "         -29.6398]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(pred_list[1],labels_list[1],log_list[1])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
