{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfQVFtXBiMWy"
   },
   "source": [
    "## Hierarchical classification using Local Classification per Parent Node technique\n",
    "Here we use the same approach as in /solutions/custom_tokens/xlm_roberta_with_classification_start_span_token.ipynb to train the first classifier to predict the first class, and we train extra three classifiers for each of those classes that will provide us fine-grained classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jYvFwavZiMW0",
    "outputId": "592f1649-ca6b-4143-fde8-96804bead382"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/matijak/Documents/programiranje/projects/semeval/merged_data/subtask1.parquet\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "wd = Path.cwd()\n",
    "wd = wd.parent.parent\n",
    "wd = wd / 'merged_data'\n",
    "sub1 = str(wd) + '/subtask1.parquet'\n",
    "print(sub1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BMEITI9CiMW2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(sub1)\n",
    "df = df[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 990
    },
    "id": "p-vczjjdjVLb",
    "outputId": "4e1bcf8a-2ba7-462c-db34-32a1f15d7357"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>art_name</th>\n",
       "      <th>entity</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>class1</th>\n",
       "      <th>classes2</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_670.txt</td>\n",
       "      <td>Запад</td>\n",
       "      <td>152</td>\n",
       "      <td>156</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Conspirator, Instigator, Foreign Adversary]</td>\n",
       "      <td>Опитът на колективния Запад да „обезкърви Руси...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_670.txt</td>\n",
       "      <td>САЩ</td>\n",
       "      <td>530</td>\n",
       "      <td>532</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Instigator]</td>\n",
       "      <td>Опитът на колективния Запад да „обезкърви Руси...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_670.txt</td>\n",
       "      <td>НАТО</td>\n",
       "      <td>535</td>\n",
       "      <td>538</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Instigator]</td>\n",
       "      <td>Опитът на колективния Запад да „обезкърви Руси...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_670.txt</td>\n",
       "      <td>Украйна</td>\n",
       "      <td>578</td>\n",
       "      <td>584</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Foreign Adversary]</td>\n",
       "      <td>Опитът на колективния Запад да „обезкърви Руси...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_670.txt</td>\n",
       "      <td>украински войници</td>\n",
       "      <td>633</td>\n",
       "      <td>649</td>\n",
       "      <td>Innocent</td>\n",
       "      <td>[Victim]</td>\n",
       "      <td>Опитът на колективния Запад да „обезкърви Руси...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BG</td>\n",
       "      <td>A9_BG_5871.txt</td>\n",
       "      <td>Москва</td>\n",
       "      <td>327</td>\n",
       "      <td>332</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Terrorist]</td>\n",
       "      <td>Зверство! Руснаците започнаха да режат глави н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BG</td>\n",
       "      <td>A9_BG_5190.txt</td>\n",
       "      <td>Киев</td>\n",
       "      <td>447</td>\n",
       "      <td>450</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Terrorist]</td>\n",
       "      <td>Дмитрий Медведев: НПО-та, спонсорирани от Соро...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BG</td>\n",
       "      <td>A9_BG_3182.txt</td>\n",
       "      <td>Молдова</td>\n",
       "      <td>92</td>\n",
       "      <td>98</td>\n",
       "      <td>Innocent</td>\n",
       "      <td>[Exploited]</td>\n",
       "      <td>Западът подготвя за Молдова ролята на \"консума...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BG</td>\n",
       "      <td>A9_BG_3182.txt</td>\n",
       "      <td>НАТО</td>\n",
       "      <td>1085</td>\n",
       "      <td>1088</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Conspirator]</td>\n",
       "      <td>Западът подготвя за Молдова ролята на \"консума...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BG</td>\n",
       "      <td>A9_BG_3182.txt</td>\n",
       "      <td>Запада</td>\n",
       "      <td>1361</td>\n",
       "      <td>1366</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Foreign Adversary]</td>\n",
       "      <td>Западът подготвя за Молдова ролята на \"консума...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BG</td>\n",
       "      <td>A9_BG_3379.txt</td>\n",
       "      <td>Запада</td>\n",
       "      <td>108</td>\n",
       "      <td>113</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Instigator, Foreign Adversary]</td>\n",
       "      <td>Британски дипломат обвини Запада за украинския...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BG</td>\n",
       "      <td>A9_BG_3379.txt</td>\n",
       "      <td>Лондон</td>\n",
       "      <td>625</td>\n",
       "      <td>630</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Tyrant]</td>\n",
       "      <td>Британски дипломат обвини Запада за украинския...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BG</td>\n",
       "      <td>A9_BG_3379.txt</td>\n",
       "      <td>Русия</td>\n",
       "      <td>656</td>\n",
       "      <td>660</td>\n",
       "      <td>Innocent</td>\n",
       "      <td>[Victim]</td>\n",
       "      <td>Британски дипломат обвини Запада за украинския...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_855.txt</td>\n",
       "      <td>Руската федерация</td>\n",
       "      <td>1453</td>\n",
       "      <td>1469</td>\n",
       "      <td>Protagonist</td>\n",
       "      <td>[Virtuous, Guardian]</td>\n",
       "      <td>Русия забрани разпространението на десетки мед...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_855.txt</td>\n",
       "      <td>ЕС</td>\n",
       "      <td>1631</td>\n",
       "      <td>1632</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Deceiver]</td>\n",
       "      <td>Русия забрани разпространението на десетки мед...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_561.txt</td>\n",
       "      <td>ЕС</td>\n",
       "      <td>213</td>\n",
       "      <td>214</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Corrupt]</td>\n",
       "      <td>Вратички на Борел за дефрагментиране на Европа...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_561.txt</td>\n",
       "      <td>Унгария</td>\n",
       "      <td>717</td>\n",
       "      <td>723</td>\n",
       "      <td>Protagonist</td>\n",
       "      <td>[Virtuous]</td>\n",
       "      <td>Вратички на Борел за дефрагментиране на Европа...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_751.txt</td>\n",
       "      <td>Путин</td>\n",
       "      <td>345</td>\n",
       "      <td>349</td>\n",
       "      <td>Protagonist</td>\n",
       "      <td>[Virtuous]</td>\n",
       "      <td>US военен: Путин ни изигра така, както Рейгън ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_751.txt</td>\n",
       "      <td>Зеленски</td>\n",
       "      <td>509</td>\n",
       "      <td>516</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Incompetent]</td>\n",
       "      <td>US военен: Путин ни изигра така, както Рейгън ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_751.txt</td>\n",
       "      <td>Украйна</td>\n",
       "      <td>1594</td>\n",
       "      <td>1600</td>\n",
       "      <td>Innocent</td>\n",
       "      <td>[Exploited]</td>\n",
       "      <td>US военен: Путин ни изигра така, както Рейгън ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_751.txt</td>\n",
       "      <td>Путин</td>\n",
       "      <td>1797</td>\n",
       "      <td>1801</td>\n",
       "      <td>Protagonist</td>\n",
       "      <td>[Peacemaker]</td>\n",
       "      <td>US военен: Путин ни изигра така, както Рейгън ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_751.txt</td>\n",
       "      <td>Зеленски</td>\n",
       "      <td>1940</td>\n",
       "      <td>1947</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Corrupt]</td>\n",
       "      <td>US военен: Путин ни изигра така, както Рейгън ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_751.txt</td>\n",
       "      <td>Западът</td>\n",
       "      <td>1951</td>\n",
       "      <td>1957</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Conspirator, Foreign Adversary]</td>\n",
       "      <td>US военен: Путин ни изигра така, както Рейгън ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_839.txt</td>\n",
       "      <td>Кремъл</td>\n",
       "      <td>62</td>\n",
       "      <td>67</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Tyrant]</td>\n",
       "      <td>Посланикът на САЩ: България вече не е лесна ми...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_839.txt</td>\n",
       "      <td>Путин</td>\n",
       "      <td>123</td>\n",
       "      <td>127</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Tyrant]</td>\n",
       "      <td>Посланикът на САЩ: България вече не е лесна ми...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_839.txt</td>\n",
       "      <td>Украйна</td>\n",
       "      <td>199</td>\n",
       "      <td>205</td>\n",
       "      <td>Innocent</td>\n",
       "      <td>[Victim]</td>\n",
       "      <td>Посланикът на САЩ: България вече не е лесна ми...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_839.txt</td>\n",
       "      <td>Европа</td>\n",
       "      <td>517</td>\n",
       "      <td>522</td>\n",
       "      <td>Protagonist</td>\n",
       "      <td>[Guardian]</td>\n",
       "      <td>Посланикът на САЩ: България вече не е лесна ми...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_839.txt</td>\n",
       "      <td>България</td>\n",
       "      <td>1091</td>\n",
       "      <td>1098</td>\n",
       "      <td>Protagonist</td>\n",
       "      <td>[Virtuous]</td>\n",
       "      <td>Посланикът на САЩ: България вече не е лесна ми...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_839.txt</td>\n",
       "      <td>Володимир Зеленски</td>\n",
       "      <td>1138</td>\n",
       "      <td>1155</td>\n",
       "      <td>Protagonist</td>\n",
       "      <td>[Peacemaker]</td>\n",
       "      <td>Посланикът на САЩ: България вече не е лесна ми...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_839.txt</td>\n",
       "      <td>Китай</td>\n",
       "      <td>1332</td>\n",
       "      <td>1336</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Foreign Adversary]</td>\n",
       "      <td>Посланикът на САЩ: България вече не е лесна ми...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lang        art_name              entity start   end       class1  \\\n",
       "0    BG      BG_670.txt               Запад   152   156   Antagonist   \n",
       "1    BG      BG_670.txt                 САЩ   530   532   Antagonist   \n",
       "2    BG      BG_670.txt                НАТО   535   538   Antagonist   \n",
       "3    BG      BG_670.txt             Украйна   578   584   Antagonist   \n",
       "4    BG      BG_670.txt   украински войници   633   649     Innocent   \n",
       "5    BG  A9_BG_5871.txt              Москва   327   332   Antagonist   \n",
       "6    BG  A9_BG_5190.txt                Киев   447   450   Antagonist   \n",
       "7    BG  A9_BG_3182.txt             Молдова    92    98     Innocent   \n",
       "8    BG  A9_BG_3182.txt                НАТО  1085  1088   Antagonist   \n",
       "9    BG  A9_BG_3182.txt              Запада  1361  1366   Antagonist   \n",
       "10   BG  A9_BG_3379.txt              Запада   108   113   Antagonist   \n",
       "11   BG  A9_BG_3379.txt              Лондон   625   630   Antagonist   \n",
       "12   BG  A9_BG_3379.txt               Русия   656   660     Innocent   \n",
       "13   BG      BG_855.txt   Руската федерация  1453  1469  Protagonist   \n",
       "14   BG      BG_855.txt                  ЕС  1631  1632   Antagonist   \n",
       "15   BG      BG_561.txt                  ЕС   213   214   Antagonist   \n",
       "16   BG      BG_561.txt             Унгария   717   723  Protagonist   \n",
       "17   BG      BG_751.txt               Путин   345   349  Protagonist   \n",
       "18   BG      BG_751.txt            Зеленски   509   516   Antagonist   \n",
       "19   BG      BG_751.txt             Украйна  1594  1600     Innocent   \n",
       "20   BG      BG_751.txt               Путин  1797  1801  Protagonist   \n",
       "21   BG      BG_751.txt            Зеленски  1940  1947   Antagonist   \n",
       "22   BG      BG_751.txt             Западът  1951  1957   Antagonist   \n",
       "23   BG      BG_839.txt              Кремъл    62    67   Antagonist   \n",
       "24   BG      BG_839.txt               Путин   123   127   Antagonist   \n",
       "25   BG      BG_839.txt             Украйна   199   205     Innocent   \n",
       "26   BG      BG_839.txt              Европа   517   522  Protagonist   \n",
       "27   BG      BG_839.txt            България  1091  1098  Protagonist   \n",
       "28   BG      BG_839.txt  Володимир Зеленски  1138  1155  Protagonist   \n",
       "29   BG      BG_839.txt               Китай  1332  1336   Antagonist   \n",
       "\n",
       "                                        classes2  \\\n",
       "0   [Conspirator, Instigator, Foreign Adversary]   \n",
       "1                                   [Instigator]   \n",
       "2                                   [Instigator]   \n",
       "3                            [Foreign Adversary]   \n",
       "4                                       [Victim]   \n",
       "5                                    [Terrorist]   \n",
       "6                                    [Terrorist]   \n",
       "7                                    [Exploited]   \n",
       "8                                  [Conspirator]   \n",
       "9                            [Foreign Adversary]   \n",
       "10               [Instigator, Foreign Adversary]   \n",
       "11                                      [Tyrant]   \n",
       "12                                      [Victim]   \n",
       "13                          [Virtuous, Guardian]   \n",
       "14                                    [Deceiver]   \n",
       "15                                     [Corrupt]   \n",
       "16                                    [Virtuous]   \n",
       "17                                    [Virtuous]   \n",
       "18                                 [Incompetent]   \n",
       "19                                   [Exploited]   \n",
       "20                                  [Peacemaker]   \n",
       "21                                     [Corrupt]   \n",
       "22              [Conspirator, Foreign Adversary]   \n",
       "23                                      [Tyrant]   \n",
       "24                                      [Tyrant]   \n",
       "25                                      [Victim]   \n",
       "26                                    [Guardian]   \n",
       "27                                    [Virtuous]   \n",
       "28                                  [Peacemaker]   \n",
       "29                           [Foreign Adversary]   \n",
       "\n",
       "                                                 text  \n",
       "0   Опитът на колективния Запад да „обезкърви Руси...  \n",
       "1   Опитът на колективния Запад да „обезкърви Руси...  \n",
       "2   Опитът на колективния Запад да „обезкърви Руси...  \n",
       "3   Опитът на колективния Запад да „обезкърви Руси...  \n",
       "4   Опитът на колективния Запад да „обезкърви Руси...  \n",
       "5   Зверство! Руснаците започнаха да режат глави н...  \n",
       "6   Дмитрий Медведев: НПО-та, спонсорирани от Соро...  \n",
       "7   Западът подготвя за Молдова ролята на \"консума...  \n",
       "8   Западът подготвя за Молдова ролята на \"консума...  \n",
       "9   Западът подготвя за Молдова ролята на \"консума...  \n",
       "10  Британски дипломат обвини Запада за украинския...  \n",
       "11  Британски дипломат обвини Запада за украинския...  \n",
       "12  Британски дипломат обвини Запада за украинския...  \n",
       "13  Русия забрани разпространението на десетки мед...  \n",
       "14  Русия забрани разпространението на десетки мед...  \n",
       "15  Вратички на Борел за дефрагментиране на Европа...  \n",
       "16  Вратички на Борел за дефрагментиране на Европа...  \n",
       "17  US военен: Путин ни изигра така, както Рейгън ...  \n",
       "18  US военен: Путин ни изигра така, както Рейгън ...  \n",
       "19  US военен: Путин ни изигра така, както Рейгън ...  \n",
       "20  US военен: Путин ни изигра така, както Рейгън ...  \n",
       "21  US военен: Путин ни изигра така, както Рейгън ...  \n",
       "22  US военен: Путин ни изигра така, както Рейгън ...  \n",
       "23  Посланикът на САЩ: България вече не е лесна ми...  \n",
       "24  Посланикът на САЩ: България вече не е лесна ми...  \n",
       "25  Посланикът на САЩ: България вече не е лесна ми...  \n",
       "26  Посланикът на САЩ: България вече не е лесна ми...  \n",
       "27  Посланикът на САЩ: България вече не е лесна ми...  \n",
       "28  Посланикът на САЩ: България вече не е лесна ми...  \n",
       "29  Посланикът на САЩ: България вече не е лесна ми...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ozEIv93FiMW3"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def labelNum(row):\n",
    "    if row['class1'] == 'Antagonist':\n",
    "        return int(0)\n",
    "    if row['class1'] == 'Innocent':\n",
    "        return int(1)\n",
    "    if row['class1'] == 'Protagonist':\n",
    "        return int(2)\n",
    "def cleanText(row):\n",
    "    text = str(row['text'])\n",
    "    #text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = text.replace('\\n',' ').replace('  ', ' ')\n",
    "    return text\n",
    "df['label1'] = df.apply(labelNum,axis=1)\n",
    "df['input'] = df.apply(cleanText,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xeWF5364tCxB",
    "outputId": "fc222c53-b674-4039-af99-69d30d86d9d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label1'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "KMBg9PYVjdzw"
   },
   "outputs": [],
   "source": [
    "def labelNum2(row):\n",
    "    labels2 = [0 for _ in range(12)]\n",
    "    if row['label1'] == 2:\n",
    "        #labels2 = [0 for _ in range(6)]\n",
    "        if 'Guardian' in row['classes2']:\n",
    "            labels2[0] = 1\n",
    "        if 'Martyr' in row['classes2']:\n",
    "            labels2[1] = 1\n",
    "        if 'Peacemaker' in row['classes2']:\n",
    "            labels2[2] = 1\n",
    "        if 'Rebel' in row['classes2']:\n",
    "            labels2[3] = 1\n",
    "        if 'Underdog' in row['classes2']:\n",
    "            labels2[4] = 1\n",
    "        if 'Virtuous' in row['classes2']:\n",
    "            labels2[5] = 1\n",
    "    elif row['label1'] == 0:\n",
    "        #labels2 = [0 for _ in range(12)]\n",
    "        if 'Instigator' in row['classes2']:\n",
    "           labels2[0] = 1\n",
    "        if 'Conspirator' in row['classes2']:\n",
    "            labels2[1] = 1\n",
    "        if 'Tyrant' in row['classes2']:\n",
    "            labels2[2] = 1\n",
    "        if  'Foreign Adversary' in row['classes2']:\n",
    "            labels2[3] = 1\n",
    "        if 'Traitor' in row['classes2']:\n",
    "            labels2[4] = 1\n",
    "        if 'Spy' in row['classes2']:\n",
    "            labels2[5] = 1\n",
    "        if 'Saboteur' in row['classes2']:\n",
    "            labels2[6] = 1\n",
    "        if 'Corrupt' in row['classes2']:\n",
    "            labels2[7] = 1\n",
    "        if 'Incompetent' in row['classes2']:\n",
    "            labels2[8] = 1\n",
    "        if 'Terrorist' in row['classes2']:\n",
    "            labels2[9] = 1\n",
    "        if 'Deceiver' in row['classes2']:\n",
    "            labels2[10] = 1\n",
    "        if 'Bigot' in row['classes2']:\n",
    "            labels2[11] = 1\n",
    "    elif row['label1'] == 1:\n",
    "        #labels2 = [0 for _ in range(4)]\n",
    "        if 'Forgotten' in row['classes2']:\n",
    "            labels2[0] = 1\n",
    "        if 'Exploited' in row['classes2']:\n",
    "            labels2[1] = 1\n",
    "        if 'Victim' in row['classes2']:\n",
    "            labels2[2] = 1\n",
    "        if 'Scapegoat' in row['classes2']:\n",
    "            labels2[3] = 1\n",
    "    return labels2\n",
    "\n",
    "df['label2'] = df.apply(labelNum2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bnshZfqsiMW4",
    "outputId": "37f0e788-7c39-41ff-bbb5-1b466fcc9a70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang                                                            BG\n",
      "art_name                                                BG_670.txt\n",
      "entity                                                       Запад\n",
      "start                                                          152\n",
      "end                                                            156\n",
      "class1                                                  Antagonist\n",
      "classes2              [Conspirator, Instigator, Foreign Adversary]\n",
      "text             Опитът на колективния Запад да „обезкърви Руси...\n",
      "label1                                                           0\n",
      "input            Опитът на колективния Запад да „обезкърви Руси...\n",
      "label2                        [1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "new_start_end                                           (151, 156)\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def find_all_substring_start_end(text, substring):\n",
    "    # Use re.finditer to find all occurrences of the substring in the text\n",
    "    matches = re.finditer(re.escape(substring), text)\n",
    "\n",
    "    # Collect the start and end indices of all matches\n",
    "    positions = [(match.start(), match.end()) for match in matches]\n",
    "\n",
    "    return positions\n",
    "def adjust_start_end(row):\n",
    "    org_text,cl_text,start,end,entity = str(row['text']),str(row['input']),int(row['start']),int(row['end']),str(row['entity'])\n",
    "    ss1 = find_all_substring_start_end(org_text,entity)\n",
    "    ss2 = find_all_substring_start_end(cl_text,entity)\n",
    "    #print(ss1,ss2)\n",
    "    #print(row['text'][start:end])\n",
    "    a = 0\n",
    "    for i in range(len(ss1)):\n",
    "        if abs((ss1[i][0] - start) + (ss1[i][1] - end) ) <= 2:\n",
    "            a = i\n",
    "            break\n",
    "    if org_text[ss1[a][0]:ss1[a][1]] != cl_text[ss2[a][0]:ss2[a][1]]:\n",
    "        print(\"ERROR!\")\n",
    "    return ss2[a][0],ss2[a][1]\n",
    "df['new_start_end'] = df.apply(adjust_start_end,axis=1)\n",
    "print(df.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "s-PdTAcViMW5"
   },
   "outputs": [],
   "source": [
    "def addTokensToInput(row):\n",
    "    inp = row['input']\n",
    "    start,end = row['new_start_end']\n",
    "    #print(start,end)\n",
    "    start = int(start)\n",
    "    end = int(end)\n",
    "    token_input = inp[:start] + \"[SPAN_START] \" + inp[start:end] + \" [SPAN_END]\" + inp[end:]\n",
    "    return token_input\n",
    "\n",
    "df['span_input'] = df.apply(addTokensToInput,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "yobaQPRoiMW5"
   },
   "outputs": [],
   "source": [
    "def upStartEnd(row):\n",
    "    start,end = row['new_start_end']\n",
    "    start += len(\"[SPAN_START] \")\n",
    "    end += len(\"[SPAN_START] \")\n",
    "    return start,end\n",
    "\n",
    "df['new_start_end'] = df.apply(upStartEnd,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PwT_XHKmiMW5",
    "outputId": "46f2691e-4da3-4900-d554-fa6e3416d8cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizerFast\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-base\", num_labels=3).to(device)\n",
    "tokenizer = XLMRobertaTokenizerFast.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['span_input'], padding=True, truncation=True,max_length=8192,return_offsets_mapping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nZDwWW9hiMW6",
    "outputId": "bfcc0500-36e9-410a-c4d0-5533faaccf59"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(250004, 768, padding_idx=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraTokens = {\n",
    "    \"additional_special_tokens\": [\"[SPAN_START]\", \"[SPAN_END]\"]\n",
    "}\n",
    "num_added_toks = tokenizer.add_special_tokens(extraTokens)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "gMWI8j1ZiMW6"
   },
   "outputs": [],
   "source": [
    "data = df.loc[ : , ['span_input', 'label1', 'label2', 'new_start_end', 'entity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 990
    },
    "id": "7eq2PO4ngplD",
    "outputId": "0f9dbad7-5637-4864-fcd3-6f5127eb66af"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>span_input</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>new_start_end</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Опитът на колективния Запад да „обезкърви Руси...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(164, 169)</td>\n",
       "      <td>Запад</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Опитът на колективния Запад да „обезкърви Руси...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(541, 544)</td>\n",
       "      <td>САЩ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Опитът на колективния Запад да „обезкърви Руси...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(546, 550)</td>\n",
       "      <td>НАТО</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Опитът на колективния Запад да „обезкърви Руси...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(589, 596)</td>\n",
       "      <td>Украйна</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Опитът на колективния Запад да „обезкърви Руси...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(644, 661)</td>\n",
       "      <td>украински войници</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Зверство! Руснаците започнаха да режат глави н...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>(339, 345)</td>\n",
       "      <td>Москва</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Дмитрий Медведев: НПО-та, спонсорирани от Соро...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>(459, 463)</td>\n",
       "      <td>Киев</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Западът подготвя за Молдова ролята на \"консума...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(104, 111)</td>\n",
       "      <td>Молдова</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Западът подготвя за Молдова ролята на \"консума...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(1097, 1101)</td>\n",
       "      <td>НАТО</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Западът подготвя за Молдова ролята на \"консума...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(1373, 1379)</td>\n",
       "      <td>Запада</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Британски дипломат обвини Запада за украинския...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(120, 126)</td>\n",
       "      <td>Запада</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Британски дипломат обвини Запада за украинския...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(637, 643)</td>\n",
       "      <td>Лондон</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Британски дипломат обвини Запада за украинския...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(668, 673)</td>\n",
       "      <td>Русия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Русия забрани разпространението на десетки мед...</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(1458, 1475)</td>\n",
       "      <td>Руската федерация</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Русия забрани разпространението на десетки мед...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>(65, 67)</td>\n",
       "      <td>ЕС</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Вратички на Борел за дефрагментиране на Европа...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>(225, 227)</td>\n",
       "      <td>ЕС</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Вратички на Борел за дефрагментиране на Европа...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(729, 736)</td>\n",
       "      <td>Унгария</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>US военен: Путин ни изигра така, както Рейгън ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(356, 361)</td>\n",
       "      <td>Путин</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>US военен: Путин ни изигра така, както Рейгън ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>(520, 528)</td>\n",
       "      <td>Зеленски</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>US военен: Путин ни изигра така, както Рейгън ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(1602, 1609)</td>\n",
       "      <td>Украйна</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>US военен: [SPAN_START] Путин [SPAN_END] ни из...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(24, 29)</td>\n",
       "      <td>Путин</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>US военен: Путин ни изигра така, както Рейгън ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>(520, 528)</td>\n",
       "      <td>Зеленски</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>US военен: Путин ни изигра така, както Рейгън ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(1958, 1965)</td>\n",
       "      <td>Западът</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Посланикът на САЩ: България вече не е лесна ми...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(74, 80)</td>\n",
       "      <td>Кремъл</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Посланикът на САЩ: България вече не е лесна ми...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(135, 140)</td>\n",
       "      <td>Путин</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Посланикът на САЩ: България вече не е лесна ми...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(211, 218)</td>\n",
       "      <td>Украйна</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Посланикът на САЩ: България вече не е лесна ми...</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(529, 535)</td>\n",
       "      <td>Европа</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Посланикът на САЩ: България вече не е лесна ми...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(1103, 1111)</td>\n",
       "      <td>България</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Посланикът на САЩ: България вече не е лесна ми...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(1150, 1168)</td>\n",
       "      <td>Володимир Зеленски</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Посланикът на САЩ: България вече не е лесна ми...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(1344, 1349)</td>\n",
       "      <td>Китай</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           span_input  label1  \\\n",
       "0   Опитът на колективния Запад да „обезкърви Руси...       0   \n",
       "1   Опитът на колективния Запад да „обезкърви Руси...       0   \n",
       "2   Опитът на колективния Запад да „обезкърви Руси...       0   \n",
       "3   Опитът на колективния Запад да „обезкърви Руси...       0   \n",
       "4   Опитът на колективния Запад да „обезкърви Руси...       1   \n",
       "5   Зверство! Руснаците започнаха да режат глави н...       0   \n",
       "6   Дмитрий Медведев: НПО-та, спонсорирани от Соро...       0   \n",
       "7   Западът подготвя за Молдова ролята на \"консума...       1   \n",
       "8   Западът подготвя за Молдова ролята на \"консума...       0   \n",
       "9   Западът подготвя за Молдова ролята на \"консума...       0   \n",
       "10  Британски дипломат обвини Запада за украинския...       0   \n",
       "11  Британски дипломат обвини Запада за украинския...       0   \n",
       "12  Британски дипломат обвини Запада за украинския...       1   \n",
       "13  Русия забрани разпространението на десетки мед...       2   \n",
       "14  Русия забрани разпространението на десетки мед...       0   \n",
       "15  Вратички на Борел за дефрагментиране на Европа...       0   \n",
       "16  Вратички на Борел за дефрагментиране на Европа...       2   \n",
       "17  US военен: Путин ни изигра така, както Рейгън ...       2   \n",
       "18  US военен: Путин ни изигра така, както Рейгън ...       0   \n",
       "19  US военен: Путин ни изигра така, както Рейгън ...       1   \n",
       "20  US военен: [SPAN_START] Путин [SPAN_END] ни из...       2   \n",
       "21  US военен: Путин ни изигра така, както Рейгън ...       0   \n",
       "22  US военен: Путин ни изигра така, както Рейгън ...       0   \n",
       "23  Посланикът на САЩ: България вече не е лесна ми...       0   \n",
       "24  Посланикът на САЩ: България вече не е лесна ми...       0   \n",
       "25  Посланикът на САЩ: България вече не е лесна ми...       1   \n",
       "26  Посланикът на САЩ: България вече не е лесна ми...       2   \n",
       "27  Посланикът на САЩ: България вече не е лесна ми...       2   \n",
       "28  Посланикът на САЩ: България вече не е лесна ми...       2   \n",
       "29  Посланикът на САЩ: България вече не е лесна ми...       0   \n",
       "\n",
       "                                  label2 new_start_end              entity  \n",
       "0   [1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]    (164, 169)               Запад  \n",
       "1   [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]    (541, 544)                 САЩ  \n",
       "2   [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]    (546, 550)                НАТО  \n",
       "3   [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]    (589, 596)             Украйна  \n",
       "4   [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]    (644, 661)   украински войници  \n",
       "5   [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]    (339, 345)              Москва  \n",
       "6   [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]    (459, 463)                Киев  \n",
       "7   [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]    (104, 111)             Молдова  \n",
       "8   [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  (1097, 1101)                НАТО  \n",
       "9   [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  (1373, 1379)              Запада  \n",
       "10  [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]    (120, 126)              Запада  \n",
       "11  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]    (637, 643)              Лондон  \n",
       "12  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]    (668, 673)               Русия  \n",
       "13  [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]  (1458, 1475)   Руската федерация  \n",
       "14  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]      (65, 67)                  ЕС  \n",
       "15  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]    (225, 227)                  ЕС  \n",
       "16  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]    (729, 736)             Унгария  \n",
       "17  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]    (356, 361)               Путин  \n",
       "18  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]    (520, 528)            Зеленски  \n",
       "19  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  (1602, 1609)             Украйна  \n",
       "20  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]      (24, 29)               Путин  \n",
       "21  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]    (520, 528)            Зеленски  \n",
       "22  [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  (1958, 1965)             Западът  \n",
       "23  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]      (74, 80)              Кремъл  \n",
       "24  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]    (135, 140)               Путин  \n",
       "25  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]    (211, 218)             Украйна  \n",
       "26  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]    (529, 535)              Европа  \n",
       "27  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]  (1103, 1111)            България  \n",
       "28  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  (1150, 1168)  Володимир Зеленски  \n",
       "29  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  (1344, 1349)               Китай  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Y4ncpV6fgpWZ"
   },
   "outputs": [],
   "source": [
    "data['tokenized']=data.apply(preprocess_function,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "cBcBQZegiMW7"
   },
   "outputs": [],
   "source": [
    "def indexes(row):\n",
    "    off_mask = row['tokenized']['offset_mapping']\n",
    "    start,end = row['new_start_end'][0],row['new_start_end'][1]\n",
    "    inds = list()\n",
    "    for p in range(len(off_mask)):\n",
    "        if off_mask[p][0] >= start and off_mask[p][1] <= end:\n",
    "            if p != len(off_mask)-1:\n",
    "                inds.append(p)\n",
    "    #if len(inds) > 1:\n",
    "        #print(\"GREATER THAN 1\")\n",
    "    if len(inds) == 0:\n",
    "        print(start,end)\n",
    "    return inds\n",
    "data['indexes'] = data.apply(indexes,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uwd1VtkRiMW8",
    "outputId": "a0485222-2434-4905-a8f7-2b4d51657005"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30\n"
     ]
    }
   ],
   "source": [
    "data['list'] = data['tokenized'].apply(lambda x: x['input_ids'])\n",
    "data['attention'] = data['tokenized'].apply(lambda x: x['attention_mask'])\n",
    "ids = data['list']\n",
    "att = data['attention']\n",
    "indexes = data['indexes']\n",
    "tids = list()\n",
    "tatt = list()\n",
    "print(len(ids),len(att),len(indexes))\n",
    "for i in range(len(ids)):\n",
    "    tids.append(torch.tensor(ids[i]))\n",
    "    tatt.append(torch.tensor(att[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Hawj2WEWiMW8"
   },
   "outputs": [],
   "source": [
    "sliced_ids = list()\n",
    "sliced_ntids = list()\n",
    "sliced_att = list()\n",
    "key_inds = list()\n",
    "key_ids = list()\n",
    "\n",
    "def slices(index,size,context_size):\n",
    "    if (size<context_size):\n",
    "        return 0,size\n",
    "    lower_c = int(context_size/2-1)\n",
    "    upper_c = int(context_size/2)\n",
    "    #print(lower_c,upper_c)\n",
    "    if index < lower_c:\n",
    "        return 0,context_size\n",
    "    elif index >= lower_c:\n",
    "        if index + upper_c > size:\n",
    "            return index-(context_size-(size-index)), size\n",
    "        else:\n",
    "            return index-lower_c,index+upper_c+1\n",
    "\n",
    "\n",
    "for i in range(len(tids)):\n",
    "    slower,supper = slices(indexes[i][0],len(tids[i]),510)\n",
    "    #key_tid = tids[i][indexes[i][0]]\n",
    "    pid = ids[i][slower:supper]\n",
    "    key_inds.append([])\n",
    "    for j in indexes[i]:\n",
    "        key_id = ids[i][j]\n",
    "        if key_id not in pid:\n",
    "           print(len(ids[i]),key_id,slower,supper,indexes[i])\n",
    "        key_inds[i].append(pid.index(key_id))\n",
    "    apid = tids[i][slower:supper]\n",
    "    apatt = tatt[i][slower:supper]\n",
    "    if 0 not in pid:\n",
    "        apid = torch.cat((torch.tensor([0]),apid),dim=0)\n",
    "        apatt = torch.cat((torch.tensor([1]),apatt),dim=0)\n",
    "    if 2 not in pid:\n",
    "        apid = torch.cat((apid,torch.tensor([2])),dim=0)\n",
    "        apatt = torch.cat((apatt,torch.tensor([1])),dim=0)\n",
    "    sliced_ids.append(apid)\n",
    "    sliced_att.append(apatt)\n",
    "\n",
    "Min = 10000\n",
    "Max = 0\n",
    "ind2 = 0\n",
    "for i in range(len(indexes)):\n",
    "    if len(sliced_ids[i]) < Min:\n",
    "        Min = len(sliced_ids[i])\n",
    "        ind2 = i\n",
    "\n",
    "    if len(sliced_ids[i]) > Max:\n",
    "        Max = len(sliced_ids[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "xFCUO_GXiMW8"
   },
   "outputs": [],
   "source": [
    "input_ids = list()\n",
    "att_mask = list()\n",
    "for ten,att in zip(sliced_ids,sliced_att):\n",
    "    if len(ten) < 512:\n",
    "        padding_length = 512 - len(ten)\n",
    "        padding_tensor = torch.full((padding_length,), tokenizer.pad_token_id, dtype=ten.dtype)\n",
    "        padding_tensor2 = torch.full((padding_length,), 0, dtype=att.dtype)\n",
    "        ten = torch.cat((ten,padding_tensor),dim=0)\n",
    "        att = torch.cat((att,padding_tensor2),dim=0)\n",
    "    input_ids.append(ten)\n",
    "    att_mask.append(att)\n",
    "inputIds = torch.stack(input_ids)\n",
    "attMask = torch.stack(att_mask)\n",
    "\n",
    "inputIds_np = inputIds.numpy()\n",
    "attMask_np = attMask.numpy()\n",
    "y1 = data['label1'].values\n",
    "y2 = data['label2'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "sZvBhiA-iMW8"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_ids, X_test_ids, X_train_mask, X_test_mask, y1_train, y1_test, y2_train, y2_test = train_test_split(\n",
    "    inputIds_np, attMask_np, y1, y2, test_size=0.2, random_state=42, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "2nVj2Hns2OyK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y2_train = np.array(y2_train.tolist(), dtype=np.int8)\n",
    "y2_test = np.array(y2_test.tolist(), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "2Nos0gEBiMW8"
   },
   "outputs": [],
   "source": [
    "X_train_ids = torch.tensor(X_train_ids, dtype=torch.long).to(device)\n",
    "X_test_ids = torch.tensor(X_test_ids, dtype=torch.long).to(device)\n",
    "X_train_mask = torch.tensor(X_train_mask, dtype=torch.long).to(device)\n",
    "X_test_mask = torch.tensor(X_test_mask, dtype=torch.long).to(device)\n",
    "y1_train = torch.tensor(y1_train, dtype=torch.long).to(device)\n",
    "y1_test = torch.tensor(y1_test, dtype=torch.long).to(device)\n",
    "y2_train = torch.tensor(y2_train, dtype=torch.long).to(device)\n",
    "y2_test = torch.tensor(y2_test, dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "GTxQJLCliMW9"
   },
   "outputs": [],
   "source": [
    "# Create TensorDatasets\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(X_train_ids, X_train_mask, y1_train, y2_train)\n",
    "test_dataset = TensorDataset(X_test_ids, X_test_mask, y1_test, y2_test )\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "YES435MWiMW9"
   },
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "\n",
    "#first layer classifier\n",
    "classifier = nn.Linear(model.config.hidden_size, 3).to(device)\n",
    "#optimizer = AdamW(list(classifier.parameters()) + list(model.parameters()), lr=8e-6)\n",
    "optimizer = AdamW(classifier.parameters(), lr=8e-6)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "OLjIgbw0DCrf"
   },
   "outputs": [],
   "source": [
    "# not used?\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2., alpha=0.25, num_classes=3):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.num_classes = num_classes\n",
    "        self.cross_entropy_loss = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = self.cross_entropy_loss(inputs, targets)\n",
    "        p_t = torch.exp(-ce_loss)  # Probability of correct class\n",
    "        focal_loss = self.alpha * (1 - p_t) ** self.gamma * ce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "#criterion = FocalLoss(gamma=2., alpha=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "FYpTCF0dvTle"
   },
   "outputs": [],
   "source": [
    "# second layer classifier model\n",
    "# class SecondLayerClassifier(nn.Module):\n",
    "#     def __init__(self, input_dim, num_classes):\n",
    "#         super(SecondLayerClassifier, self).__init__()\n",
    "#         self.fc = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return torch.sigmoid(self.fc(x))\n",
    "\n",
    "criterion2 = nn.BCEWithLogitsLoss()\n",
    "\n",
    "class SecondLayerClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, num_classes, dropout_prob=0.3):\n",
    "        \"\"\"\n",
    "        Multi-layer classifier for second-layer classification.\n",
    "\n",
    "        Args:\n",
    "            input_dim (int): Dimension of the input features.\n",
    "            hidden_dims (list of int): List of hidden layer dimensions.\n",
    "            num_classes (int): Number of output classes.\n",
    "            dropout_prob (float): Dropout probability (default: 0.3).\n",
    "        \"\"\"\n",
    "        super(SecondLayerClassifier, self).__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        layers = []\n",
    "        current_dim = input_dim\n",
    "\n",
    "        # Add hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(current_dim, hidden_dim))\n",
    "            layers.append(nn.GELU())\n",
    "            layers.append(nn.Dropout(dropout_prob)) #probably dont need drouput, since we use dropout for final probability, try to remove this\n",
    "            current_dim = hidden_dim\n",
    "\n",
    "        # Final output layer\n",
    "        layers.append(nn.Linear(current_dim, num_classes))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "xoya1IIJycu_"
   },
   "outputs": [],
   "source": [
    "#klasifikatori za finiju granulaciju\n",
    "\n",
    "hidden_dimension = [768, 512]\n",
    "\n",
    "child_classifiers = {\n",
    "    int(0) : SecondLayerClassifier(input_dim=model.config.hidden_size, hidden_dims=hidden_dimension, num_classes=12).to(device) , #Antagonist\n",
    "    int(1) : SecondLayerClassifier(input_dim=model.config.hidden_size, hidden_dims=hidden_dimension, num_classes=4).to(device) , #Innocent\n",
    "    int(2) : SecondLayerClassifier(input_dim=model.config.hidden_size, hidden_dims=hidden_dimension,  num_classes=6).to(device) , #Protagonist\n",
    "}\n",
    "\n",
    "second_layer_optimizers = {\n",
    "    name: AdamW(child.parameters(), lr=0.0001)\n",
    "    for name, child in child_classifiers.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rA1KQaKPsqK-",
    "outputId": "25598ade-5e92-44fb-de38-a4890bdf96c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "SecondLayerClassifier(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (4): GELU(approximate='none')\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Linear(in_features=512, out_features=12, bias=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "SecondLayerClassifier(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (4): GELU(approximate='none')\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Linear(in_features=512, out_features=4, bias=True)\n",
      "  )\n",
      ")\n",
      "2\n",
      "SecondLayerClassifier(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (4): GELU(approximate='none')\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Linear(in_features=512, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for cls, child_classifier in child_classifiers.items():\n",
    "  print(cls)\n",
    "  print(child_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "VxX8jmCe-p8a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# for the confusion matrix in the end\n",
    "all_preds = np.array([], dtype=np.int8)\n",
    "all_labels = np.array([], dtype=np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YP8zVTHUqqa"
   },
   "source": [
    "TODO:\n",
    "Ovdje treba dodati da nakon sto uzmemo entity_representations na temelju koje smo do sada odredjivali prvu klasu, da ih damo i drugim klasifikatorima, ali tijekom treniranja treba iskoristiti cinjenicu da znamo tocnu prvu klasu, dakle iz odluciti na temelju pravog label-a kojem klasifikatoru dajemo podatke.\n",
    "Testiranje u zadnjoj epohi se provodi tako da nakon sto je nas model odredio prvu klasu, prosljedujemo taj input klasifikatoru nize razine.\n",
    "\n",
    "NE RADI, pitanje moze li se uopce paralelno trenirati ta 4 klasifikatora... stalno baca errore u okviru treniranja druge klasifikacije"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ms3jToMlm-4I",
    "outputId": "05cc77d1-5364-4b4f-b684-89915b6fa5ba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/6: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:04<00:00,  2.28s/it, loss=1.18]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "Training loss: 1.1822, Training accuracy: 0.2917\n",
      "Second-Layer Classifier: 0, Avg Loss: 0.0764, Accuracy: 0.1071\n",
      "Second-Layer Classifier: 1, Avg Loss: 0.2118, Accuracy: 0.2500\n",
      "Second-Layer Classifier: 2, Avg Loss: 0.1461, Accuracy: 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/6: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:04<00:00,  2.35s/it, loss=1.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/6\n",
      "Training loss: 1.1918, Training accuracy: 0.2500\n",
      "Second-Layer Classifier: 0, Avg Loss: 0.0759, Accuracy: 0.1071\n",
      "Second-Layer Classifier: 1, Avg Loss: 0.2104, Accuracy: 0.2500\n",
      "Second-Layer Classifier: 2, Avg Loss: 0.1448, Accuracy: 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/6: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:04<00:00,  2.27s/it, loss=1.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/6\n",
      "Training loss: 1.1877, Training accuracy: 0.2500\n",
      "Second-Layer Classifier: 0, Avg Loss: 0.0754, Accuracy: 0.1071\n",
      "Second-Layer Classifier: 1, Avg Loss: 0.2085, Accuracy: 0.2500\n",
      "Second-Layer Classifier: 2, Avg Loss: 0.1438, Accuracy: 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/6: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:04<00:00,  2.26s/it, loss=1.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/6\n",
      "Training loss: 1.1889, Training accuracy: 0.2917\n",
      "Second-Layer Classifier: 0, Avg Loss: 0.0749, Accuracy: 0.1071\n",
      "Second-Layer Classifier: 1, Avg Loss: 0.2067, Accuracy: 0.2500\n",
      "Second-Layer Classifier: 2, Avg Loss: 0.1429, Accuracy: 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/6: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:04<00:00,  2.26s/it, loss=1.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/6\n",
      "Training loss: 1.1297, Training accuracy: 0.2500\n",
      "Second-Layer Classifier: 0, Avg Loss: 0.0745, Accuracy: 0.1071\n",
      "Second-Layer Classifier: 1, Avg Loss: 0.2056, Accuracy: 0.2500\n",
      "Second-Layer Classifier: 2, Avg Loss: 0.1415, Accuracy: 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/6: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:04<00:00,  2.27s/it, loss=1.17]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/6\n",
      "Training loss: 1.1361, Training accuracy: 0.3750\n",
      "Second-Layer Classifier: 0, Avg Loss: 0.0740, Accuracy: 0.1071\n",
      "Second-Layer Classifier: 1, Avg Loss: 0.2032, Accuracy: 0.2500\n",
      "Second-Layer Classifier: 2, Avg Loss: 0.1411, Accuracy: 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "#retain_graph je potencijalno nepotreban\n",
    "\n",
    "num_epochs = 6\n",
    "debug = 0\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    second_layer_stats = {\n",
    "        cls: {'loss': 0.0, 'correct': 0, 'total': 0}\n",
    "        for cls in child_classifiers.keys()\n",
    "    }\n",
    "\n",
    "    train_progress_bar = tqdm(train_dataloader, desc=f\"Training Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "    for batch in train_progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        labels_1 = batch[2].to(device)\n",
    "        labels_2 = batch[3].to(device)  # second-layer labels\n",
    "\n",
    "        batch_size = input_ids.size(0)\n",
    "\n",
    "        #taking the output from BERT model\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels_1, output_hidden_states=True)\n",
    "\n",
    "        hidden_states = outputs.hidden_states[-1]\n",
    "\n",
    "        span_start_token_id = tokenizer.convert_tokens_to_ids('[SPAN_START]')\n",
    "        #span_end_token_id = tokenizer.convert_tokens_to_ids('[SPAN_END]')\n",
    "\n",
    "        start_mask = (input_ids == span_start_token_id)\n",
    "        #end_mask = (input_ids == span_end_token_id)\n",
    "\n",
    "        entity_representations = []\n",
    "\n",
    "        start_indices = start_mask.nonzero(as_tuple=True)[1]\n",
    "        #end_indices = end_mask.nonzero(as_tuple=True)[1]\n",
    "\n",
    "        valid_spans = (start_indices != -1) #& (end_indices != -1) & (start_indices <= end_indices)\n",
    "\n",
    "        valid_start_indices = start_indices[valid_spans]\n",
    "        #valid_end_indices = end_indices[valid_spans]\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            entity_tokens = hidden_states[i, valid_start_indices[i]] #for this version only start span tokens\n",
    "            entity_representations.append(entity_tokens)\n",
    "\n",
    "        entity_representations = torch.stack(entity_representations, dim=0)\n",
    "\n",
    "        #first layer classification\n",
    "        logits = classifier(entity_representations)\n",
    "        loss = criterion(logits, labels_1)\n",
    "\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        correct_predictions += (preds == labels_1).sum().item()\n",
    "        total_predictions += labels_1.size(0)\n",
    "\n",
    "        train_progress_bar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "        #second layer classification\n",
    "\n",
    "        for cls, second_layer_classifier in child_classifiers.items():\n",
    "            second_layer_indices = (labels_1 == cls).nonzero(as_tuple=True)[0]\n",
    "\n",
    "            if second_layer_indices.size(0) > 0:\n",
    "                second_layer_inputs = entity_representations[second_layer_indices]\n",
    "\n",
    "                num_classes = second_layer_classifier.num_classes\n",
    "                second_layer_labels = labels_2[second_layer_indices, :num_classes].float()\n",
    "\n",
    "                child_logits = second_layer_classifier(second_layer_inputs)\n",
    "                child_loss = criterion2(child_logits, second_layer_labels)\n",
    "\n",
    "                second_layer_optimizers[cls].zero_grad()\n",
    "                child_loss.backward(retain_graph=True)\n",
    "                second_layer_optimizers[cls].step()\n",
    "\n",
    "                #TODO change this, it only counts as correct if all the labels are correcty predicted for one input\n",
    "                second_layer_stats[cls]['loss'] += child_loss.item() * second_layer_labels.size(0)\n",
    "                child_preds = (torch.sigmoid(child_logits) > 0.29).int() #TODO find perfect threshold\n",
    "                correct = (child_preds == second_layer_labels.int()).sum().item()\n",
    "                second_layer_stats[cls]['correct'] += correct\n",
    "                second_layer_stats[cls]['total'] += second_layer_labels.numel()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    print(f\"Training loss: {avg_train_loss:.4f}, Training accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "    for cls, stats in second_layer_stats.items():\n",
    "        if stats['total'] > 0:\n",
    "            avg_loss = stats['loss'] / stats['total']\n",
    "            accuracy = stats['correct'] / stats['total']\n",
    "        else:\n",
    "            avg_loss = 0.0\n",
    "            accuracy = 0.0\n",
    "        print(f\"Second-Layer Classifier: {cls}, Avg Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "#TO DO uncomment and add second layer classification for the evaluation\n",
    "\n",
    "    # model.eval()\n",
    "    # test_loss = 0\n",
    "    # correct_test_predictions = 0\n",
    "    # total_test_predictions = 0\n",
    "\n",
    "    # test_progress_bar = tqdm(test_dataloader, desc=f\"Test Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "    # with torch.no_grad():\n",
    "    #     for batch in test_progress_bar:\n",
    "\n",
    "    #         input_ids = batch[0].to(device)\n",
    "    #         attention_mask = batch[1].to(device)\n",
    "    #         labels = batch[2].to(device)\n",
    "\n",
    "    #         batch_size = input_ids.size(0)\n",
    "\n",
    "    #         outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels, output_hidden_states=True)\n",
    "\n",
    "    #         hidden_states = outputs.hidden_states[-1]\n",
    "\n",
    "    #         span_start_token_id = tokenizer.convert_tokens_to_ids('[SPAN_START]')\n",
    "    #         span_end_token_id = tokenizer.convert_tokens_to_ids('[SPAN_END]')\n",
    "\n",
    "    #         start_mask = (input_ids == span_start_token_id)\n",
    "    #         end_mask = (input_ids == span_end_token_id)\n",
    "\n",
    "    #         entity_representations = []\n",
    "\n",
    "    #         start_indices = start_mask.nonzero(as_tuple=True)[1]\n",
    "    #         end_indices = end_mask.nonzero(as_tuple=True)[1]\n",
    "\n",
    "    #         valid_spans = (start_indices != -1) & (end_indices != -1) & (start_indices <= end_indices)\n",
    "\n",
    "    #         valid_start_indices = start_indices[valid_spans]\n",
    "    #         valid_end_indices = end_indices[valid_spans]\n",
    "\n",
    "    #         # extract entity tokens for every sample in batch\n",
    "    #         for i in range(batch_size):\n",
    "    #             entity_tokens = hidden_states[i, valid_start_indices[i]]\n",
    "    #             entity_representations.append(entity_tokens)\n",
    "\n",
    "    #         entity_representations = torch.stack(entity_representations, dim=0)\n",
    "\n",
    "    #         logits = classifier(entity_representations)\n",
    "    #         loss = criterion(logits, labels)\n",
    "    #         test_loss += loss.item()\n",
    "\n",
    "    #         #if epoch is the last epoch we want to redirect data to second layer classifier according to predicted label\n",
    "\n",
    "    #         preds = torch.argmax(logits, dim=-1)\n",
    "    #         if epoch == num_epochs-1:\n",
    "    #             all_preds = np.concatenate((all_preds, preds.cpu().numpy()))\n",
    "    #             all_labels = np.concatenate((all_labels, labels.cpu().numpy()))\n",
    "\n",
    "    #         correct_test_predictions += (preds == labels).sum().item()\n",
    "    #         total_test_predictions += labels.size(0)\n",
    "\n",
    "    #         test_progress_bar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    # avg_test_loss = test_loss / len(test_dataloader)\n",
    "    # test_accuracy = correct_test_predictions / total_test_predictions\n",
    "\n",
    "    # print(f\"Test loss: {avg_test_loss:.4f}, Test accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "REV-VUQvAiSN"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds, labels=[0, 1, 2])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Antagonist', 'Innocent', 'Protagonist'], yticklabels=['Antagonist', 'Innocent', 'Protagonist'])\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykSAAXhcDCrg"
   },
   "source": [
    "Comments for the future work\n",
    "- around 20% of predictions for the class 'innocent' is false predicted - this is very expected in the sentiment classification and polarity problems, that a neutral label will be harder to predict\n",
    "- around 16.9% of predictions for the class 'protagonist' is false predicted\n",
    "- around 15.7% of predictions for the class 'antagonist' is false predicted (note that 'antagonist' has significantly more representations in our dataset than 'innocent' and 'protagonist,' which could easily introduce bias into our model)\n",
    "\n",
    "- many false predictions are coming from the \"opposite\" classes, which could be easily influenced by models' bad generalization and tendency to memorize articles that are having the same 2 topics, for example in the non-Russian articles, Russia could be a Antagonist, and Russian articles are probably naming themself a innocent or protagonist (should be explored directly when evaluating the model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
