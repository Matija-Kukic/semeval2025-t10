{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfQVFtXBiMWy"
      },
      "source": [
        "## Hierarchical classification using Local Classification per Parent Node technique\n",
        "Here we use the same approach as in /solutions/custom_tokens/xlm_roberta_with_classification_start_span_token.ipynb to train the first classifier to predict the first class, and we train extra three classifiers for each of those classes that will provide us fine-grained classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYvFwavZiMW0",
        "outputId": "a94aa1ea-e7e9-4798-8d2d-8ac6447ce280"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "drive/My Drive/Colab Notebooks/semeval_data/subtask1.parquet\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "sub1 = 'drive/My Drive/Colab Notebooks/semeval_data/subtask1.parquet'\n",
        "print(sub1)\n",
        "\n",
        "# from pathlib import Path\n",
        "# wd = Path.cwd()\n",
        "# wd = wd.parent.parent\n",
        "# wd = wd / 'merged_data'\n",
        "# sub1 = str(wd) + '/subtask1.parquet'\n",
        "# print(sub1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BMEITI9CiMW2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_parquet(sub1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "p-vczjjdjVLb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ozEIv93FiMW3"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def labelNum(row):\n",
        "    if row['class1'] == 'Antagonist':\n",
        "        return int(0)\n",
        "    if row['class1'] == 'Innocent':\n",
        "        return int(1)\n",
        "    if row['class1'] == 'Protagonist':\n",
        "        return int(2)\n",
        "def cleanText(row):\n",
        "    text = str(row['text'])\n",
        "    #text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "    text = text.replace('\\n',' ').replace('  ', ' ')\n",
        "    return text\n",
        "df['label1'] = df.apply(labelNum,axis=1)\n",
        "df['input'] = df.apply(cleanText,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KMBg9PYVjdzw"
      },
      "outputs": [],
      "source": [
        "def labelNum2(row):\n",
        "    labels2 = [0 for _ in range(12)]\n",
        "    if row['label1'] == 2:\n",
        "        #labels2 = [0 for _ in range(6)]\n",
        "        if 'Guardian' in row['classes2']:\n",
        "            labels2[0] = 1\n",
        "        if 'Martyr' in row['classes2']:\n",
        "            labels2[1] = 1\n",
        "        if 'Peacemaker' in row['classes2']:\n",
        "            labels2[2] = 1\n",
        "        if 'Rebel' in row['classes2']:\n",
        "            labels2[3] = 1\n",
        "        if 'Underdog' in row['classes2']:\n",
        "            labels2[4] = 1\n",
        "        if 'Virtuous' in row['classes2']:\n",
        "            labels2[5] = 1\n",
        "    elif row['label1'] == 0:\n",
        "        #labels2 = [0 for _ in range(12)]\n",
        "        if 'Instigator' in row['classes2']:\n",
        "           labels2[0] = 1\n",
        "        if 'Conspirator' in row['classes2']:\n",
        "            labels2[1] = 1\n",
        "        if 'Tyrant' in row['classes2']:\n",
        "            labels2[2] = 1\n",
        "        if  'Foreign Adversary' in row['classes2']:\n",
        "            labels2[3] = 1\n",
        "        if 'Traitor' in row['classes2']:\n",
        "            labels2[4] = 1\n",
        "        if 'Spy' in row['classes2']:\n",
        "            labels2[5] = 1\n",
        "        if 'Saboteur' in row['classes2']:\n",
        "            labels2[6] = 1\n",
        "        if 'Corrupt' in row['classes2']:\n",
        "            labels2[7] = 1\n",
        "        if 'Incompetent' in row['classes2']:\n",
        "            labels2[8] = 1\n",
        "        if 'Terrorist' in row['classes2']:\n",
        "            labels2[9] = 1\n",
        "        if 'Deceiver' in row['classes2']:\n",
        "            labels2[10] = 1\n",
        "        if 'Bigot' in row['classes2']:\n",
        "            labels2[11] = 1\n",
        "    elif row['label1'] == 1:\n",
        "        #labels2 = [0 for _ in range(4)]\n",
        "        if 'Forgotten' in row['classes2']:\n",
        "            labels2[0] = 1\n",
        "        if 'Exploited' in row['classes2']:\n",
        "            labels2[1] = 1\n",
        "        if 'Victim' in row['classes2']:\n",
        "            labels2[2] = 1\n",
        "        if 'Scapegoat' in row['classes2']:\n",
        "            labels2[3] = 1\n",
        "    return labels2\n",
        "\n",
        "df['label2'] = df.apply(labelNum2, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnshZfqsiMW4",
        "outputId": "a27100a3-ee9d-49a6-d41e-81dddf497aea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lang                                                            BG\n",
            "art_name                                                BG_670.txt\n",
            "entity                                                       Запад\n",
            "start                                                          152\n",
            "end                                                            156\n",
            "class1                                                  Antagonist\n",
            "classes2              [Conspirator, Instigator, Foreign Adversary]\n",
            "text             Опитът на колективния Запад да „обезкърви Руси...\n",
            "label1                                                           0\n",
            "input            Опитът на колективния Запад да „обезкърви Руси...\n",
            "label2                        [1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "new_start_end                                           (151, 156)\n",
            "Name: 0, dtype: object\n"
          ]
        }
      ],
      "source": [
        "def find_all_substring_start_end(text, substring):\n",
        "    # Use re.finditer to find all occurrences of the substring in the text\n",
        "    matches = re.finditer(re.escape(substring), text)\n",
        "\n",
        "    # Collect the start and end indices of all matches\n",
        "    positions = [(match.start(), match.end()) for match in matches]\n",
        "\n",
        "    return positions\n",
        "def adjust_start_end(row):\n",
        "    org_text,cl_text,start,end,entity = str(row['text']),str(row['input']),int(row['start']),int(row['end']),str(row['entity'])\n",
        "    ss1 = find_all_substring_start_end(org_text,entity)\n",
        "    ss2 = find_all_substring_start_end(cl_text,entity)\n",
        "    #print(ss1,ss2)\n",
        "    #print(row['text'][start:end])\n",
        "    a = 0\n",
        "    for i in range(len(ss1)):\n",
        "        if abs((ss1[i][0] - start) + (ss1[i][1] - end) ) <= 2:\n",
        "            a = i\n",
        "            break\n",
        "    if org_text[ss1[a][0]:ss1[a][1]] != cl_text[ss2[a][0]:ss2[a][1]]:\n",
        "        print(\"ERROR!\")\n",
        "    return ss2[a][0],ss2[a][1]\n",
        "df['new_start_end'] = df.apply(adjust_start_end,axis=1)\n",
        "print(df.loc[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "s-PdTAcViMW5"
      },
      "outputs": [],
      "source": [
        "def addTokensToInput(row):\n",
        "    inp = row['input']\n",
        "    start,end = row['new_start_end']\n",
        "    #print(start,end)\n",
        "    start = int(start)\n",
        "    end = int(end)\n",
        "    token_input = inp[:start] + \"[SPAN_START] \" + inp[start:end] + \" [SPAN_END]\" + inp[end:]\n",
        "    return token_input\n",
        "\n",
        "df['span_input'] = df.apply(addTokensToInput,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yobaQPRoiMW5"
      },
      "outputs": [],
      "source": [
        "def upStartEnd(row):\n",
        "    start,end = row['new_start_end']\n",
        "    start += len(\"[SPAN_START] \")\n",
        "    end += len(\"[SPAN_START] \")\n",
        "    return start,end\n",
        "\n",
        "df['new_start_end'] = df.apply(upStartEnd,axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwT_XHKmiMW5",
        "outputId": "5a7a6609-c330-466b-9dfa-f164e0c12260"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizerFast\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = XLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-base\", num_labels=3).to(device)\n",
        "tokenizer = XLMRobertaTokenizerFast.from_pretrained(\"xlm-roberta-base\")\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['span_input'], padding=True, truncation=True,max_length=8192,return_offsets_mapping=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZDwWW9hiMW6",
        "outputId": "b03d55b4-fa6b-4d68-fa85-ecb9a3669e35"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Embedding(250004, 768, padding_idx=1)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "extraTokens = {\n",
        "    \"additional_special_tokens\": [\"[SPAN_START]\", \"[SPAN_END]\"]\n",
        "}\n",
        "num_added_toks = tokenizer.add_special_tokens(extraTokens)\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gMWI8j1ZiMW6"
      },
      "outputs": [],
      "source": [
        "data = df.loc[ : , ['span_input', 'label1', 'label2', 'new_start_end', 'entity']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "7eq2PO4ngplD",
        "outputId": "a3333ebe-7fb0-48e0-c775-c916950ae97d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 2902,\n  \"fields\": [\n    {\n      \"column\": \"span_input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2821,\n        \"samples\": [\n          \"\\u092f\\u0942\\u0915\\u094d\\u0930\\u0947\\u0928 \\u0914\\u0930 \\u0930\\u0942\\u0938 \\u0915\\u0947 \\u092c\\u0940\\u091a \\u092f\\u0941\\u0926\\u094d\\u0927 \\u0916\\u0924\\u094d\\u092e \\u0915\\u0930\\u093e\\u0928\\u0947 \\u092e\\u0947\\u0902 \\u092d\\u093e\\u0930\\u0924 \\u0915\\u0930 \\u0938\\u0915\\u0924\\u093e \\u0939\\u0948 \\u092e\\u0926\\u0926: \\u0930\\u093f\\u092a\\u094b\\u0930\\u094d\\u091f \\u092f\\u0942\\u0915\\u094d\\u0930\\u0947\\u0928, \\u0930\\u0942\\u0938 \\u0915\\u0947 \\u0938\\u093e\\u0925 \\u0936\\u093e\\u0902\\u0924\\u093f \\u0938\\u092e\\u091d\\u094c\\u0924\\u0947 \\u0915\\u0947 \\u0932\\u093f\\u090f, \\u092d\\u093e\\u0930\\u0924 \\u0916\\u093e\\u0938 \\u0924\\u094c\\u0930 \\u092a\\u0930 \\u092a\\u094d\\u0930\\u0927\\u093e\\u0928\\u092e\\u0902\\u0924\\u094d\\u0930\\u0940 \\u0928\\u0930\\u0947\\u0902\\u0926\\u094d\\u0930 \\u092e\\u094b\\u0926\\u0940 \\u0915\\u094b \\u090f\\u0915 \\u092a\\u094d\\u0930\\u092e\\u0941\\u0916 \\u092e\\u0927\\u094d\\u092f\\u0938\\u094d\\u0925 \\u0915\\u0947 \\u0930\\u0942\\u092a \\u092e\\u0947\\u0902 \\u0926\\u0947\\u0916 \\u0930\\u0939\\u093e \\u0939\\u0948. \\u092a\\u0949\\u0932\\u093f\\u091f\\u093f\\u0915\\u094b \\u0915\\u0940 \\u0930\\u093f\\u092a\\u094b\\u0930\\u094d\\u091f \\u0915\\u0947 \\u0905\\u0928\\u0941\\u0938\\u093e\\u0930, \\u0915\\u0940\\u0935 \\u0915\\u094b \\u0909\\u092e\\u094d\\u092e\\u0940\\u0926 \\u0939\\u0948 \\u0915\\u093f \\u092d\\u093e\\u0930\\u0924 \\u0915\\u093e \\u0924\\u091f\\u0938\\u094d\\u0925 \\u0930\\u0941\\u0916 \\u0914\\u0930 \\u0915\\u0942\\u091f\\u0928\\u0940\\u0924\\u093f\\u0915 \\u092a\\u094d\\u0930\\u092d\\u093e\\u0935 \\u092f\\u0941\\u0926\\u094d\\u0927 \\u0915\\u094b \\u0938\\u092e\\u093e\\u092a\\u094d\\u0924 \\u0915\\u0930\\u0928\\u0947 \\u0915\\u0940 \\u0926\\u093f\\u0936\\u093e \\u092e\\u0947\\u0902 \\u0905\\u0939\\u092e \\u0915\\u0926\\u092e \\u0939\\u094b \\u0938\\u0915\\u0924\\u093e \\u0939\\u0948. \\u0939\\u093e\\u0932 \\u0939\\u0940 \\u092e\\u0947\\u0902 \\u092a\\u0940\\u090f\\u092e \\u092e\\u094b\\u0926\\u0940 \\u0915\\u0940 \\u092f\\u0942\\u0915\\u094d\\u0930\\u0947\\u0928 \\u0915\\u0947 \\u092a\\u094d\\u0930\\u0947\\u0938\\u093f\\u0921\\u0947\\u0902\\u091f \\u091c\\u093c\\u0947\\u0932\\u0947\\u0902\\u0938\\u094d\\u0915\\u0940 \\u0938\\u0947 \\u092e\\u0941\\u0932\\u093e\\u0915\\u093e\\u0924 \\u0939\\u0941\\u0908. \\u092f\\u0942\\u0915\\u094d\\u0930\\u0947\\u0928\\u0940 \\u092e\\u0940\\u0921\\u093f\\u092f\\u093e \\u0907\\u0902\\u091f\\u0930\\u092b\\u0948\\u0915\\u094d\\u0938 \\u0928\\u0947 \\u091c\\u093c\\u0947\\u0932\\u0947\\u0902\\u0938\\u094d\\u0915\\u0940 \\u0915\\u0947 \\u0936\\u0940\\u0930\\u094d\\u0937 \\u0938\\u0932\\u093e\\u0939\\u0915\\u093e\\u0930 \\u090f\\u0902\\u0921\\u094d\\u0930\\u0940 \\u092f\\u0930\\u092e\\u0915 \\u0915\\u0947 \\u0939\\u0935\\u093e\\u0932\\u0947 \\u0938\\u0947 \\u092c\\u0924\\u093e\\u092f\\u093e, '\\u092f\\u0942\\u0915\\u094d\\u0930\\u0947\\u0928 \\u0915\\u0940 \\u0905\\u092a\\u0928\\u0940 \\u092f\\u093e\\u0924\\u094d\\u0930\\u093e \\u0915\\u0947 \\u0926\\u094c\\u0930\\u093e\\u0928, \\u092a\\u0940\\u090f\\u092e \\u092e\\u094b\\u0926\\u0940 \\u0928\\u0947 \\u092f\\u0939 \\u0938\\u094d\\u092a\\u0937\\u094d\\u091f \\u0915\\u0930 \\u0926\\u093f\\u092f\\u093e \\u0925\\u093e \\u0915\\u093f \\u092d\\u093e\\u0930\\u0924 \\u0915\\u092d\\u0940 \\u092d\\u0940 \\u0915\\u093f\\u0938\\u0940 \\u0910\\u0938\\u0940 \\u092f\\u094b\\u091c\\u0928\\u093e \\u092f\\u093e \\u092a\\u094d\\u0930\\u0938\\u094d\\u0924\\u093e\\u0935 \\u0915\\u093e \\u0938\\u092e\\u0930\\u094d\\u0925\\u0928 \\u0928\\u0939\\u0940\\u0902 \\u0915\\u0930\\u0947\\u0917\\u093e, \\u091c\\u093f\\u0938\\u092e\\u0947\\u0902 \\u092f\\u0942\\u0915\\u094d\\u0930\\u0947\\u0928 \\u0915\\u0940 \\u0915\\u094d\\u0937\\u0947\\u0924\\u094d\\u0930\\u0940\\u092f \\u0905\\u0916\\u0902\\u0921\\u0924\\u093e \\u0915\\u0947 \\u0938\\u093e\\u0925 \\u0915\\u094b\\u0908 \\u0938\\u092e\\u091d\\u094c\\u0924\\u093e \\u0936\\u093e\\u092e\\u093f\\u0932 \\u0939\\u094b.' \\u090f\\u0915 \\u0909\\u091a\\u094d\\u091a \\u092a\\u0926\\u0938\\u094d\\u0925 \\u092f\\u0942\\u0915\\u094d\\u0930\\u0947\\u0928\\u0940 \\u0905\\u0927\\u093f\\u0915\\u093e\\u0930\\u0940 \\u0928\\u0947 \\u0928\\u093e\\u092e \\u0928 \\u092c\\u0924\\u093e\\u0928\\u0947 \\u0915\\u0940 \\u0936\\u0930\\u094d\\u0924 \\u092a\\u0930 \\u0915\\u0939\\u093e \\u0915\\u093f \\u092d\\u093e\\u0930\\u0924 \\u0915\\u0940\\u0935 \\u0915\\u0940 \\u090f\\u0915 \\u092c\\u0921\\u093c\\u0940 \\u0909\\u092e\\u094d\\u092e\\u0940\\u0926 \\u0939\\u0948. \\u092d\\u093e\\u0930\\u0924 \\u0915\\u0940 \\u0935\\u091c\\u0939 \\u0938\\u0947 \\u0936\\u093e\\u0902\\u0924\\u093f \\u0938\\u092e\\u091d\\u094c\\u0924\\u0947 \\u092a\\u0930 \\u092a\\u0939\\u0941\\u0902\\u091a\\u093e \\u091c\\u093e \\u0938\\u0915\\u0924\\u093e \\u0939\\u0948. \\u0905\\u0927\\u093f\\u0915\\u093e\\u0930\\u0940 \\u0915\\u0947 \\u0905\\u0928\\u0941\\u0938\\u093e\\u0930, \\u092e\\u094b\\u0926\\u0940 \\u0928\\u0947 \\u0915\\u0940\\u0935 \\u0915\\u0947 \\u0938\\u093e\\u0925 \\u092c\\u093e\\u0924\\u091a\\u0940\\u0924 \\u092e\\u0947\\u0902 \\u0938\\u094d\\u092a\\u0937\\u094d\\u091f \\u0915\\u093f\\u092f\\u093e \\u0925\\u093e \\u0915\\u093f \\u092f\\u0942\\u0915\\u094d\\u0930\\u0947\\u0928 \\u0915\\u094b \\u0930\\u0942\\u0938 \\u0915\\u0947 \\u0939\\u092e\\u0932\\u0947 \\u0915\\u094b \\u0916\\u0924\\u094d\\u092e \\u0915\\u0930\\u0928\\u0947 \\u0915\\u0947 \\u0932\\u093f\\u090f \\u0915\\u0941\\u091b \\u091a\\u0940\\u091c\\u094b\\u0902 \\u092a\\u0930 \\u0905\\u0928\\u093f\\u0935\\u093e\\u0930\\u094d\\u092f \\u0930\\u0942\\u092a \\u0938\\u0947 \\u0938\\u092e\\u091d\\u094c\\u0924\\u093e \\u0915\\u0930\\u0928\\u0947 \\u0915\\u0940 \\u0906\\u0935\\u0936\\u094d\\u092f\\u0915\\u0924\\u093e \\u0939\\u094b\\u0917\\u0940. \\u0915\\u0940\\u0935 \\u0915\\u0940 \\u0928\\u091c\\u0930 \\u092e\\u0947\\u0902 \\u092e\\u094b\\u0926\\u0940 \\u0928\\u0947 \\u0915\\u092e \\u0938\\u092e\\u092f \\u092e\\u0947\\u0902 \\u090f\\u0915 \\u0932\\u0902\\u092c\\u093e \\u0938\\u092b\\u0930 \\u0924\\u092f \\u0915\\u093f\\u092f\\u093e \\u0939\\u0948. \\u091c\\u092c \\u0909\\u0928\\u094d\\u0939\\u094b\\u0902\\u0928\\u0947 \\u091c\\u0941\\u0932\\u093e\\u0908 \\u092e\\u0947\\u0902 \\u092e\\u0949\\u0938\\u094d\\u0915\\u094b \\u0915\\u093e \\u0926\\u094c\\u0930\\u093e \\u0915\\u093f\\u092f\\u093e \\u0914\\u0930 \\u0930\\u0942\\u0938\\u0940 \\u0930\\u093e\\u0937\\u094d\\u091f\\u094d\\u0930\\u092a\\u0924\\u093f \\u092a\\u0941\\u0924\\u093f\\u0928 \\u0915\\u094b \\u0917\\u0930\\u094d\\u092e\\u091c\\u094b\\u0936\\u0940 \\u0938\\u0947 \\u0917\\u0932\\u0947 \\u0932\\u0917\\u093e\\u092f\\u093e, \\u0924\\u094b \\u0915\\u0940\\u0935 \\u0915\\u0940 \\u092a\\u094d\\u0930\\u0924\\u093f\\u0915\\u094d\\u0930\\u093f\\u092f\\u093e \\u0924\\u0940\\u0916\\u0940 \\u0925\\u0940. \\u091c\\u093c\\u0947\\u0932\\u0947\\u0902\\u0938\\u094d\\u0915\\u0940 \\u0928\\u0947 \\u0907\\u0938 \\u0917\\u0932\\u0947 \\u092e\\u093f\\u0932\\u0928\\u0947 \\u0915\\u094b \\u092c\\u0939\\u0941\\u0924 \\u092c\\u0921\\u093c\\u0940 \\u0928\\u093f\\u0930\\u093e\\u0936\\u093e \\u0914\\u0930 \\u0936\\u093e\\u0902\\u0924\\u093f \\u092a\\u094d\\u0930\\u092f\\u093e\\u0938\\u094b\\u0902 \\u0915\\u0947 \\u0932\\u093f\\u090f \\u090f\\u0915 \\u0935\\u093f\\u0928\\u093e\\u0936\\u0915\\u093e\\u0930\\u0940 \\u091d\\u091f\\u0915\\u093e \\u0915\\u0939\\u093e. \\u0915\\u094d\\u092f\\u094b\\u0902\\u0915\\u093f \\u0909\\u0938\\u0940 \\u0926\\u093f\\u0928 \\u0930\\u0942\\u0938\\u0940 \\u092e\\u093f\\u0938\\u093e\\u0907\\u0932 \\u0939\\u092e\\u0932\\u0947 \\u092e\\u0947\\u0902 \\u0926\\u0930\\u094d\\u091c\\u0928\\u094b\\u0902 \\u092f\\u0942\\u0915\\u094d\\u0930\\u0947\\u0928\\u093f\\u092f\\u0928 \\u092e\\u093e\\u0930\\u0947 \\u0917\\u090f \\u0925\\u0947. \\u092e\\u0949\\u0938\\u094d\\u0915\\u094b \\u092f\\u093e\\u0924\\u094d\\u0930\\u093e \\u0915\\u0947 \\u091b\\u0939 \\u0938\\u092a\\u094d\\u0924\\u093e\\u0939 \\u092c\\u093e\\u0926 \\u092f\\u0942\\u0915\\u094d\\u0930\\u0947\\u0928 \\u0915\\u0940 \\u0928\\u093e\\u0930\\u093e\\u091c\\u0917\\u0940 \\u092c\\u0922\\u093c\\u0928\\u0947 \\u092a\\u0930 [SPAN_START] \\u092e\\u094b\\u0926\\u0940 [SPAN_END] \\u0928\\u0947 \\u091c\\u093c\\u0947\\u0932\\u0947\\u0902\\u0938\\u094d\\u0915\\u0940 \\u0938\\u0947 \\u092e\\u093f\\u0932\\u0928\\u0947 \\u0915\\u0947 \\u0932\\u093f\\u090f \\u0915\\u0940\\u0935 \\u0915\\u0940 \\u092f\\u093e\\u0924\\u094d\\u0930\\u093e \\u0915\\u0940. \\u0909\\u0928\\u094d\\u0939\\u094b\\u0902\\u0928\\u0947 \\u0915\\u0940\\u0935 \\u0915\\u0947 \\u0938\\u093e\\u0925 '\\u092e\\u093f\\u0924\\u094d\\u0930' \\u092c\\u0928\\u0947 \\u0930\\u0939\\u0928\\u0947 \\u0914\\u0930 \\u0936\\u093e\\u0902\\u0924\\u093f \\u0938\\u092e\\u091d\\u094c\\u0924\\u0947 \\u092e\\u0947\\u0902 \\u092e\\u0926\\u0926 \\u0915\\u0930\\u0928\\u0947 \\u0915\\u0940 \\u092c\\u093e\\u0924 \\u0915\\u0939\\u0940.\",\n          \"Poucas esperan\\u00e7as de justi\\u00e7a no 10\\u00ba anivers\\u00e1rio da queda do voo MH17 na Ucr\\u00e2nia Dez anos ap\\u00f3s a queda do voo MH17, que sobrevoava a Ucr\\u00e2nia, os familiares das v\\u00edtimas t\\u00eam poucas esperan\\u00e7as de ver os respons\\u00e1veis \\u200b\\u200bdetidos. Centenas de familiares das 298 v\\u00edtimas participaram numa homenagem esta quarta-feira(17) perto do aeroporto de Amesterd\\u00e3o-Schiphol, de onde o avi\\u00e3o descolou a 17 de julho de 2014 com destino a Kuala Lumpur. Horas depois, o Boeing 777 da Malaysia Airlines foi alvejado por um m\\u00edssil de fabrico russo numa zona da Ucr\\u00e2nia controlada por separatistas pr\\u00f3-R\\u00fassia. Todas as pessoas a bordo morreram. Durante a cerim\\u00f3nia, foram lidos em voz alta os nomes de todas as v\\u00edtimas, a maioria dos Pa\\u00edses Baixos (196), mas tamb\\u00e9m muitas da Mal\\u00e1sia (43) e da Austr\\u00e1lia (38). A justi\\u00e7a holandesa condenou tr\\u00eas homens a pris\\u00e3o perp\\u00e9tua em 2022 pelo seu papel no desastre, incluindo dois russos, mas Moscovo recusou extraditar qualquer suspeito. No ano passado, os investigadores internacionais suspenderam os seus trabalhos depois de conclu\\u00edrem que n\\u00e3o havia provas suficientes para perseguir os suspeitos envolvidos. \\\"N\\u00e3o creio que os respons\\u00e1veis \\u200b\\u200bcumpram a pena\\\", disse \\u00e0 AFP Evert van Zijtveld, que perdeu a filha Fr\\u00e9d\\u00e9rique, de 19 anos, o filho [SPAN_START] Robert-Jan [SPAN_END], de 18, e os sogros. A televis\\u00e3o holandesa transmitiu a cerim\\u00f3nia em direto e a bandeira nacional esteve a meia haste em muitos munic\\u00edpios do pa\\u00eds. O Governo australiano, numa cerim\\u00f3nia no Parlamento com familiares das v\\u00edtimas, disse que n\\u00e3o vai desistir \\\"do seu compromisso de responsabilizar a R\\u00fassia\\\". \\\"Comprometo-me mais uma vez com a nossa busca coletiva pela verdade, justi\\u00e7a e responsabiliza\\u00e7\\u00e3o pelas atrocidades cometidas no dia 17 de julho de 2014\\\", afirmou a ministra dos Neg\\u00f3cios Estrangeiros australiana, Penny Wong. - \\\"Dif\\u00edcil de acreditar\\\" - O avi\\u00e3o despenhou-se nas fases iniciais do conflito entre o governo ucraniano e os separatistas pr\\u00f3-russos no leste do pa\\u00eds, durante o qual Moscovo assumiu o controlo da pen\\u00ednsula da Crimeia. Em novembro de 2022, um tribunal holand\\u00eas considerou os russos Igor Guirkin e Sergei Dubinski e o ucraniano Leonid Kharchenko \\\"culpados\\\" de homic\\u00eddio doloso e condenou-os a pris\\u00e3o perp\\u00e9tua. Os magistrados consideraram que foram os respons\\u00e1veis \\u200b\\u200bpelo transporte do m\\u00edssil que derrubou o avi\\u00e3o de uma base na R\\u00fassia at\\u00e9 ao local de lan\\u00e7amento, embora n\\u00e3o tenham sido acusados \\u200b\\u200bpelo disparo. Os tr\\u00eas homens rejeitaram participar no processo judicial nos Pa\\u00edses Baixos, que os condenou \\u00e0 revelia, e negaram qualquer responsabilidade. Um quarto suspeito, o russo Oleg Pulatov, foi absolvido. Os investigadores internacionais conclu\\u00edram que existem \\\"fortes ind\\u00edcios\\\" de que o presidente russo, Vladimir Putin, aprovou o fornecimento do m\\u00edssil que derrubou a aeronave. Moscovo nega qualquer envolvimento e rejeitou veementemente o veredicto do tribunal de 2022, considerando-o \\\"pol\\u00edtico\\\" e \\\"escandaloso\\\". A Uni\\u00e3o Europeia instou Moscovo na ter\\u00e7a-feira a \\\"aceitar a sua responsabilidade por esta trag\\u00e9dia e a cooperar plenamente ao servi\\u00e7o da Justi\\u00e7a\\\". As provas apresentadas durante o julgamento \\\"mostram claramente que o sistema de m\\u00edsseis terra-ar BUK utilizado para abater o voo MH17 pertencia, sem d\\u00favida, \\u00e0s for\\u00e7as armadas da Federa\\u00e7\\u00e3o Russa\\\", disse o chefe da diplomacia da UE, Josep Borrell. Moscovo recusou-se a extraditar os suspeitos, alegando que seria contra as suas leis. \\\"A invas\\u00e3o da Ucr\\u00e2nia e a escalada da guerra tornam realmente dif\\u00edcil acreditar que um deles ser\\u00e1 preso em breve\\\", declarou Evert van Zijtveld. \",\n          \"European leader calls on world, China to pressure Russia  NUSA DUA \\u2013 The European Council president urged global powers Tuesday to intensify pressure on Russia over its war against Ukraine, including Moscow's biggest supporter, China, saying that this week's meeting of the world's largest economies was crucial to stopping Moscow's push \\\"to use food and energy as weapons.\\u201d Charles Michel, speaking to reporters on the first day of the Group of 20 meeting in Bali, said the nine-month war waged by Russia, a permanent member of the U.N. Security Council, has disrupted lives across the world, as food and energy prices surge and economies stagnate. Recommended Videos \\u201cRussia\\u2019s war impacts us all, no matter where we live, from Europe to Africa or the Middle East, and the single best way to end the acute crisis in food and energy is for Russia to end this senseless war and to respect the U.N. charter,\\u201d Michel said. \\u201cThe [SPAN_START] Kremlin [SPAN_END] has decided to weaponize food, driving up hunger, poverty and instability.\\u201d Europe, Michel said, is working to help Ukraine, a big food exporter before the war, increase its shipments, and is also trying to address disruptions in fertilizer supplies and rising prices. EU sanctions against Russia, he said, don\\u2019t target agricultural products, even though Russia has imposed restrictions on its own food and fertilizer products. \\u201cThis is not a battle (of) Russia against the Western part of the world. It\\u2019s a battle for the U.N. charter. It\\u2019s a battle for the international law. It's a battle for the idea that this is not acceptable to try to change by force internationally recognized borders.\\u201d Michel said he had no plans to meet with the most senior Russian present in Bali, Foreign Minister Sergey Lavrov. China, the world's second biggest economy, has largely refrained from public criticism of Russia\\u2019s war, although Beijing has avoided direct support of the Russians, such as supplying arms. Michel avoided direct criticism of China when asked if Beijing has shown any signs of changing its steadfast support of Russia in recent days. Instead, he said that the G-20 meeting Tuesday and Wednesday was important to convince all nations present \\u201cto put more pressure on Russia.\\\" After a meeting Monday between President Joe Biden and Chinese President Xi Jinping, Biden said the two leaders discussed Russia\\u2019s aggression against Ukraine and \\u201creaffirmed our shared belief\\u201d that the use or even the threat of nuclear weapons is \\u201ctotally unacceptable\\u201d \\u2014 a reference to Moscow\\u2019s thinly veiled threats to use atomic weapons as its invasion of Ukraine has faltered. Michel said that Europe must make sure that it creates a different economic and political relationship with China than the one it did with Russia. \\u201cWe don't want to make the same mistakes maybe we make with Russia on fossil fuels,\\u201d which Europe was very dependent on, \\u201cwith China, (where) we don't want to be too dependent for the innovative technology that we need today and that we need more in the future. That's why it's important to rebalance the relationship,\\u201d Michel said.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label2\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"new_start_end\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2649,\n        \"samples\": [\n          [\n            622,\n            625\n          ],\n          [\n            18651,\n            18658\n          ],\n          [\n            273,\n            280\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"entity\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1117,\n        \"samples\": [\n          \"\\u0412\\u043b\\u0430\\u0434\\u0438\\u043c\\u0438\\u0440 \\u041a\\u0443\\u0437\\u044c\\u043c\\u0438\\u043d\",\n          \"\\u0420\\u0435\\u043f\\u0443\\u0431\\u043b\\u0438\\u043a\\u0430 \\u041a\\u0440\\u0438\\u043c\",\n          \"\\u092e\\u0927\\u094d\\u092f \\u090f\\u0936\\u093f\\u092f\\u093e\\u0908\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-2bf82c90-afd0-40fc-b40d-771f429af453\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>span_input</th>\n",
              "      <th>label1</th>\n",
              "      <th>label2</th>\n",
              "      <th>new_start_end</th>\n",
              "      <th>entity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Опитът на колективния Запад да „обезкърви Руси...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>(164, 169)</td>\n",
              "      <td>Запад</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Опитът на колективния Запад да „обезкърви Руси...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>(541, 544)</td>\n",
              "      <td>САЩ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Опитът на колективния Запад да „обезкърви Руси...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>(546, 550)</td>\n",
              "      <td>НАТО</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Опитът на колективния Запад да „обезкърви Руси...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>(589, 596)</td>\n",
              "      <td>Украйна</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Опитът на колективния Запад да „обезкърви Руси...</td>\n",
              "      <td>1</td>\n",
              "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>(644, 661)</td>\n",
              "      <td>украински войници</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2897</th>\n",
              "      <td>Медведев: Даже в случае признания поражения Ки...</td>\n",
              "      <td>2</td>\n",
              "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>(569, 576)</td>\n",
              "      <td>Россией</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2898</th>\n",
              "      <td>Медведев: Даже в случае признания поражения Ки...</td>\n",
              "      <td>2</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>(1015, 1021)</td>\n",
              "      <td>Москва</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2899</th>\n",
              "      <td>Медведев: Даже в случае признания поражения Ки...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>(1308, 1312)</td>\n",
              "      <td>НАТО</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2900</th>\n",
              "      <td>Медведев: Даже в случае признания поражения [S...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>(57, 63)</td>\n",
              "      <td>Киевом</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2901</th>\n",
              "      <td>Эпизоды с призывами «убить Путина» нашли в дел...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>(68, 83)</td>\n",
              "      <td>Дмитрия Гордона</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2902 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2bf82c90-afd0-40fc-b40d-771f429af453')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2bf82c90-afd0-40fc-b40d-771f429af453 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2bf82c90-afd0-40fc-b40d-771f429af453');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-91ac7580-9fc2-4606-b098-6ce1496d98a7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-91ac7580-9fc2-4606-b098-6ce1496d98a7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-91ac7580-9fc2-4606-b098-6ce1496d98a7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_1a1aea31-849a-499c-8926-a597dd3b1fa3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1a1aea31-849a-499c-8926-a597dd3b1fa3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                             span_input  label1  \\\n",
              "0     Опитът на колективния Запад да „обезкърви Руси...       0   \n",
              "1     Опитът на колективния Запад да „обезкърви Руси...       0   \n",
              "2     Опитът на колективния Запад да „обезкърви Руси...       0   \n",
              "3     Опитът на колективния Запад да „обезкърви Руси...       0   \n",
              "4     Опитът на колективния Запад да „обезкърви Руси...       1   \n",
              "...                                                 ...     ...   \n",
              "2897  Медведев: Даже в случае признания поражения Ки...       2   \n",
              "2898  Медведев: Даже в случае признания поражения Ки...       2   \n",
              "2899  Медведев: Даже в случае признания поражения Ки...       0   \n",
              "2900  Медведев: Даже в случае признания поражения [S...       0   \n",
              "2901  Эпизоды с призывами «убить Путина» нашли в дел...       0   \n",
              "\n",
              "                                    label2 new_start_end             entity  \n",
              "0     [1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]    (164, 169)              Запад  \n",
              "1     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]    (541, 544)                САЩ  \n",
              "2     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]    (546, 550)               НАТО  \n",
              "3     [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]    (589, 596)            Украйна  \n",
              "4     [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]    (644, 661)  украински войници  \n",
              "...                                    ...           ...                ...  \n",
              "2897  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]    (569, 576)            Россией  \n",
              "2898  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  (1015, 1021)             Москва  \n",
              "2899  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  (1308, 1312)               НАТО  \n",
              "2900  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]      (57, 63)             Киевом  \n",
              "2901  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]      (68, 83)    Дмитрия Гордона  \n",
              "\n",
              "[2902 rows x 5 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Y4ncpV6fgpWZ"
      },
      "outputs": [],
      "source": [
        "data['tokenized']=data.apply(preprocess_function,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "cBcBQZegiMW7"
      },
      "outputs": [],
      "source": [
        "def indexes(row):\n",
        "    off_mask = row['tokenized']['offset_mapping']\n",
        "    start,end = row['new_start_end'][0],row['new_start_end'][1]\n",
        "    inds = list()\n",
        "    for p in range(len(off_mask)):\n",
        "        if off_mask[p][0] >= start and off_mask[p][1] <= end:\n",
        "            if p != len(off_mask)-1:\n",
        "                inds.append(p)\n",
        "    #if len(inds) > 1:\n",
        "        #print(\"GREATER THAN 1\")\n",
        "    if len(inds) == 0:\n",
        "        print(start,end)\n",
        "    return inds\n",
        "data['indexes'] = data.apply(indexes,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwd1VtkRiMW8",
        "outputId": "534aaa71-824d-4592-ec04-5213d560ef42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2902 2902 2902\n"
          ]
        }
      ],
      "source": [
        "data['list'] = data['tokenized'].apply(lambda x: x['input_ids'])\n",
        "data['attention'] = data['tokenized'].apply(lambda x: x['attention_mask'])\n",
        "ids = data['list']\n",
        "att = data['attention']\n",
        "indexes = data['indexes']\n",
        "tids = list()\n",
        "tatt = list()\n",
        "print(len(ids),len(att),len(indexes))\n",
        "for i in range(len(ids)):\n",
        "    tids.append(torch.tensor(ids[i]))\n",
        "    tatt.append(torch.tensor(att[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Hawj2WEWiMW8"
      },
      "outputs": [],
      "source": [
        "sliced_ids = list()\n",
        "sliced_ntids = list()\n",
        "sliced_att = list()\n",
        "key_inds = list()\n",
        "key_ids = list()\n",
        "\n",
        "def slices(index,size,context_size):\n",
        "    if (size<context_size):\n",
        "        return 0,size\n",
        "    lower_c = int(context_size/2-1)\n",
        "    upper_c = int(context_size/2)\n",
        "    #print(lower_c,upper_c)\n",
        "    if index < lower_c:\n",
        "        return 0,context_size\n",
        "    elif index >= lower_c:\n",
        "        if index + upper_c > size:\n",
        "            return index-(context_size-(size-index)), size\n",
        "        else:\n",
        "            return index-lower_c,index+upper_c+1\n",
        "\n",
        "\n",
        "for i in range(len(tids)):\n",
        "    slower,supper = slices(indexes[i][0],len(tids[i]),510)\n",
        "    #key_tid = tids[i][indexes[i][0]]\n",
        "    pid = ids[i][slower:supper]\n",
        "    key_inds.append([])\n",
        "    for j in indexes[i]:\n",
        "        key_id = ids[i][j]\n",
        "        if key_id not in pid:\n",
        "           print(len(ids[i]),key_id,slower,supper,indexes[i])\n",
        "        key_inds[i].append(pid.index(key_id))\n",
        "    apid = tids[i][slower:supper]\n",
        "    apatt = tatt[i][slower:supper]\n",
        "    if 0 not in pid:\n",
        "        apid = torch.cat((torch.tensor([0]),apid),dim=0)\n",
        "        apatt = torch.cat((torch.tensor([1]),apatt),dim=0)\n",
        "    if 2 not in pid:\n",
        "        apid = torch.cat((apid,torch.tensor([2])),dim=0)\n",
        "        apatt = torch.cat((apatt,torch.tensor([1])),dim=0)\n",
        "    sliced_ids.append(apid)\n",
        "    sliced_att.append(apatt)\n",
        "\n",
        "Min = 10000\n",
        "Max = 0\n",
        "ind2 = 0\n",
        "for i in range(len(indexes)):\n",
        "    if len(sliced_ids[i]) < Min:\n",
        "        Min = len(sliced_ids[i])\n",
        "        ind2 = i\n",
        "\n",
        "    if len(sliced_ids[i]) > Max:\n",
        "        Max = len(sliced_ids[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xFCUO_GXiMW8"
      },
      "outputs": [],
      "source": [
        "input_ids = list()\n",
        "att_mask = list()\n",
        "for ten,att in zip(sliced_ids,sliced_att):\n",
        "    if len(ten) < 512:\n",
        "        padding_length = 512 - len(ten)\n",
        "        padding_tensor = torch.full((padding_length,), tokenizer.pad_token_id, dtype=ten.dtype)\n",
        "        padding_tensor2 = torch.full((padding_length,), 0, dtype=att.dtype)\n",
        "        ten = torch.cat((ten,padding_tensor),dim=0)\n",
        "        att = torch.cat((att,padding_tensor2),dim=0)\n",
        "    input_ids.append(ten)\n",
        "    att_mask.append(att)\n",
        "inputIds = torch.stack(input_ids)\n",
        "attMask = torch.stack(att_mask)\n",
        "\n",
        "inputIds_np = inputIds.numpy()\n",
        "attMask_np = attMask.numpy()\n",
        "y1 = data['label1'].values\n",
        "y2 = data['label2'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "sZvBhiA-iMW8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train_ids, X_test_ids, X_train_mask, X_test_mask, y1_train, y1_test, y2_train, y2_test = train_test_split(\n",
        "    inputIds_np, attMask_np, y1, y2, test_size=0.2, random_state=42, shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "2nVj2Hns2OyK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "y2_train = np.array(y2_train.tolist(), dtype=np.int8)\n",
        "y2_test = np.array(y2_test.tolist(), dtype=np.int8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "2Nos0gEBiMW8"
      },
      "outputs": [],
      "source": [
        "X_train_ids = torch.tensor(X_train_ids, dtype=torch.long).to(device)\n",
        "X_test_ids = torch.tensor(X_test_ids, dtype=torch.long).to(device)\n",
        "X_train_mask = torch.tensor(X_train_mask, dtype=torch.long).to(device)\n",
        "X_test_mask = torch.tensor(X_test_mask, dtype=torch.long).to(device)\n",
        "y1_train = torch.tensor(y1_train, dtype=torch.long).to(device)\n",
        "y1_test = torch.tensor(y1_test, dtype=torch.long).to(device)\n",
        "y2_train = torch.tensor(y2_train, dtype=torch.long).to(device)\n",
        "y2_test = torch.tensor(y2_test, dtype=torch.long).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "GTxQJLCliMW9"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "train_dataset = TensorDataset(X_train_ids, X_train_mask, y1_train, y2_train)\n",
        "test_dataset = TensorDataset(X_test_ids, X_test_mask, y1_test, y2_test )\n",
        "\n",
        "# Create DataLoaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True) #shuffle=True provides data shuffle for batches in different epochs\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "YES435MWiMW9"
      },
      "outputs": [],
      "source": [
        "from torch.optim import AdamW\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "\n",
        "#first layer classifier\n",
        "classifier = nn.Linear(model.config.hidden_size, 3).to(device)\n",
        "#optimizer = AdamW(list(classifier.parameters()) + list(model.parameters()), lr=8e-6)\n",
        "optimizer = AdamW(model.parameters(), lr=8e-6)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "OLjIgbw0DCrf"
      },
      "outputs": [],
      "source": [
        "# not used?\n",
        "# class FocalLoss(nn.Module):\n",
        "#     def __init__(self, gamma=2., alpha=0.25, num_classes=3):\n",
        "#         super(FocalLoss, self).__init__()\n",
        "#         self.gamma = gamma\n",
        "#         self.alpha = alpha\n",
        "#         self.num_classes = num_classes\n",
        "#         self.cross_entropy_loss = nn.CrossEntropyLoss(reduction='none')\n",
        "\n",
        "#     def forward(self, inputs, targets):\n",
        "#         ce_loss = self.cross_entropy_loss(inputs, targets)\n",
        "#         p_t = torch.exp(-ce_loss)  # Probability of correct class\n",
        "#         focal_loss = self.alpha * (1 - p_t) ** self.gamma * ce_loss\n",
        "#         return focal_loss.mean()\n",
        "\n",
        "#criterion = FocalLoss(gamma=2., alpha=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "FYpTCF0dvTle"
      },
      "outputs": [],
      "source": [
        "criterion2 = nn.BCEWithLogitsLoss()\n",
        "\n",
        "class SecondLayerClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dims, num_classes):\n",
        "        \"\"\"\n",
        "        Multi-layer classifier for second-layer classification.\n",
        "\n",
        "        Args:\n",
        "            input_dim (int): Dimension of the input features.\n",
        "            hidden_dims (list of int): List of hidden layer dimensions.\n",
        "            num_classes (int): Number of output classes.\n",
        "            dropout_prob (float): Dropout probability (default: 0.3). // this is removed\n",
        "        \"\"\"\n",
        "        super(SecondLayerClassifier, self).__init__()\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        layers = []\n",
        "        current_dim = input_dim\n",
        "\n",
        "        # Add hidden layers\n",
        "        for hidden_dim in hidden_dims:\n",
        "            layers.append(nn.Linear(current_dim, hidden_dim))\n",
        "            layers.append(nn.GELU())\n",
        "            #layers.append(nn.Dropout(dropout_prob)) #probably dont need drouput, since we use dropout for final probability, try to remove this\n",
        "            current_dim = hidden_dim\n",
        "\n",
        "        # Final output layer\n",
        "        layers.append(nn.Linear(current_dim, num_classes))\n",
        "\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "xoya1IIJycu_"
      },
      "outputs": [],
      "source": [
        "#klasifikatori za finiju granulaciju\n",
        "\n",
        "hidden_dimension = []\n",
        "\n",
        "child_classifiers = {\n",
        "    int(0) : SecondLayerClassifier(input_dim=model.config.hidden_size, hidden_dims=hidden_dimension, num_classes=12).to(device) , #Antagonist\n",
        "    int(1) : SecondLayerClassifier(input_dim=model.config.hidden_size, hidden_dims=hidden_dimension, num_classes=4).to(device) , #Innocent\n",
        "    int(2) : SecondLayerClassifier(input_dim=model.config.hidden_size, hidden_dims=hidden_dimension,  num_classes=6).to(device) , #Protagonist\n",
        "}\n",
        "\n",
        "second_layer_optimizers = {\n",
        "    name: AdamW(sec_layer_classifier.parameters(), lr=0.0001)\n",
        "    for name, sec_layer_classifier in child_classifiers.items()\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rA1KQaKPsqK-",
        "outputId": "a7bfc11d-7dc1-4df4-ff62-f776dbb66e99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "SecondLayerClassifier(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=12, bias=True)\n",
            "  )\n",
            ")\n",
            "1\n",
            "SecondLayerClassifier(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=4, bias=True)\n",
            "  )\n",
            ")\n",
            "2\n",
            "SecondLayerClassifier(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=6, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "for cls, child_classifier in child_classifiers.items():\n",
        "  print(cls)\n",
        "  print(child_classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "VxX8jmCe-p8a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# for the confusion matrix in the end\n",
        "all_preds = np.array([], dtype=np.int8)\n",
        "all_labels = np.array([], dtype=np.int8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ms3jToMlm-4I",
        "outputId": "e829302a-9c87-43e4-9fe5-1a9c1c7898d8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 1/6: 100%|██████████| 146/146 [03:50<00:00,  1.58s/it, loss=1.44]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "Training loss: 0.8660, Training accuracy: 0.6114\n",
            "Second-Layer Classifier: 0, Avg Loss: 0.0582, (strict) Accuracy: 0.0646, Total: 1145\n",
            "Second-Layer Classifier: 1, Avg Loss: 0.1387, (strict) Accuracy: 0.1831, Total: 508\n",
            "Second-Layer Classifier: 2, Avg Loss: 0.1045, (strict) Accuracy: 0.1063, Total: 668\n",
            "Second-Layer Classifier 0 - Precision: 0.1109, Recall: 0.4439, Micro-F1-Score: 0.1775, Macro-F1-Score: 0.1355\n",
            "Confusion Matrix for Classifier 0:\n",
            "[[[ 828  113]\n",
            "  [ 186   18]]\n",
            "\n",
            " [[ 626  417]\n",
            "  [  60   42]]\n",
            "\n",
            " [[ 700  342]\n",
            "  [  72   31]]\n",
            "\n",
            " [[ 257  546]\n",
            "  [  79  263]]\n",
            "\n",
            " [[ 607  506]\n",
            "  [  19   13]]\n",
            "\n",
            " [[ 775  356]\n",
            "  [  10    4]]\n",
            "\n",
            " [[1000  100]\n",
            "  [  40    5]]\n",
            "\n",
            " [[ 732  341]\n",
            "  [  47   25]]\n",
            "\n",
            " [[ 614  389]\n",
            "  [  78   64]]\n",
            "\n",
            " [[ 477  556]\n",
            "  [  51   61]]\n",
            "\n",
            " [[ 577  473]\n",
            "  [  55   40]]\n",
            "\n",
            " [[ 695  429]\n",
            "  [  17    4]]]\n",
            "Second-Layer Classifier 1 - Precision: 0.3782, Recall: 0.9094, Micro-F1-Score: 0.5342, Macro-F1-Score: 0.3046\n",
            "Confusion Matrix for Classifier 1:\n",
            "[[[334 152]\n",
            "  [ 16   6]]\n",
            "\n",
            " [[103 355]\n",
            "  [  9  41]]\n",
            "\n",
            " [[  0  84]\n",
            "  [  6 418]]\n",
            "\n",
            " [[300 185]\n",
            "  [ 16   7]]]\n",
            "Second-Layer Classifier 2 - Precision: 0.2669, Recall: 0.6113, Micro-F1-Score: 0.3716, Macro-F1-Score: 0.2396\n",
            "Confusion Matrix for Classifier 2:\n",
            "[[[ 44 365]\n",
            "  [ 27 232]]\n",
            "\n",
            " [[511 142]\n",
            "  [ 12   3]]\n",
            "\n",
            " [[381 141]\n",
            "  [105  41]]\n",
            "\n",
            " [[419 198]\n",
            "  [ 30  21]]\n",
            "\n",
            " [[579  52]\n",
            "  [ 36   1]]\n",
            "\n",
            " [[172 294]\n",
            "  [ 66 136]]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Test Epoch 1/6: 100%|██████████| 37/37 [00:17<00:00,  2.16it/s, loss=0.427]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss: 0.5969, Test accuracy: 0.7814\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 2/6: 100%|██████████| 146/146 [03:50<00:00,  1.58s/it, loss=0.399]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/6\n",
            "Training loss: 0.5534, Training accuracy: 0.7897\n",
            "Second-Layer Classifier: 0, Avg Loss: 0.0359, (strict) Accuracy: 0.1057, Total: 1145\n",
            "Second-Layer Classifier: 1, Avg Loss: 0.0746, (strict) Accuracy: 0.8071, Total: 508\n",
            "Second-Layer Classifier: 2, Avg Loss: 0.0837, (strict) Accuracy: 0.2530, Total: 668\n",
            "Second-Layer Classifier 0 - Precision: 0.4116, Recall: 0.1160, Micro-F1-Score: 0.1810, Macro-F1-Score: 0.0523\n",
            "Confusion Matrix for Classifier 0:\n",
            "[[[ 933    8]\n",
            "  [ 201    3]]\n",
            "\n",
            " [[1040    3]\n",
            "  [ 102    0]]\n",
            "\n",
            " [[1040    2]\n",
            "  [ 103    0]]\n",
            "\n",
            " [[ 641  162]\n",
            "  [ 205  137]]\n",
            "\n",
            " [[1111    2]\n",
            "  [  31    1]]\n",
            "\n",
            " [[1131    0]\n",
            "  [  14    0]]\n",
            "\n",
            " [[1099    1]\n",
            "  [  45    0]]\n",
            "\n",
            " [[1073    0]\n",
            "  [  72    0]]\n",
            "\n",
            " [[1000    3]\n",
            "  [ 141    1]]\n",
            "\n",
            " [[1004   29]\n",
            "  [ 106    6]]\n",
            "\n",
            " [[1047    3]\n",
            "  [  94    1]]\n",
            "\n",
            " [[1124    0]\n",
            "  [  21    0]]]\n",
            "Second-Layer Classifier 1 - Precision: 0.8265, Recall: 0.8170, Micro-F1-Score: 0.8217, Macro-F1-Score: 0.2275\n",
            "Confusion Matrix for Classifier 1:\n",
            "[[[486   0]\n",
            "  [ 22   0]]\n",
            "\n",
            " [[453   5]\n",
            "  [ 50   0]]\n",
            "\n",
            " [[  0  84]\n",
            "  [  0 424]]\n",
            "\n",
            " [[485   0]\n",
            "  [ 23   0]]]\n",
            "Second-Layer Classifier 2 - Precision: 0.4204, Recall: 0.4239, Micro-F1-Score: 0.4222, Macro-F1-Score: 0.1848\n",
            "Confusion Matrix for Classifier 2:\n",
            "[[[141 268]\n",
            "  [ 57 202]]\n",
            "\n",
            " [[651   2]\n",
            "  [ 15   0]]\n",
            "\n",
            " [[503  19]\n",
            "  [134  12]]\n",
            "\n",
            " [[617   0]\n",
            "  [ 51   0]]\n",
            "\n",
            " [[631   0]\n",
            "  [ 37   0]]\n",
            "\n",
            " [[340 126]\n",
            "  [115  87]]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Test Epoch 2/6: 100%|██████████| 37/37 [00:17<00:00,  2.17it/s, loss=0.327]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss: 0.4761, Test accuracy: 0.8382\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 3/6: 100%|██████████| 146/146 [03:51<00:00,  1.58s/it, loss=0.0941]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/6\n",
            "Training loss: 0.3883, Training accuracy: 0.8587\n",
            "Second-Layer Classifier: 0, Avg Loss: 0.0342, (strict) Accuracy: 0.1546, Total: 1145\n",
            "Second-Layer Classifier: 1, Avg Loss: 0.0737, (strict) Accuracy: 0.8130, Total: 508\n",
            "Second-Layer Classifier: 2, Avg Loss: 0.0822, (strict) Accuracy: 0.2246, Total: 668\n",
            "Second-Layer Classifier 0 - Precision: 0.5023, Recall: 0.1737, Micro-F1-Score: 0.2581, Macro-F1-Score: 0.0627\n",
            "Confusion Matrix for Classifier 0:\n",
            "[[[ 917   24]\n",
            "  [ 192   12]]\n",
            "\n",
            " [[1042    1]\n",
            "  [ 102    0]]\n",
            "\n",
            " [[1040    2]\n",
            "  [ 103    0]]\n",
            "\n",
            " [[ 628  175]\n",
            "  [ 136  206]]\n",
            "\n",
            " [[1112    1]\n",
            "  [  32    0]]\n",
            "\n",
            " [[1131    0]\n",
            "  [  14    0]]\n",
            "\n",
            " [[1100    0]\n",
            "  [  45    0]]\n",
            "\n",
            " [[1073    0]\n",
            "  [  72    0]]\n",
            "\n",
            " [[1000    3]\n",
            "  [ 142    0]]\n",
            "\n",
            " [[1019   14]\n",
            "  [ 108    4]]\n",
            "\n",
            " [[1049    1]\n",
            "  [  94    1]]\n",
            "\n",
            " [[1124    0]\n",
            "  [  21    0]]]\n",
            "Second-Layer Classifier 1 - Precision: 0.8330, Recall: 0.8170, Micro-F1-Score: 0.8249, Macro-F1-Score: 0.2275\n",
            "Confusion Matrix for Classifier 1:\n",
            "[[[486   0]\n",
            "  [ 22   0]]\n",
            "\n",
            " [[457   1]\n",
            "  [ 50   0]]\n",
            "\n",
            " [[  0  84]\n",
            "  [  0 424]]\n",
            "\n",
            " [[485   0]\n",
            "  [ 23   0]]]\n",
            "Second-Layer Classifier 2 - Precision: 0.4238, Recall: 0.4465, Micro-F1-Score: 0.4348, Macro-F1-Score: 0.2116\n",
            "Confusion Matrix for Classifier 2:\n",
            "[[[168 241]\n",
            "  [ 64 195]]\n",
            "\n",
            " [[652   1]\n",
            "  [ 15   0]]\n",
            "\n",
            " [[462  60]\n",
            "  [111  35]]\n",
            "\n",
            " [[615   2]\n",
            "  [ 51   0]]\n",
            "\n",
            " [[631   0]\n",
            "  [ 37   0]]\n",
            "\n",
            " [[339 127]\n",
            "  [115  87]]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Test Epoch 3/6: 100%|██████████| 37/37 [00:17<00:00,  2.16it/s, loss=0.315]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss: 0.4768, Test accuracy: 0.8158\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 4/6: 100%|██████████| 146/146 [03:50<00:00,  1.58s/it, loss=0.0163]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/6\n",
            "Training loss: 0.2763, Training accuracy: 0.9121\n",
            "Second-Layer Classifier: 0, Avg Loss: 0.0334, (strict) Accuracy: 0.1659, Total: 1145\n",
            "Second-Layer Classifier: 1, Avg Loss: 0.0750, (strict) Accuracy: 0.8110, Total: 508\n",
            "Second-Layer Classifier: 2, Avg Loss: 0.0811, (strict) Accuracy: 0.2725, Total: 668\n",
            "Second-Layer Classifier 0 - Precision: 0.5178, Recall: 0.1815, Micro-F1-Score: 0.2687, Macro-F1-Score: 0.0625\n",
            "Confusion Matrix for Classifier 0:\n",
            "[[[ 928   13]\n",
            "  [ 201    3]]\n",
            "\n",
            " [[1040    3]\n",
            "  [ 101    1]]\n",
            "\n",
            " [[1034    8]\n",
            "  [ 103    0]]\n",
            "\n",
            " [[ 630  173]\n",
            "  [ 119  223]]\n",
            "\n",
            " [[1110    3]\n",
            "  [  32    0]]\n",
            "\n",
            " [[1131    0]\n",
            "  [  14    0]]\n",
            "\n",
            " [[1100    0]\n",
            "  [  45    0]]\n",
            "\n",
            " [[1073    0]\n",
            "  [  72    0]]\n",
            "\n",
            " [[ 999    4]\n",
            "  [ 140    2]]\n",
            "\n",
            " [[1024    9]\n",
            "  [ 110    2]]\n",
            "\n",
            " [[1046    4]\n",
            "  [  93    2]]\n",
            "\n",
            " [[1124    0]\n",
            "  [  21    0]]]\n",
            "Second-Layer Classifier 1 - Precision: 0.8252, Recall: 0.8189, Micro-F1-Score: 0.8221, Macro-F1-Score: 0.2369\n",
            "Confusion Matrix for Classifier 1:\n",
            "[[[484   2]\n",
            "  [ 22   0]]\n",
            "\n",
            " [[456   2]\n",
            "  [ 49   1]]\n",
            "\n",
            " [[  0  84]\n",
            "  [  0 424]]\n",
            "\n",
            " [[483   2]\n",
            "  [ 23   0]]]\n",
            "Second-Layer Classifier 2 - Precision: 0.4506, Recall: 0.5014, Micro-F1-Score: 0.4747, Macro-F1-Score: 0.2413\n",
            "Confusion Matrix for Classifier 2:\n",
            "[[[173 236]\n",
            "  [ 37 222]]\n",
            "\n",
            " [[647   6]\n",
            "  [ 15   0]]\n",
            "\n",
            " [[479  43]\n",
            "  [128  18]]\n",
            "\n",
            " [[613   4]\n",
            "  [ 49   2]]\n",
            "\n",
            " [[626   5]\n",
            "  [ 35   2]]\n",
            "\n",
            " [[326 140]\n",
            "  [ 90 112]]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Test Epoch 4/6: 100%|██████████| 37/37 [00:17<00:00,  2.16it/s, loss=0.373]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss: 0.4700, Test accuracy: 0.8296\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 5/6: 100%|██████████| 146/146 [03:50<00:00,  1.58s/it, loss=0.0053]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/6\n",
            "Training loss: 0.1797, Training accuracy: 0.9405\n",
            "Second-Layer Classifier: 0, Avg Loss: 0.0330, (strict) Accuracy: 0.1686, Total: 1145\n",
            "Second-Layer Classifier: 1, Avg Loss: 0.0689, (strict) Accuracy: 0.8110, Total: 508\n",
            "Second-Layer Classifier: 2, Avg Loss: 0.0808, (strict) Accuracy: 0.2575, Total: 668\n",
            "Second-Layer Classifier 0 - Precision: 0.5436, Recall: 0.1846, Micro-F1-Score: 0.2756, Macro-F1-Score: 0.0608\n",
            "Confusion Matrix for Classifier 0:\n",
            "[[[ 927   14]\n",
            "  [ 200    4]]\n",
            "\n",
            " [[1042    1]\n",
            "  [ 102    0]]\n",
            "\n",
            " [[1041    1]\n",
            "  [ 103    0]]\n",
            "\n",
            " [[ 630  173]\n",
            "  [ 114  228]]\n",
            "\n",
            " [[1113    0]\n",
            "  [  32    0]]\n",
            "\n",
            " [[1131    0]\n",
            "  [  14    0]]\n",
            "\n",
            " [[1100    0]\n",
            "  [  45    0]]\n",
            "\n",
            " [[1073    0]\n",
            "  [  72    0]]\n",
            "\n",
            " [[1001    2]\n",
            "  [ 141    1]]\n",
            "\n",
            " [[1028    5]\n",
            "  [ 108    4]]\n",
            "\n",
            " [[1047    3]\n",
            "  [  95    0]]\n",
            "\n",
            " [[1124    0]\n",
            "  [  21    0]]]\n",
            "Second-Layer Classifier 1 - Precision: 0.8288, Recall: 0.8208, Micro-F1-Score: 0.8248, Macro-F1-Score: 0.2453\n",
            "Confusion Matrix for Classifier 1:\n",
            "[[[486   0]\n",
            "  [ 22   0]]\n",
            "\n",
            " [[454   4]\n",
            "  [ 48   2]]\n",
            "\n",
            " [[  0  84]\n",
            "  [  0 424]]\n",
            "\n",
            " [[485   0]\n",
            "  [ 23   0]]]\n",
            "Second-Layer Classifier 2 - Precision: 0.4463, Recall: 0.5155, Micro-F1-Score: 0.4784, Macro-F1-Score: 0.2395\n",
            "Confusion Matrix for Classifier 2:\n",
            "[[[152 257]\n",
            "  [ 37 222]]\n",
            "\n",
            " [[653   0]\n",
            "  [ 15   0]]\n",
            "\n",
            " [[504  18]\n",
            "  [128  18]]\n",
            "\n",
            " [[615   2]\n",
            "  [ 51   0]]\n",
            "\n",
            " [[630   1]\n",
            "  [ 34   3]]\n",
            "\n",
            " [[290 176]\n",
            "  [ 79 123]]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Test Epoch 5/6: 100%|██████████| 37/37 [00:17<00:00,  2.17it/s, loss=0.4]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss: 0.4847, Test accuracy: 0.8485\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 6/6: 100%|██████████| 146/146 [03:50<00:00,  1.58s/it, loss=0.00478]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/6\n",
            "Training loss: 0.1270, Training accuracy: 0.9595\n",
            "Second-Layer Classifier: 0, Avg Loss: 0.0322, (strict) Accuracy: 0.1712, Total: 1145\n",
            "Second-Layer Classifier: 1, Avg Loss: 0.0698, (strict) Accuracy: 0.8110, Total: 508\n",
            "Second-Layer Classifier: 2, Avg Loss: 0.0782, (strict) Accuracy: 0.2769, Total: 668\n",
            "Second-Layer Classifier 0 - Precision: 0.5614, Recall: 0.1815, Micro-F1-Score: 0.2743, Macro-F1-Score: 0.0783\n",
            "Confusion Matrix for Classifier 0:\n",
            "[[[ 933    8]\n",
            "  [ 200    4]]\n",
            "\n",
            " [[1042    1]\n",
            "  [ 102    0]]\n",
            "\n",
            " [[1040    2]\n",
            "  [ 103    0]]\n",
            "\n",
            " [[ 648  155]\n",
            "  [ 135  207]]\n",
            "\n",
            " [[1112    1]\n",
            "  [  32    0]]\n",
            "\n",
            " [[1131    0]\n",
            "  [  14    0]]\n",
            "\n",
            " [[1100    0]\n",
            "  [  45    0]]\n",
            "\n",
            " [[1073    0]\n",
            "  [  72    0]]\n",
            "\n",
            " [[ 997    6]\n",
            "  [ 131   11]]\n",
            "\n",
            " [[1027    6]\n",
            "  [ 102   10]]\n",
            "\n",
            " [[1047    3]\n",
            "  [  94    1]]\n",
            "\n",
            " [[1124    0]\n",
            "  [  21    0]]]\n",
            "Second-Layer Classifier 1 - Precision: 0.8243, Recall: 0.8227, Micro-F1-Score: 0.8235, Macro-F1-Score: 0.2724\n",
            "Confusion Matrix for Classifier 1:\n",
            "[[[486   0]\n",
            "  [ 22   0]]\n",
            "\n",
            " [[451   7]\n",
            "  [ 47   3]]\n",
            "\n",
            " [[  1  83]\n",
            "  [  1 423]]\n",
            "\n",
            " [[484   1]\n",
            "  [ 22   1]]]\n",
            "Second-Layer Classifier 2 - Precision: 0.4565, Recall: 0.4803, Micro-F1-Score: 0.4681, Macro-F1-Score: 0.2596\n",
            "Confusion Matrix for Classifier 2:\n",
            "[[[162 247]\n",
            "  [ 45 214]]\n",
            "\n",
            " [[652   1]\n",
            "  [ 14   1]]\n",
            "\n",
            " [[498  24]\n",
            "  [122  24]]\n",
            "\n",
            " [[615   2]\n",
            "  [ 51   0]]\n",
            "\n",
            " [[627   4]\n",
            "  [ 34   3]]\n",
            "\n",
            " [[338 128]\n",
            "  [103  99]]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Test Epoch 6/6: 100%|██████████| 37/37 [00:17<00:00,  2.17it/s, loss=0.518]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss: 0.5277, Test accuracy: 0.8485\n",
            "Second-Layer Classifier: 0, Avg Loss: 0.0395, (strict) Accuracy: 0.1667, Total: 240\n",
            "Second-Layer Classifier: 1, Avg Loss: 0.0792, (strict) Accuracy: 0.8416, Total: 101\n",
            "Second-Layer Classifier: 2, Avg Loss: 0.0853, (strict) Accuracy: 0.2566, Total: 152\n",
            "OVERALL STRICT ACCURACY AFTER THE SECOND LAYER CLASSIFICATION: 0.2823\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support, multilabel_confusion_matrix, f1_score\n",
        "\n",
        "second_layer_true_labels = {cls: [] for cls in child_classifiers.keys()}\n",
        "second_layer_pred_labels = {cls: [] for cls in child_classifiers.keys()}\n",
        "confusion_matrices = {cls: [] for cls in child_classifiers.keys()}\n",
        "\n",
        "num_epochs = 6\n",
        "debug = 0\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    model.train()\n",
        "    classifier.train()\n",
        "    child_classifiers[0].train()\n",
        "    child_classifiers[1].train()\n",
        "    child_classifiers[2].train()\n",
        "\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    second_layer_stats = {\n",
        "        cls: {'loss': 0.0, 'correct': 0, 'total': 0}\n",
        "        for cls in child_classifiers.keys()\n",
        "    }\n",
        "\n",
        "    # reset for cm metrics\n",
        "    for cls in child_classifiers.keys():\n",
        "        second_layer_true_labels[cls] = []\n",
        "        second_layer_pred_labels[cls] = []\n",
        "        confusion_matrices[cls] = []\n",
        "\n",
        "    train_progress_bar = tqdm(train_dataloader, desc=f\"Training Epoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "    for batch in train_progress_bar:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch[0].to(device)\n",
        "        attention_mask = batch[1].to(device)\n",
        "        labels_1 = batch[2].to(device)\n",
        "        labels_2 = batch[3].to(device)  # second-layer labels\n",
        "\n",
        "        batch_size = input_ids.size(0)\n",
        "\n",
        "        #taking the output from BERT model\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels_1, output_hidden_states=True)\n",
        "        hidden_states = outputs.hidden_states[-1]\n",
        "        # finding the embedding that \"represents\" start_span special token\n",
        "        span_start_token_id = tokenizer.convert_tokens_to_ids('[SPAN_START]')\n",
        "        start_mask = (input_ids == span_start_token_id)\n",
        "        entity_representations = []\n",
        "        start_indices = start_mask.nonzero(as_tuple=True)[1]\n",
        "        valid_spans = (start_indices != -1)\n",
        "        valid_start_indices = start_indices[valid_spans]\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            entity_tokens = hidden_states[i, valid_start_indices[i]] #for this version only start span tokens\n",
        "            entity_representations.append(entity_tokens)\n",
        "\n",
        "        entity_representations = torch.stack(entity_representations, dim=0)\n",
        "\n",
        "        #first layer classification\n",
        "        logits = classifier(entity_representations)\n",
        "        loss = criterion(logits, labels_1)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        preds = torch.argmax(logits, dim=-1)\n",
        "        correct_predictions += (preds == labels_1).sum().item()\n",
        "        total_predictions += labels_1.size(0)\n",
        "\n",
        "        train_progress_bar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "        #second layer classification\n",
        "        for cls, second_layer_classifier in child_classifiers.items():\n",
        "            second_layer_indices = (labels_1 == cls).nonzero(as_tuple=True)[0]\n",
        "\n",
        "            if second_layer_indices.size(0) > 0:\n",
        "                second_layer_inputs = entity_representations[second_layer_indices].detach()\n",
        "\n",
        "                num_classes = second_layer_classifier.num_classes\n",
        "                second_layer_labels = labels_2[second_layer_indices, :num_classes].float()\n",
        "\n",
        "                child_logits = second_layer_classifier(second_layer_inputs)\n",
        "                child_loss = criterion2(child_logits, second_layer_labels)\n",
        "\n",
        "                second_layer_optimizers[cls].zero_grad()\n",
        "                child_loss.backward()\n",
        "                second_layer_optimizers[cls].step()\n",
        "\n",
        "                #for accuracy\n",
        "                second_layer_stats[cls]['loss'] += child_loss.item()\n",
        "                child_preds = (torch.sigmoid(child_logits) > 0.35).int()\n",
        "                correct = ((child_preds == second_layer_labels.int()).all(dim=1)).sum().item() #strict accuracy, all the labels have to be well predicted\n",
        "                second_layer_stats[cls]['correct'] += correct\n",
        "                second_layer_stats[cls]['total'] += second_layer_labels.size(0)\n",
        "                #for confusion matrix\n",
        "                child_preds = child_preds.cpu().numpy()\n",
        "                second_layer_labels = second_layer_labels.cpu().numpy()\n",
        "                second_layer_true_labels[cls].append(second_layer_labels)\n",
        "                second_layer_pred_labels[cls].append(child_preds)\n",
        "                confusion_matrices[cls].append(multilabel_confusion_matrix(second_layer_labels, child_preds))\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    train_accuracy = correct_predictions / total_predictions\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "    print(f\"Training loss: {avg_train_loss:.4f}, Training accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "    for cls, stats in second_layer_stats.items():\n",
        "        if stats['total'] > 0:\n",
        "            avg_loss = stats['loss'] / stats['total']\n",
        "            accuracy = stats['correct'] / stats['total']\n",
        "        else:\n",
        "            avg_loss = 0.0\n",
        "            accuracy = 0.0\n",
        "        print(f\"Second-Layer Classifier: {cls}, Avg Loss: {avg_loss:.4f}, (strict) Accuracy: {accuracy:.4f}, Total: {stats['total']}\")\n",
        "\n",
        "    for cls in child_classifiers.keys():\n",
        "        true_labels = np.vstack(second_layer_true_labels[cls])\n",
        "        pred_labels = np.vstack(second_layer_pred_labels[cls])\n",
        "\n",
        "        # Compute precision, recall, F1 for the current classifier\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(true_labels, pred_labels, average='micro')\n",
        "        macro_f1 = f1_score(true_labels, pred_labels, average='macro')\n",
        "        print(f\"Second-Layer Classifier {cls} - Precision: {precision:.4f}, Recall: {recall:.4f}, Micro-F1-Score: {f1:.4f}, Macro-F1-Score: {macro_f1:.4f}\")\n",
        "\n",
        "        # Compute confusion matrix for the current classifier\n",
        "        confusion_matrix = np.sum(confusion_matrices[cls], axis=0)\n",
        "        print(f\"Confusion Matrix for Classifier {cls}:\\n{confusion_matrix}\")\n",
        "\n",
        "    model.eval()\n",
        "    classifier.eval()\n",
        "    child_classifiers[0].eval()\n",
        "    child_classifiers[1].eval()\n",
        "    child_classifiers[2].eval()\n",
        "\n",
        "    test_loss = 0\n",
        "    correct_test_predictions = 0\n",
        "    total_test_predictions = 0\n",
        "\n",
        "    test_stats_per_classifier = {\n",
        "        cls: {'loss': 0.0, 'correct': 0, 'total': 0}\n",
        "        for cls in child_classifiers.keys()\n",
        "    }\n",
        "    overall_stats = {'loss': 0.0, 'correct': 0, 'total': 0}\n",
        "\n",
        "    test_progress_bar = tqdm(test_dataloader, desc=f\"Test Epoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_progress_bar:\n",
        "\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            labels_1 = batch[2].to(device)\n",
        "            labels_2 = batch[3].to(device)\n",
        "\n",
        "            batch_size = input_ids.size(0)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels_1, output_hidden_states=True)\n",
        "            hidden_states = outputs.hidden_states[-1]\n",
        "\n",
        "            span_start_token_id = tokenizer.convert_tokens_to_ids('[SPAN_START]')\n",
        "            start_mask = (input_ids == span_start_token_id)\n",
        "            entity_representations = []\n",
        "            start_indices = start_mask.nonzero(as_tuple=True)[1]\n",
        "            valid_spans = (start_indices != -1)\n",
        "            valid_start_indices = start_indices[valid_spans]\n",
        "\n",
        "            # extract entity tokens for every sample in batch\n",
        "            for i in range(batch_size):\n",
        "                entity_tokens = hidden_states[i, valid_start_indices[i]]\n",
        "                entity_representations.append(entity_tokens)\n",
        "\n",
        "            entity_representations = torch.stack(entity_representations, dim=0)\n",
        "\n",
        "            logits = classifier(entity_representations)\n",
        "            loss = criterion(logits, labels_1)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            #if epoch is the last epoch we want to redirect data to second layer classifier according to predicted label\n",
        "            if epoch == num_epochs-1:\n",
        "\n",
        "                #second layer classification\n",
        "                for cls, second_layer_classifier in child_classifiers.items():\n",
        "                    incorrect_label_1_indices = ((preds != labels_1) & (preds == cls)).nonzero(as_tuple=True)[0]\n",
        "                    if incorrect_label_1_indices.size(0) > 0:\n",
        "                        overall_stats['total'] += incorrect_label_1_indices.size(0)\n",
        "                        overall_stats['correct'] += 0\n",
        "\n",
        "                    second_layer_indices = ((preds == labels_1) & (labels_1 == cls)).nonzero(as_tuple=True)[0]\n",
        "\n",
        "                    # only correct first layer predictions for second layer evaluation\n",
        "                    if second_layer_indices.size(0) > 0:\n",
        "                        second_layer_inputs = entity_representations[second_layer_indices]\n",
        "\n",
        "                        num_classes = second_layer_classifier.num_classes\n",
        "                        second_layer_labels = labels_2[second_layer_indices, :num_classes].float()\n",
        "\n",
        "                        child_logits = second_layer_classifier(second_layer_inputs)\n",
        "                        child_loss = criterion2(child_logits, second_layer_labels)\n",
        "\n",
        "                        test_stats_per_classifier[cls]['loss'] += child_loss.item()\n",
        "\n",
        "                        child_preds = (torch.sigmoid(child_logits) > 0.35).int()\n",
        "\n",
        "                        # Count strict accuracy (all labels must match)\n",
        "                        correct = ((child_preds == second_layer_labels.int()).all(dim=1)).sum().item()\n",
        "                        test_stats_per_classifier[cls]['correct'] += correct\n",
        "                        test_stats_per_classifier[cls]['total'] += second_layer_labels.size(0)\n",
        "\n",
        "                        overall_stats['loss'] += child_loss.item() * second_layer_labels.size(0)\n",
        "                        overall_stats['correct'] += correct\n",
        "                        overall_stats['total'] += second_layer_labels.size(0)\n",
        "\n",
        "                #for confusion matrix in determing first class\n",
        "                all_preds = np.concatenate((all_preds, preds.cpu().numpy()))\n",
        "                all_labels = np.concatenate((all_labels, labels_1.cpu().numpy()))\n",
        "\n",
        "            correct_test_predictions += (preds == labels_1).sum().item()\n",
        "            total_test_predictions += labels_1.size(0)\n",
        "\n",
        "            test_progress_bar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_dataloader)\n",
        "    test_accuracy = correct_test_predictions / total_test_predictions\n",
        "\n",
        "    print(f\"Test loss: {avg_test_loss:.4f}, Test accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "    if epoch == num_epochs-1:\n",
        "\n",
        "        for cls, stats in test_stats_per_classifier.items():\n",
        "            if stats['total'] > 0:\n",
        "                avg_loss = stats['loss'] / stats['total']\n",
        "                accuracy = stats['correct'] / stats['total']\n",
        "            else:\n",
        "                avg_loss = 0.0\n",
        "                accuracy = 0.0\n",
        "            print(f\"Second-Layer Classifier: {cls}, Avg Loss: {avg_loss:.4f}, (strict) Accuracy: {accuracy:.4f}, Total: {stats['total']}\")\n",
        "\n",
        "        overall_accuracy = overall_stats['correct'] / overall_stats['total'] if overall_stats['total'] > 0 else 0.0\n",
        "        print(f\"OVERALL STRICT ACCURACY AFTER THE SECOND LAYER CLASSIFICATION: {overall_accuracy:.4f}\")\n",
        "        #strict accuracy means all the labels are correctly predicted for the input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "REV-VUQvAiSN"
      },
      "outputs": [],
      "source": [
        "\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "# import seaborn as sns\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# cm = confusion_matrix(all_labels, all_preds, labels=[0, 1, 2])\n",
        "\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Antagonist', 'Innocent', 'Protagonist'], yticklabels=['Antagonist', 'Innocent', 'Protagonist'])\n",
        "# plt.xlabel('Predicted Labels')\n",
        "# plt.ylabel('True Labels')\n",
        "# plt.title('Confusion Matrix')\n",
        "# plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
