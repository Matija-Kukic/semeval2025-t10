{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1dcb9da-abd9-4b4b-aaf1-1f3864ac9775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/matijak/Documents/programiranje/projects/semeval/merged_data/subtask1.parquet\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "wd = Path.cwd()\n",
    "wd = wd.parent.parent\n",
    "wd = wd / 'merged_data' \n",
    "sub1 = str(wd) + '/subtask1.parquet'\n",
    "print(sub1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5fd66dd-f991-454f-8684-4bd0a6cc41b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.aggregate of      lang    art_name             entity start   end       class1  \\\n",
       "0      BG  BG_670.txt              Запад   152   156   Antagonist   \n",
       "1      BG  BG_670.txt                САЩ   530   532   Antagonist   \n",
       "2      BG  BG_670.txt               НАТО   535   538   Antagonist   \n",
       "3      BG  BG_670.txt            Украйна   578   584   Antagonist   \n",
       "4      BG  BG_670.txt  украински войници   633   649     Innocent   \n",
       "...   ...         ...                ...   ...   ...          ...   \n",
       "2530   PT  PT_159.txt              China   371   375     Innocent   \n",
       "2531   PT   PT_74.txt           Pokrovsk  1139  1146     Innocent   \n",
       "2532   PT   PT_31.txt            Ucrânia   313   319   Antagonist   \n",
       "2533   PT   PT_31.txt                EUA   327   329   Antagonist   \n",
       "2534   PT   PT_31.txt            Moscovo  1999  2005  Protagonist   \n",
       "\n",
       "                                          classes2  \\\n",
       "0     [Conspirator, Instigator, Foreign Adversary]   \n",
       "1                                     [Instigator]   \n",
       "2                                     [Instigator]   \n",
       "3                              [Foreign Adversary]   \n",
       "4                                         [Victim]   \n",
       "...                                            ...   \n",
       "2530                                      [Victim]   \n",
       "2531                                      [Victim]   \n",
       "2532                           [Foreign Adversary]   \n",
       "2533                           [Foreign Adversary]   \n",
       "2534                                    [Guardian]   \n",
       "\n",
       "                                                   text  \n",
       "0     Опитът на колективния Запад да „обезкърви Руси...  \n",
       "1     Опитът на колективния Запад да „обезкърви Руси...  \n",
       "2     Опитът на колективния Запад да „обезкърви Руси...  \n",
       "3     Опитът на колективния Запад да „обезкърви Руси...  \n",
       "4     Опитът на колективния Запад да „обезкърви Руси...  \n",
       "...                                                 ...  \n",
       "2530  A transição energética\\n\\nMultiplicam-se os fe...  \n",
       "2531  Rússia assume controlo de mais uma povoação no...  \n",
       "2532  Quais foram as consequências do ataque de Iska...  \n",
       "2533  Quais foram as consequências do ataque de Iska...  \n",
       "2534  Quais foram as consequências do ataque de Iska...  \n",
       "\n",
       "[2535 rows x 8 columns]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(sub1)\n",
    "#df.head(n=20)\n",
    "df.aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e86fc621-83e0-4a5e-83a0-2ed0d0b31dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelNum(row):\n",
    "    if row['class1'] == 'Antagonist':\n",
    "        return int(0)\n",
    "    if row['class1'] == 'Innocent':\n",
    "        return int(1)\n",
    "    if row['class1'] == 'Protagonist':\n",
    "        return int(2)\n",
    "\n",
    "def textCon(row):\n",
    "    text1 = \"Consider the role of \" + row['entity'] + \" in the text.\"\n",
    "    text = text1 + \" \" + row['text']\n",
    "    return text\n",
    "\n",
    "df['label'] = df.apply(labelNum,axis=1)\n",
    "#print(df['label'].value_counts(),\n",
    "#df['class1'].value_counts())\n",
    "df['input'] = df.apply(textCon,axis=1)\n",
    "#print(df['input'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7df1b46-d7eb-4d62-85a2-2c28c7f4fcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.aggregate of                                                   input  label\n",
       "0     Consider the role of Запад in the text. Опитът...      0\n",
       "1     Consider the role of САЩ in the text. Опитът н...      0\n",
       "2     Consider the role of НАТО in the text. Опитът ...      0\n",
       "3     Consider the role of Украйна in the text. Опит...      0\n",
       "4     Consider the role of украински войници in the ...      1\n",
       "...                                                 ...    ...\n",
       "2530  Consider the role of China in the text. A tran...      1\n",
       "2531  Consider the role of Pokrovsk in the text. Rús...      1\n",
       "2532  Consider the role of Ucrânia in the text. Quai...      0\n",
       "2533  Consider the role of EUA in the text. Quais fo...      0\n",
       "2534  Consider the role of Moscovo in the text. Quai...      2\n",
       "\n",
       "[2535 rows x 2 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.loc[ : , ['input','label']]\n",
    "data.aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "576757dc-4d90-41b7-848f-38741d103564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1762    Consider the role of भारत in the text. अभी भार...\n",
       " 729     Consider the role of Russia in the text. Head ...\n",
       " 2204    Consider the role of Climáximo in the text. \"O...\n",
       " 1174    Consider the role of मास्को in the text. संयुक...\n",
       " 1721    Consider the role of नीदरलैंड in the text. Rus...\n",
       " Name: input, dtype: object,\n",
       " 1414    Consider the role of रूस in the text. प्रधानमं...\n",
       " 1776    Consider the role of ओरबान in the text. Viktor...\n",
       " 2323    Consider the role of Comissão Europeia in the ...\n",
       " 1389    Consider the role of रुबिज़ने in the text. यूक...\n",
       " 1379    Consider the role of रूस in the text. रूस-यूक्...\n",
       " Name: input, dtype: object,\n",
       " 1762    2\n",
       " 729     1\n",
       " 2204    2\n",
       " 1174    0\n",
       " 1721    2\n",
       " Name: label, dtype: int64,\n",
       " 1414    2\n",
       " 1776    0\n",
       " 2323    2\n",
       " 1389    1\n",
       " 1379    2\n",
       " Name: label, dtype: int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data[\"input\"]\n",
    "y = data[\"label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42\n",
    ")\n",
    "X_train.head(), X_test.head(), y_train.head(), y_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e03cf61-a696-4620-9e26-d107bd9b03b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1d13a99-5f0d-4c0d-b733-acdbeb43f9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1b38560-7053-45e2-9d42-c323963611f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizer\n",
    "\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-base\", num_labels=3).to(device)\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19270409-f532-42e6-a101-f255b228e77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Convert pandas DataFrame/Series to Hugging Face Dataset\n",
    "train_data = pd.DataFrame({'text': X_train, 'label': y_train})\n",
    "test_data = pd.DataFrame({'text': X_test, 'label': y_test})\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "test_dataset = Dataset.from_pandas(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8ca0c4d-bf53-44ec-9059-ad0ee7293815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb0242ee21e499e84484497e3b81c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2281 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d197b113934822a881ef70bf30cdfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/254 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['text'], padding=True, truncation=True, max_length=128)\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "test_dataset = test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad36295b-2e87-4f51-972d-208050efda7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Consider the role of भारत in the text. अभी भारत में चुनाव हुए भी नहीं हैं और प्रधानमंत्री नरेंद्र मोदी को विदेश से चुनाव बाद के आमंत्रण आने लगे हैं। रूस के राष्ट्रपति ब्लादिमीर पुतिन से बात करने के कुछ ही घंटों बाद पीएम मोदी ने यूक्रेन के राष्ट्रपति वोलोडिमिर ज़ेलेंस्की से फोन पर बातचीत की। बता दें कि रूस और यूक्रेन में पिछले 2 वर्षों से युद्ध चल रहा है और हाल ही में पुतिन ने चेताया था कि अगर NATO यूक्रेन में उतरता है तो तृतीया विश्व युद्ध होने से कोई नहीं रोक पाएगा। इस तनाव के बीच पीएम मोदी ने दोनों नेताओं से बात की।\\nबताया जा रहा है कि पुतिन और जेलेंस्की दोनों ने ही चुनाव बाद पीएम मोदी को अपने-अपने देश आने का न्योता दिया है। साथ ही दोनों ने ये भी कहा है कि वो भारत को समझौता करा कर शांति स्थापित कराने वाले देश के रूप में देखते हैं। प्रधानमंत्री नरेंद्र मोदी इससे पहले 2019 में रूस के दौरे पर गए थे। पीएम मोदी को न्योता मिलना ये भी दिखाता है कि अन्य देश भी ये मान कर चल रहे हैं कि बतौर प्रधानमंत्री लगातार तीसरी बार उनकी वापसी तय है और जनादेश उनके ही पक्ष में जाने वाला है।\\nपीएम मोदी ने वोलोडिमिर ज़ेलेंस्की से रूस-यूक्रेन के आम लोगों के बीच संबंध प्रगाढ़ करने के साथ-साथ रूस से यूक्रेन का तनाव खत्म करने पर भी बात की। उन्होंने कहा कि बातचीत और कूटनीति के जरिए ही युद्ध को समाप्त किया जा सकता है। जापान के हिरोशिमा में मई 2023 में पीएम मोदी ने G7 समिट से इतर जेलेंस्की से मुलाकात भी की थी। भारत ने यूक्रेन को मानवीय सहायता भी भेजी थी, जिसके लिए जेलेसी ने पीएम मोदी को ताज़ा बातचीत के दौरान धन्यवाद दिया।\\nPresident Putin invites PM Modi to Russia hours after Modi-Zelensky talk\\n— WION (@WIONews) March 20, 2024\\nUkraine and Russia see India as peacemaker@susanmtehrani joined by @siddhant for more insights\\nWatch more on https://t.co/AXC5qRugeb pic.twitter.com/dh7NbihQRT\\nइससे पहले पुतिन के फिर से रूस का राष्ट्रपति चुने जाने पर पीएम मोदी ने उन्हें फोन कॉल कर के बधाई दी थी। इस दौरान दोनों ने भारत-रूस के रणनीतिक संबंधों को प्रगाढ़ करने पर सहमति जताई। पुतिन 87.17% वोटों से फिर से रूस के प्रेजिडेंट चुने गए हैं। इससे पहले 2000, 2004, 2012 और 2018 में भी वो राष्ट्रपति का चुनाव जीत चुके हैं। पश्चिमी देशों ने इस चुनाव को अलोकतांत्रिक करार दिया है। यूक्रेन ने यूएस कॉन्ग्रेस से 60 बिलियन डॉलर के पैकेज को अनब्लॉक करने की माँग की है, जो राजनीतिक खींचातानी में अटकी हुई है।',\n",
       " 'label': 2,\n",
       " '__index_level_0__': 1762,\n",
       " 'input_ids': [0,\n",
       "  137399,\n",
       "  70,\n",
       "  31486,\n",
       "  111,\n",
       "  3946,\n",
       "  23,\n",
       "  70,\n",
       "  7986,\n",
       "  5,\n",
       "  38159,\n",
       "  3946,\n",
       "  421,\n",
       "  14117,\n",
       "  9179,\n",
       "  1780,\n",
       "  2191,\n",
       "  1293,\n",
       "  871,\n",
       "  42775,\n",
       "  64775,\n",
       "  10903,\n",
       "  629,\n",
       "  44893,\n",
       "  646,\n",
       "  14117,\n",
       "  6435,\n",
       "  287,\n",
       "  2220,\n",
       "  171103,\n",
       "  4846,\n",
       "  47619,\n",
       "  54751,\n",
       "  1293,\n",
       "  125,\n",
       "  179129,\n",
       "  287,\n",
       "  27030,\n",
       "  6,\n",
       "  60624,\n",
       "  68242,\n",
       "  10398,\n",
       "  1393,\n",
       "  12881,\n",
       "  4781,\n",
       "  998,\n",
       "  646,\n",
       "  13073,\n",
       "  4050,\n",
       "  287,\n",
       "  7494,\n",
       "  2093,\n",
       "  14054,\n",
       "  23530,\n",
       "  1302,\n",
       "  6435,\n",
       "  72447,\n",
       "  10903,\n",
       "  1142,\n",
       "  26460,\n",
       "  121704,\n",
       "  998,\n",
       "  287,\n",
       "  27030,\n",
       "  15667,\n",
       "  9376,\n",
       "  44985,\n",
       "  15679,\n",
       "  1393,\n",
       "  84173,\n",
       "  16230,\n",
       "  7810,\n",
       "  28979,\n",
       "  659,\n",
       "  646,\n",
       "  31162,\n",
       "  968,\n",
       "  185002,\n",
       "  471,\n",
       "  125,\n",
       "  26956,\n",
       "  50486,\n",
       "  1682,\n",
       "  179129,\n",
       "  871,\n",
       "  26460,\n",
       "  121704,\n",
       "  998,\n",
       "  421,\n",
       "  71383,\n",
       "  116,\n",
       "  5850,\n",
       "  1302,\n",
       "  646,\n",
       "  67114,\n",
       "  15048,\n",
       "  7172,\n",
       "  460,\n",
       "  871,\n",
       "  26898,\n",
       "  2093,\n",
       "  421,\n",
       "  12881,\n",
       "  4781,\n",
       "  998,\n",
       "  1142,\n",
       "  36004,\n",
       "  1480,\n",
       "  3889,\n",
       "  3813,\n",
       "  1682,\n",
       "  24050,\n",
       "  16232,\n",
       "  26460,\n",
       "  121704,\n",
       "  998,\n",
       "  421,\n",
       "  85038,\n",
       "  1480,\n",
       "  460,\n",
       "  2073,\n",
       "  201325,\n",
       "  1026,\n",
       "  13743,\n",
       "  67114,\n",
       "  12509,\n",
       "  646,\n",
       "  2],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df3f9328-4662-462b-b385-65cf4f9cadec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2b0314d-ee2a-4340-9918-b621ebd0072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcfc6363-7f64-4c59-b06e-7b0cf7a907ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/3: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 72/72 [00:31<00:00,  2.28it/s, loss=1.05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Training loss: 1.0319, Training accuracy: 0.4836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 1/3: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00,  8.08it/s, loss=0.969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.9598, Test accuracy: 0.5394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/3: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 72/72 [00:31<00:00,  2.25it/s, loss=0.626]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3\n",
      "Training loss: 0.9532, Training accuracy: 0.5594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 2/3: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:01<00:00,  7.92it/s, loss=0.866]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.8743, Test accuracy: 0.6220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/3: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 72/72 [00:32<00:00,  2.22it/s, loss=0.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3\n",
      "Training loss: 0.8450, Training accuracy: 0.6234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 3/3: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00,  8.06it/s, loss=0.714]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.7855, Test accuracy: 0.6654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    # Initialize tqdm progress bar for training\n",
    "    train_progress_bar = tqdm(train_dataloader, desc=f\"Training Epoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    for batch in train_progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        correct_predictions += (preds == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "        \n",
    "        # Update tqdm description with current loss\n",
    "        train_progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    print(f\"Training loss: {avg_train_loss:.4f}, Training accuracy: {train_accuracy:.4f}\")\n",
    "    \n",
    "    # Test phase\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct_test_predictions = 0\n",
    "    total_test_predictions = 0\n",
    "    \n",
    "    # Initialize tqdm progress bar for test\n",
    "    test_progress_bar = tqdm(test_dataloader, desc=f\"Test Epoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_progress_bar:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Calculate test accuracy\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            correct_test_predictions += (preds == labels).sum().item()\n",
    "            total_test_predictions += labels.size(0)\n",
    "            \n",
    "            # Update tqdm description with current loss\n",
    "            test_progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    avg_test_loss = test_loss / len(test_dataloader)\n",
    "    test_accuracy = correct_test_predictions / total_test_predictions\n",
    "    \n",
    "    print(f\"Test loss: {avg_test_loss:.4f}, Test accuracy: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
