{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1dcb9da-abd9-4b4b-aaf1-1f3864ac9775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/matijak/Documents/programiranje/projects/semeval/merged_data/subtask1.parquet\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "wd = Path.cwd()\n",
    "wd = wd.parent.parent\n",
    "wd = wd / 'merged_data' \n",
    "sub1 = str(wd) + '/subtask1.parquet'\n",
    "print(sub1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5fd66dd-f991-454f-8684-4bd0a6cc41b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.aggregate of      lang    art_name             entity start   end       class1  \\\n",
       "0      BG  BG_670.txt              Запад   152   156   Antagonist   \n",
       "1      BG  BG_670.txt                САЩ   530   532   Antagonist   \n",
       "2      BG  BG_670.txt               НАТО   535   538   Antagonist   \n",
       "3      BG  BG_670.txt            Украйна   578   584   Antagonist   \n",
       "4      BG  BG_670.txt  украински войници   633   649     Innocent   \n",
       "...   ...         ...                ...   ...   ...          ...   \n",
       "2530   PT  PT_159.txt              China   371   375     Innocent   \n",
       "2531   PT   PT_74.txt           Pokrovsk  1139  1146     Innocent   \n",
       "2532   PT   PT_31.txt            Ucrânia   313   319   Antagonist   \n",
       "2533   PT   PT_31.txt                EUA   327   329   Antagonist   \n",
       "2534   PT   PT_31.txt            Moscovo  1999  2005  Protagonist   \n",
       "\n",
       "                                          classes2  \\\n",
       "0     [Conspirator, Instigator, Foreign Adversary]   \n",
       "1                                     [Instigator]   \n",
       "2                                     [Instigator]   \n",
       "3                              [Foreign Adversary]   \n",
       "4                                         [Victim]   \n",
       "...                                            ...   \n",
       "2530                                      [Victim]   \n",
       "2531                                      [Victim]   \n",
       "2532                           [Foreign Adversary]   \n",
       "2533                           [Foreign Adversary]   \n",
       "2534                                    [Guardian]   \n",
       "\n",
       "                                                   text  \n",
       "0     Опитът на колективния Запад да „обезкърви Руси...  \n",
       "1     Опитът на колективния Запад да „обезкърви Руси...  \n",
       "2     Опитът на колективния Запад да „обезкърви Руси...  \n",
       "3     Опитът на колективния Запад да „обезкърви Руси...  \n",
       "4     Опитът на колективния Запад да „обезкърви Руси...  \n",
       "...                                                 ...  \n",
       "2530  A transição energética\\n\\nMultiplicam-se os fe...  \n",
       "2531  Rússia assume controlo de mais uma povoação no...  \n",
       "2532  Quais foram as consequências do ataque de Iska...  \n",
       "2533  Quais foram as consequências do ataque de Iska...  \n",
       "2534  Quais foram as consequências do ataque de Iska...  \n",
       "\n",
       "[2535 rows x 8 columns]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(sub1)\n",
    "#df.head(n=20)\n",
    "df.aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e86fc621-83e0-4a5e-83a0-2ed0d0b31dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelNum(row):\n",
    "    if row['class1'] == 'Antagonist':\n",
    "        return int(0)\n",
    "    if row['class1'] == 'Innocent':\n",
    "        return int(1)\n",
    "    if row['class1'] == 'Protagonist':\n",
    "        return int(2)\n",
    "\n",
    "def textCon(row):\n",
    "    text1 = \"Consider the role of \" + row['entity'] + \" in the text.\"\n",
    "    text = text1 + \" \" + row['text']\n",
    "    return text\n",
    "\n",
    "df['label'] = df.apply(labelNum,axis=1)\n",
    "#print(df['label'].value_counts(),\n",
    "#df['class1'].value_counts())\n",
    "df['input'] = df.apply(textCon,axis=1)\n",
    "#print(df['input'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7df1b46-d7eb-4d62-85a2-2c28c7f4fcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.aggregate of                                                   input  label\n",
       "0     Consider the role of Запад in the text. Опитът...      0\n",
       "1     Consider the role of САЩ in the text. Опитът н...      0\n",
       "2     Consider the role of НАТО in the text. Опитът ...      0\n",
       "3     Consider the role of Украйна in the text. Опит...      0\n",
       "4     Consider the role of украински войници in the ...      1\n",
       "...                                                 ...    ...\n",
       "2530  Consider the role of China in the text. A tran...      1\n",
       "2531  Consider the role of Pokrovsk in the text. Rús...      1\n",
       "2532  Consider the role of Ucrânia in the text. Quai...      0\n",
       "2533  Consider the role of EUA in the text. Quais fo...      0\n",
       "2534  Consider the role of Moscovo in the text. Quai...      2\n",
       "\n",
       "[2535 rows x 2 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.loc[ : , ['input','label']]\n",
    "data.aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "576757dc-4d90-41b7-848f-38741d103564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1979    Consider the role of Europa in the text. O pas...\n",
       " 1110    Consider the role of पश्चिमी देश in the text. ...\n",
       " 157     Consider the role of Русия in the text. Столте...\n",
       " 1210    Consider the role of ट्रंप in the text. 'रूस-य...\n",
       " 888     Consider the role of मोदी in the text. नई दिल्...\n",
       " Name: input, dtype: object,\n",
       " 1414    Consider the role of रूस in the text. प्रधानमं...\n",
       " 1776    Consider the role of ओरबान in the text. Viktor...\n",
       " 2323    Consider the role of Comissão Europeia in the ...\n",
       " 1389    Consider the role of रुबिज़ने in the text. यूक...\n",
       " 1379    Consider the role of रूस in the text. रूस-यूक्...\n",
       " Name: input, dtype: object,\n",
       " 1979    1\n",
       " 1110    0\n",
       " 157     0\n",
       " 1210    2\n",
       " 888     2\n",
       " Name: label, dtype: int64,\n",
       " 1414    2\n",
       " 1776    0\n",
       " 2323    2\n",
       " 1389    1\n",
       " 1379    2\n",
       " Name: label, dtype: int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data[\"input\"]\n",
    "y = data[\"label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "X_train.head(), X_test.head(), y_train.head(), y_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e03cf61-a696-4620-9e26-d107bd9b03b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1d13a99-5f0d-4c0d-b733-acdbeb43f9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1b38560-7053-45e2-9d42-c323963611f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizer\n",
    "\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-base\", num_labels=3).to(device)\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19270409-f532-42e6-a101-f255b228e77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Convert pandas DataFrame/Series to Hugging Face Dataset\n",
    "train_data = pd.DataFrame({'text': X_train, 'label': y_train})\n",
    "test_data = pd.DataFrame({'text': X_test, 'label': y_test})\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "test_dataset = Dataset.from_pandas(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8ca0c4d-bf53-44ec-9059-ad0ee7293815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b5347cd1134a30823e78a3977d92cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2028 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb12eafb7664a998646556277105e11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/507 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['text'], padding=True, truncation=True, max_length=128)\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "test_dataset = test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad36295b-2e87-4f51-972d-208050efda7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Consider the role of Europa in the text. O passado domingo foi o dia mais quente já registado no mundo, diz observatório europeu\\n\\nO passado domingo, 21 de julho, foi o dia mais quente de que há registo a nível global, de acordo com os dados preliminares do Serviço de Alterações Climáticas Copernicus, da União Europeia.\\n\\nA temperatura média do ar à superfície do planeta no domingo atingiu os 17,09°C —um pouco acima do recorde anterior, de 6 de julho do ano passado, de 17,08°C.\\n\\nAs ondas de calor atingiram grandes áreas dos Estados Unidos, Europa e Rússia na última semana.\\n\\nO observatório Copernicus confirmou à agência Reuters que o recorde de temperatura média diária estabelecido no ano passado parece ter sido batido no domingo, de acordo com os seus registos, que remontam a 1940.\\n\\nSegundo o Copernicus, o novo recorde diário pode ser ultrapassado nos próximos dias. As temperaturas devem descer a seguir, mas são esperadas ainda flutuações nas próximas semanas.\\n\\n\"O que realmente surpreende é a magnitude da diferença entre a temperatura dos últimos 13 meses e os recordes anteriores. Estamos em território desconhecido e, à medida que o clima aquece, vamos certamente bater novos recordes nos próximos meses e anos\", prevê Carlo Buontempo, diretor do departamento de alterações climáticas do Copernicus (conhecido pela sigla C3S).\\n\\nTodos os meses desde junho de 2023 —ou seja, 13 meses consecutivos— foram classificados como os mais quentes do planeta desde o início dos registos, em comparação com o mês correspondente nos anos anteriores, disse o Copernicus.\\n\\nNo ano passado, quatro dias consecutivos bateram o recorde, de 3 a 6 de julho, em consequência das alterações climáticas provocadas pelas atividades humanas, sobretudo a queima de combustíveis fósseis. Em 2023, este quadro levou a dias de calor extremo em todo o hemisfério norte.\\n\\nAntes de julho de 2023, o recorde da temperatura média mundial diária tinha sido de 16,8°C, a 13 de agosto de 2016, segundo o observatório europeu. Desde 3 de julho de 2023, 57 dias ultrapassaram este índice.\\n\\nAlguns cientistas apontam que 2024 poderá superar 2023 como o ano mais quente de que há registo, uma vez que as alterações climáticas e o fenómeno climático natural El Niño —que terminou em abril— fizeram subir ainda mais as temperaturas este ano.\\n\\nO observatório Copernicus, no entanto, é cauteloso ao comentar esta possibilidade. \"Por enquanto, 2024 está suficientemente quente para que o ano inteiro\" bata o recorde, disse o serviço europeu, \"mas o calor excecional registado nos últimos quatro meses de 2023 faz com que ainda seja demasiado cedo [para prever]\".\\n',\n",
       " 'label': 1,\n",
       " '__index_level_0__': 1979,\n",
       " 'input_ids': [0,\n",
       "  137399,\n",
       "  70,\n",
       "  31486,\n",
       "  111,\n",
       "  3974,\n",
       "  23,\n",
       "  70,\n",
       "  7986,\n",
       "  5,\n",
       "  180,\n",
       "  49523,\n",
       "  24182,\n",
       "  1715,\n",
       "  36,\n",
       "  879,\n",
       "  732,\n",
       "  41,\n",
       "  1479,\n",
       "  3113,\n",
       "  134950,\n",
       "  246,\n",
       "  110,\n",
       "  3307,\n",
       "  4,\n",
       "  21111,\n",
       "  22046,\n",
       "  31757,\n",
       "  128655,\n",
       "  180,\n",
       "  49523,\n",
       "  24182,\n",
       "  4,\n",
       "  952,\n",
       "  8,\n",
       "  100463,\n",
       "  4,\n",
       "  1715,\n",
       "  36,\n",
       "  879,\n",
       "  732,\n",
       "  41,\n",
       "  1479,\n",
       "  8,\n",
       "  41,\n",
       "  5059,\n",
       "  62334,\n",
       "  188,\n",
       "  10,\n",
       "  61919,\n",
       "  7964,\n",
       "  4,\n",
       "  8,\n",
       "  18172,\n",
       "  375,\n",
       "  362,\n",
       "  26620,\n",
       "  118276,\n",
       "  90,\n",
       "  54,\n",
       "  108529,\n",
       "  8,\n",
       "  39176,\n",
       "  24489,\n",
       "  313,\n",
       "  3141,\n",
       "  28447,\n",
       "  7,\n",
       "  1311,\n",
       "  1264,\n",
       "  35723,\n",
       "  7,\n",
       "  4,\n",
       "  48,\n",
       "  156231,\n",
       "  109792,\n",
       "  11,\n",
       "  5,\n",
       "  62,\n",
       "  17294,\n",
       "  28486,\n",
       "  54,\n",
       "  187,\n",
       "  253,\n",
       "  148270,\n",
       "  54,\n",
       "  33910,\n",
       "  110,\n",
       "  24182,\n",
       "  60844,\n",
       "  34,\n",
       "  362,\n",
       "  21567,\n",
       "  6463,\n",
       "  7236,\n",
       "  441,\n",
       "  292,\n",
       "  316,\n",
       "  11721,\n",
       "  76883,\n",
       "  54,\n",
       "  17164,\n",
       "  13,\n",
       "  14798,\n",
       "  4,\n",
       "  8,\n",
       "  305,\n",
       "  8,\n",
       "  100463,\n",
       "  54,\n",
       "  2373,\n",
       "  49523,\n",
       "  4,\n",
       "  8,\n",
       "  21567,\n",
       "  8318,\n",
       "  7236,\n",
       "  441,\n",
       "  5,\n",
       "  1301,\n",
       "  18785,\n",
       "  7,\n",
       "  8,\n",
       "  30713,\n",
       "  60844,\n",
       "  2198,\n",
       "  9255,\n",
       "  2],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df3f9328-4662-462b-b385-65cf4f9cadec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 2028\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2b0314d-ee2a-4340-9918-b621ebd0072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcfc6363-7f64-4c59-b06e-7b0cf7a907ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/3: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:25<00:00,  1.24it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Training loss: 1.0659, Training accuracy: 0.4882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 1/3: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:01<00:00,  4.13it/s, loss=1.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0577, Test accuracy: 0.4458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/3: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:24<00:00,  1.29it/s, loss=1.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3\n",
      "Training loss: 1.0232, Training accuracy: 0.4995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 2/3: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:01<00:00,  4.10it/s, loss=1.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0245, Test accuracy: 0.5089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/3: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:24<00:00,  1.29it/s, loss=1.05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3\n",
      "Training loss: 0.9780, Training accuracy: 0.5247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 3/3: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:01<00:00,  4.03it/s, loss=1.21]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.9834, Test accuracy: 0.5483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    # Initialize tqdm progress bar for training\n",
    "    train_progress_bar = tqdm(train_dataloader, desc=f\"Training Epoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    for batch in train_progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        #print(preds)\n",
    "        correct_predictions += (preds == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "        \n",
    "        # Update tqdm description with current loss\n",
    "        train_progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    print(f\"Training loss: {avg_train_loss:.4f}, Training accuracy: {train_accuracy:.4f}\")\n",
    "    \n",
    "    # Test phase\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct_test_predictions = 0\n",
    "    total_test_predictions = 0\n",
    "    \n",
    "    # Initialize tqdm progress bar for test\n",
    "    test_progress_bar = tqdm(test_dataloader, desc=f\"Test Epoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_progress_bar:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Calculate test accuracy\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            correct_test_predictions += (preds == labels).sum().item()\n",
    "            total_test_predictions += labels.size(0)\n",
    "            \n",
    "            # Update tqdm description with current loss\n",
    "            test_progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    avg_test_loss = test_loss / len(test_dataloader)\n",
    "    test_accuracy = correct_test_predictions / total_test_predictions\n",
    "    \n",
    "    print(f\"Test loss: {avg_test_loss:.4f}, Test accuracy: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
