{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b5570de-d44e-4a9c-a55c-8490c84a8940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/matijak/Documents/programiranje/projects/semeval/merged_data/subtask1.parquet\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "wd = Path.cwd()\n",
    "wd = wd.parent.parent\n",
    "wd = wd / 'merged_data' \n",
    "sub1 = str(wd) + '/subtask1.parquet'\n",
    "print(sub1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f55f3ef9-19df-424c-a0df-c6db341e943b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.aggregate of      lang    art_name             entity start   end       class1  \\\n",
       "0      BG  BG_670.txt              Запад   152   156   Antagonist   \n",
       "1      BG  BG_670.txt                САЩ   530   532   Antagonist   \n",
       "2      BG  BG_670.txt               НАТО   535   538   Antagonist   \n",
       "3      BG  BG_670.txt            Украйна   578   584   Antagonist   \n",
       "4      BG  BG_670.txt  украински войници   633   649     Innocent   \n",
       "...   ...         ...                ...   ...   ...          ...   \n",
       "2530   PT  PT_159.txt              China   371   375     Innocent   \n",
       "2531   PT   PT_74.txt           Pokrovsk  1139  1146     Innocent   \n",
       "2532   PT   PT_31.txt            Ucrânia   313   319   Antagonist   \n",
       "2533   PT   PT_31.txt                EUA   327   329   Antagonist   \n",
       "2534   PT   PT_31.txt            Moscovo  1999  2005  Protagonist   \n",
       "\n",
       "                                          classes2  \\\n",
       "0     [Conspirator, Instigator, Foreign Adversary]   \n",
       "1                                     [Instigator]   \n",
       "2                                     [Instigator]   \n",
       "3                              [Foreign Adversary]   \n",
       "4                                         [Victim]   \n",
       "...                                            ...   \n",
       "2530                                      [Victim]   \n",
       "2531                                      [Victim]   \n",
       "2532                           [Foreign Adversary]   \n",
       "2533                           [Foreign Adversary]   \n",
       "2534                                    [Guardian]   \n",
       "\n",
       "                                                   text  \n",
       "0     Опитът на колективния Запад да „обезкърви Руси...  \n",
       "1     Опитът на колективния Запад да „обезкърви Руси...  \n",
       "2     Опитът на колективния Запад да „обезкърви Руси...  \n",
       "3     Опитът на колективния Запад да „обезкърви Руси...  \n",
       "4     Опитът на колективния Запад да „обезкърви Руси...  \n",
       "...                                                 ...  \n",
       "2530  A transição energética\\n\\nMultiplicam-se os fe...  \n",
       "2531  Rússia assume controlo de mais uma povoação no...  \n",
       "2532  Quais foram as consequências do ataque de Iska...  \n",
       "2533  Quais foram as consequências do ataque de Iska...  \n",
       "2534  Quais foram as consequências do ataque de Iska...  \n",
       "\n",
       "[2535 rows x 8 columns]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(sub1)\n",
    "#df.head(n=20)\n",
    "df.aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b12c647a-ba86-4758-8921-14456a3908d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def labelNum(row):\n",
    "    if row['class1'] == 'Antagonist':\n",
    "        return int(0)\n",
    "    if row['class1'] == 'Innocent':\n",
    "        return int(1)\n",
    "    if row['class1'] == 'Protagonist':\n",
    "        return int(2)\n",
    "def cleanText(row):\n",
    "    text = str(row['text'])\n",
    "    #text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = text.replace('\\n',' ').replace('  ', ' ')\n",
    "    return text\n",
    "\n",
    "df['label'] = df.apply(labelNum,axis=1)\n",
    "#print(df['label'].value_counts(),\n",
    "#df['class1'].value_counts())\n",
    "#df['input'] = df['text']\n",
    "df['input'] = df.apply(cleanText,axis=1)\n",
    "#print(df['input'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23355896-bef2-480e-a0b7-356f420be97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.aggregate of                                                   input  label\n",
       "0     Опитът на колективния Запад да „обезкърви Руси...      0\n",
       "1     Опитът на колективния Запад да „обезкърви Руси...      0\n",
       "2     Опитът на колективния Запад да „обезкърви Руси...      0\n",
       "3     Опитът на колективния Запад да „обезкърви Руси...      0\n",
       "4     Опитът на колективния Запад да „обезкърви Руси...      1\n",
       "...                                                 ...    ...\n",
       "2530  A transição energética Multiplicam-se os fenóm...      1\n",
       "2531  Rússia assume controlo de mais uma povoação no...      1\n",
       "2532  Quais foram as consequências do ataque de Iska...      0\n",
       "2533  Quais foram as consequências do ataque de Iska...      0\n",
       "2534  Quais foram as consequências do ataque de Iska...      2\n",
       "\n",
       "[2535 rows x 2 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.loc[ : , ['input','label']]\n",
    "data.aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e23b119-dd99-4617-8517-dcc30b30475f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "lang                                                       EN\n",
      "art_name                                     EN_UA_103861.txt\n",
      "entity                                                Chinese\n",
      "start                                                     791\n",
      "end                                                       797\n",
      "class1                                             Antagonist\n",
      "classes2                                                [Spy]\n",
      "text        The World Needs Peacemaker Trump Again \\n\\n by...\n",
      "label                                                       0\n",
      "input       The World Needs Peacemaker Trump Again  by Jef...\n",
      "Name: 448, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizerFast\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-base\", num_labels=3).to(device)\n",
    "tokenizer = XLMRobertaTokenizerFast.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['input'], padding=True, truncation=True, max_length=1024, return_offsets_mapping=True)\n",
    "df_en = df[ df['lang'] == 'EN']\n",
    "test_row = df_en.iloc[0]\n",
    "print(test_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3178a871-3179-4c3e-b579-1499f39c967d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785 792 791 798\n",
      "Chinese\n",
      "Chinese\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def find_all_substring_start_end(text, substring):\n",
    "    # Use re.finditer to find all occurrences of the substring in the text\n",
    "    matches = re.finditer(re.escape(substring), text)\n",
    "    \n",
    "    # Collect the start and end indices of all matches\n",
    "    positions = [(match.start(), match.end()) for match in matches]\n",
    "    \n",
    "    return positions\n",
    "def adjust_start_end(org_text,cl_text,start,end,entity):\n",
    "    ss1 = find_all_substring_start_end(org_text,entity)\n",
    "    ss2 = find_all_substring_start_end(cl_text,entity)\n",
    "    i = ss1.index((start,end+1))\n",
    "    return ss2[i][0],ss2[i][1]\n",
    "\n",
    "astart,aend = adjust_start_end(str(test_row['text']),str(test_row['input']),int(test_row['start']),int(test_row['end']),test_row['entity'])\n",
    "print(astart,aend,int(test_row['start']),int(test_row['end'])  + 1)\n",
    "print(test_row['text'][ int(test_row['start'])  : int(test_row['end'])  + 1])\n",
    "print(test_row['input'][astart : aend])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aeb3d8bd-8980-4aa3-a88d-b2b9bcc2fafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = preprocess_function(test_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70da79c2-5894-42de-9cf4-31a03b694a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n",
      "180 76438\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(tokenizer.convert_ids_to_tokens(ids = st['input_ids']))\n",
    "offsets = st['offset_mapping']\n",
    "#print(offsets)\n",
    "#print(test_row['input'][offsets[7][0] : offsets[7][1]])\n",
    "#print(test_row['start'],test_row['end'],test_row['entity'],test_row['text'][791:797+1])\n",
    "#print(test_row['input'])\n",
    "i2 =offsets.index((astart,aend))\n",
    "print(i2)\n",
    "ID = st['input_ids'][i2]\n",
    "print(i2,ID)\n",
    "#print(offsets[i2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98a30657-f440-40dd-8dd6-fc5070da875b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1117\n",
      "9 10\n",
      "0 512 171 191\n",
      "9 tensor(76438, device='cuda:0')\n",
      "torch.Size([1, 20, 768]) tensor([-3.8030e-02,  6.1766e-02, -1.2041e-02,  8.1261e-02,  1.1645e-01,\n",
      "        -4.1574e-02, -6.8827e-02,  1.6705e-01, -1.3724e-02,  1.4196e-01,\n",
      "         2.3124e-01, -2.4499e-02,  2.5300e-01, -3.3634e-02, -5.2891e-02,\n",
      "         2.0294e-02,  3.6776e-02, -4.3493e-02,  1.2598e-01,  2.5545e-02,\n",
      "        -2.6041e-02, -1.8180e-03, -1.1143e-01,  9.0330e-02, -1.8791e-02,\n",
      "         4.0260e-02, -4.5485e-02, -2.6283e-02, -2.2984e-02,  2.0385e-02,\n",
      "        -1.4176e-02,  8.2748e-03,  6.8492e-02,  2.7737e-02, -8.3461e-03,\n",
      "         1.3725e-01,  5.7024e-03, -8.9304e-04,  8.3084e-03,  8.8177e-02,\n",
      "         7.7985e-02,  4.8468e-02, -1.3107e-02,  6.6338e-02,  7.3917e-02,\n",
      "        -2.3748e-02,  4.6240e-02,  3.9508e-02,  5.5423e-02, -7.5599e-02,\n",
      "        -3.2826e-02,  2.0258e-01,  5.1928e-02,  1.4441e-01,  8.6287e-02,\n",
      "         5.0944e-02,  1.2601e-02, -5.3017e-02, -2.9732e-02, -6.0536e-03,\n",
      "         8.2299e-02,  3.9527e-02, -8.0973e-03,  4.7182e-02,  1.6261e-01,\n",
      "        -3.3533e-02, -1.6092e-02, -1.9353e-02,  5.0268e-02, -6.9006e-02,\n",
      "         8.4537e-02, -1.1258e-01,  3.2131e-01, -2.5858e-02, -1.7276e-01,\n",
      "         8.5452e-03,  8.4904e-02,  2.1315e-02, -1.0921e-02,  4.0029e-03,\n",
      "        -5.4180e-02,  1.3960e-01,  1.2203e-02,  5.2970e-02,  7.2474e-02,\n",
      "         8.2025e-02, -4.6536e-02,  3.5367e-02,  5.6401e-02,  2.0962e-01,\n",
      "         2.0542e-02,  8.8749e-03,  7.8943e-02,  1.0604e-01,  7.8541e-02,\n",
      "         3.1800e-02,  5.4095e-02,  3.1444e-03,  2.1072e-02, -7.6910e-02,\n",
      "        -4.5666e-02, -1.7851e-03, -2.6514e-02,  2.1606e-01, -6.1802e-02,\n",
      "        -5.7647e-02, -3.2388e-02,  7.3029e-02,  1.1308e-01,  9.5027e-02,\n",
      "         1.3373e-01,  2.7582e-02,  3.2133e-01, -9.4939e-02,  1.7049e-01,\n",
      "         2.2063e-02, -3.8408e-02,  1.5492e-01,  7.5260e-02, -1.1335e-01,\n",
      "         1.6329e-02, -4.4915e-02,  5.0280e-02,  4.3211e-02, -5.5476e-02,\n",
      "        -1.7774e-02, -7.9590e-02,  2.6654e-04,  1.7907e-02, -2.5956e-01,\n",
      "         1.3282e-02, -2.0715e-02,  2.0063e-02,  3.1694e-02,  1.2489e-03,\n",
      "        -9.8466e-03,  7.8659e-02,  7.0457e-02,  6.3931e-02,  9.6142e-02,\n",
      "         1.0364e-01, -1.6008e-01, -2.6795e-02, -1.8603e-03, -2.2494e-02,\n",
      "         9.5654e-01,  9.9044e-02, -1.7276e-01,  2.4789e-02,  2.2128e-01,\n",
      "        -8.8571e-02,  3.3241e-01, -1.1092e+00,  2.2566e-02, -2.0069e-02,\n",
      "         9.9264e-02, -8.7255e-03,  1.0228e-02, -1.0755e-01, -1.3946e-02,\n",
      "         4.2949e-02,  1.4578e-01,  2.4256e-02, -7.4205e-02, -7.0172e-02,\n",
      "         3.2939e-02,  7.2648e-02, -5.9647e-02,  1.3614e-02, -3.6524e-02,\n",
      "         1.9170e-02,  3.8771e-02,  3.0300e-02, -7.0005e-04,  1.7123e-02,\n",
      "         1.1514e-01,  3.8992e-02,  6.8491e-02, -4.7691e-03, -8.5641e-02,\n",
      "         1.0160e-01, -7.9294e-02, -5.2569e-02,  5.5999e-02, -2.3635e-02,\n",
      "        -4.6873e-02,  3.8192e-02, -6.4740e-02, -3.7136e-02, -5.2941e-02,\n",
      "        -1.8990e-02, -6.3936e-02, -1.2822e-01,  7.1316e-02,  1.0720e-02,\n",
      "        -3.6311e-03, -2.5343e-02,  4.1352e-03,  7.0448e-02, -1.0153e-01,\n",
      "         5.7532e-02,  6.6063e-02,  6.2399e-02, -1.4261e-01, -7.3626e-02,\n",
      "        -1.7878e-01,  2.4540e-02,  3.0262e-02,  4.9583e-02,  1.0105e-01,\n",
      "         5.1129e-02, -8.2844e-02, -3.5683e-02, -2.0093e-02, -3.2011e-02,\n",
      "        -7.9089e-02, -8.5386e-02,  3.0177e-02,  6.4007e-02,  5.2832e-02,\n",
      "        -1.3261e-01,  7.8211e-02,  2.3777e-02,  8.8010e-02, -9.0363e-03,\n",
      "         5.5237e-02,  7.1226e-02, -3.6877e-02,  9.1758e-02, -4.2511e-02,\n",
      "         2.8636e-03,  2.4043e-02,  6.4682e-02, -1.9622e-02, -8.3723e-02,\n",
      "         4.5212e-02, -9.2995e-02, -6.5538e-02,  6.2807e-02, -2.7823e-02,\n",
      "         6.7781e-04,  1.8552e-02,  5.1733e-04,  1.7303e-02,  1.0750e-01,\n",
      "         1.4258e-02,  8.3409e-02,  8.1824e-02, -1.8451e-01,  2.8496e-03,\n",
      "        -1.2528e-02,  6.8383e-02, -5.1574e-02, -4.2552e-03, -8.3865e-02,\n",
      "        -1.0838e-01, -2.4747e-02,  1.0282e-02, -3.5684e-02,  5.2323e-02,\n",
      "         2.6039e-02,  6.5946e-02,  1.5312e-02, -1.2540e-01,  5.7906e-02,\n",
      "         1.8845e-02,  2.3652e-01,  2.9948e-02, -1.2413e-02, -2.1380e-02,\n",
      "        -1.2359e-01,  1.3094e-01,  9.5712e-02,  5.3510e-02, -2.3978e-02,\n",
      "         5.9091e-02,  1.6239e-03,  8.9671e-02,  2.4543e-02, -2.0321e-02,\n",
      "         1.1599e-01,  9.0632e-02, -7.9592e-02,  6.1270e-02,  8.0943e-03,\n",
      "         7.4308e-02,  2.2186e-01,  1.6673e-03,  1.2069e-01, -6.0511e-02,\n",
      "        -2.8816e-02,  5.2108e-02, -2.1223e-02,  9.2861e-02,  1.3563e-01,\n",
      "        -2.1347e-02,  8.1081e-03, -3.6757e-03, -1.3088e-01,  1.7908e-01,\n",
      "        -2.3274e-02,  7.4295e-02, -5.8356e-02, -5.3637e-02,  6.4288e-02,\n",
      "         1.8424e-01,  2.0543e-01,  2.0802e-02, -1.3768e-01,  9.8708e-02,\n",
      "        -3.2084e-02, -2.0436e-02, -1.1992e-01, -1.7075e-01, -2.4786e-01,\n",
      "        -4.3169e-03, -2.0316e-01,  1.1798e-01,  8.0900e-02,  2.6956e-02,\n",
      "         7.1611e-02,  1.9133e-02,  1.1218e-01, -8.6963e-03,  2.2835e-02,\n",
      "        -7.0055e-02,  4.5298e-02, -6.2289e-02, -7.1889e-03,  6.9742e-02,\n",
      "         1.6339e-02,  3.1779e-03,  2.0930e-02,  1.5358e-01, -2.9196e-01,\n",
      "        -1.2029e-02,  8.0673e-02, -2.7764e-02,  5.0297e-02,  3.0821e-02,\n",
      "         5.9108e-02,  2.3683e-02,  2.3439e-01,  3.8103e-02,  7.0554e-02,\n",
      "         3.1818e-02,  1.7025e-02,  2.1808e-01, -9.7195e-03,  1.8578e-02,\n",
      "         8.5768e-02, -4.8666e-02, -7.0653e-02, -6.1622e-02, -6.7966e-02,\n",
      "        -9.1076e-02,  1.0827e-01,  1.8970e-01,  1.4832e-03,  4.3901e-02,\n",
      "        -5.0458e-02, -9.8036e-02,  8.8775e-03,  5.6235e-02,  2.5277e-02,\n",
      "        -3.0438e-02, -1.3160e-01,  2.0479e-02,  6.0939e-02, -6.1384e-02,\n",
      "        -1.3964e-01,  1.9910e-02,  1.7841e-02, -1.8705e-03, -4.3375e-02,\n",
      "         2.6851e-02, -2.5960e-02, -2.6336e-01,  1.5729e-02,  1.1862e-01,\n",
      "         8.6366e-02,  8.2309e-02, -1.1689e-01, -1.7948e-02,  1.9577e-02,\n",
      "         7.5876e-02,  7.8419e-02,  1.7402e-01, -1.5483e-02, -2.7090e-02,\n",
      "         6.2497e-02, -1.2078e-02, -9.0270e-02,  1.2563e-02,  8.0268e-02,\n",
      "        -1.0112e-01,  3.8850e-02, -8.3465e-02, -1.0747e-02, -1.5560e-01,\n",
      "         8.5351e-02,  2.1258e-02, -1.0269e-01, -2.8666e-02,  1.3811e-02,\n",
      "         8.3246e-02, -2.1514e-02, -6.7995e-02,  3.9475e-02, -1.0704e-02,\n",
      "         1.3376e-01, -1.9728e-01,  2.6991e-03, -5.7755e-03,  1.4789e-02,\n",
      "        -2.4303e-02,  9.4907e-02,  2.3762e-02, -3.5960e-02, -1.9105e-02,\n",
      "         4.0905e-02, -9.1560e-03, -3.0540e-02, -8.1315e-03,  7.4496e-02,\n",
      "        -2.0672e-02, -4.1172e-02,  1.8924e-02, -2.5323e-02, -2.0807e-02,\n",
      "         2.6702e-02,  2.2394e-02, -4.4337e-02,  1.8217e-02,  3.1265e-02,\n",
      "         9.2926e-02,  2.0720e-02, -3.6478e-02, -2.6237e-02, -3.2604e-02,\n",
      "        -4.6200e-02, -1.6467e-02, -2.3323e-02, -8.3732e-02, -1.8280e-02,\n",
      "        -1.6406e-02,  3.1543e-02, -1.2887e-02, -8.6575e-02,  5.8373e-02,\n",
      "         2.7959e-02, -6.3496e-02,  3.0037e-02,  6.7937e-03, -4.7400e-02,\n",
      "         1.0674e-01, -1.9502e-03,  4.5759e-02,  9.6342e-03, -1.5683e+00,\n",
      "        -6.3052e-02, -5.2193e-02, -2.7428e-02,  6.0853e-02,  6.9653e-02,\n",
      "        -1.6382e-02, -2.1747e-02, -4.1443e-03,  6.4581e-02,  2.6793e-02,\n",
      "        -2.0819e-02, -4.9246e-02, -5.1670e-03,  9.8814e-02,  7.6870e-02,\n",
      "        -1.4591e-02,  5.5861e-02,  6.0538e-02, -1.3603e-02, -2.4553e-02,\n",
      "         8.0317e-03,  1.1869e-02, -8.4365e-02,  2.1360e-02,  9.1987e-02,\n",
      "         1.5438e-02,  7.4106e-02,  1.5098e-01, -5.7583e-02, -5.6060e-02,\n",
      "        -1.8536e-01, -1.0011e-01,  1.4269e-02,  1.9745e-02, -5.8103e-02,\n",
      "         4.1429e-02,  8.2186e-04, -8.4299e-02, -1.3792e-01, -3.5452e-02,\n",
      "        -1.9784e-02,  5.3681e-02,  1.5406e-02,  2.6427e-02, -8.4618e-02,\n",
      "         2.8252e-02, -1.4507e-01, -8.1387e-02,  1.5655e-03, -2.4574e-02,\n",
      "         2.4507e-01,  1.0308e-02, -1.1761e-01,  1.6422e-02, -7.8796e-02,\n",
      "         8.4380e-02, -2.4340e-02,  3.6469e-02, -1.4531e-02, -5.1815e-02,\n",
      "        -3.0986e-02,  5.9212e-02, -1.3883e-02,  3.0567e-02,  3.0307e-02,\n",
      "        -4.3629e-02,  1.0010e-01, -2.9892e-01, -5.5805e-02,  1.0951e-01,\n",
      "         5.3011e-02,  7.9789e-02,  1.1516e-01, -1.1533e-01,  1.9450e-01,\n",
      "        -6.8906e-02, -2.7601e-02,  2.0106e-02,  6.4964e-03,  2.2717e-02,\n",
      "         7.2796e-02,  2.3725e-02,  5.0779e-02, -7.5827e-02, -1.7616e-02,\n",
      "        -1.5121e-02,  5.3483e-02, -4.1910e-02,  1.9920e-02,  9.6332e-02,\n",
      "         2.0472e-02, -1.5391e-01, -8.1440e-02,  9.5155e-02, -2.0923e-01,\n",
      "         7.5073e-02, -5.7632e-02,  2.5965e-02,  8.6174e-02,  7.5034e-03,\n",
      "         1.0808e-01, -7.6253e-02, -5.0856e-03,  1.0139e-02,  5.2991e-03,\n",
      "        -1.8998e-02,  3.8990e-02,  3.6193e-02,  3.0938e-02,  1.4872e-03,\n",
      "         1.7027e-01, -8.4224e-03, -4.4940e-02, -2.1206e-01, -9.5026e-03,\n",
      "        -8.2680e-02, -1.0353e-02, -3.7010e-02,  1.5147e-01, -4.7793e-02,\n",
      "        -4.2268e-02, -7.6953e-02,  1.2240e-01,  7.5919e-02,  1.8485e-01,\n",
      "         1.9221e-02,  2.5136e-02,  2.0695e-01, -5.8285e+00,  1.7792e-01,\n",
      "         7.0246e-02,  2.2446e-02, -2.7051e-02, -5.4906e-02,  4.5150e-02,\n",
      "        -5.2963e-02,  5.3390e-02,  1.3291e-02,  3.1824e-02, -9.2264e-03,\n",
      "         1.0069e-02,  1.5165e-01,  9.7825e-03,  8.9717e-02,  6.9592e-02,\n",
      "         8.0218e-02, -5.1003e-03,  3.6819e-02,  4.2206e-03, -1.4729e-02,\n",
      "         1.0935e-01,  1.9226e-01, -1.4190e-02, -7.0510e-03, -2.7196e-02,\n",
      "        -5.6418e-02, -3.9116e-02, -5.0734e-02,  9.6853e-04,  1.3471e-02,\n",
      "        -3.1926e-03,  6.6071e-02, -4.8226e-02,  1.3845e-01, -7.3038e-02,\n",
      "         2.5675e-02,  3.9845e-02, -1.4604e-01, -1.5321e-02, -6.3769e-02,\n",
      "        -7.5871e-02, -2.1862e-03, -1.8228e-02, -1.5647e-01,  4.5993e-02,\n",
      "         4.4600e-03, -3.2351e-02,  4.4144e-02,  3.9099e-02,  7.4151e-02,\n",
      "         2.6912e-03,  1.8916e-03, -3.2095e-02,  9.2657e-02,  1.0438e-01,\n",
      "         9.4891e-03,  1.6233e-01,  3.8349e-02,  7.7182e-02, -2.1276e-01,\n",
      "        -3.6492e-02, -4.8705e-02,  1.1845e-03,  8.4267e-02,  1.4398e-01,\n",
      "        -1.7699e-02, -6.0121e-02,  1.7612e-02,  5.6331e-02,  4.1545e-02,\n",
      "         1.5146e-01,  2.9262e-02, -5.4161e-02,  3.1632e-02,  2.5590e-02,\n",
      "        -5.3299e-02,  6.6488e-02,  8.2566e-02,  1.2219e-01, -4.3834e-02,\n",
      "        -2.6575e-02, -2.6346e-04,  8.6399e-02, -4.2904e-02,  2.6754e-01,\n",
      "        -4.0046e-02,  2.5887e-04,  5.7822e-02,  1.2847e-01, -1.3664e-02,\n",
      "         6.6781e-02,  2.1210e-02,  3.5235e-02, -2.5013e-02, -6.1173e-02,\n",
      "        -3.6827e-02,  1.7577e-02,  1.5322e-02,  1.1950e-01, -6.0020e-02,\n",
      "        -3.8793e-02, -6.3736e-02,  7.2636e-02,  1.2762e-02, -2.2020e-01,\n",
      "         1.1857e-01, -5.4785e-03,  1.8338e-02, -5.0128e-02,  1.3424e-01,\n",
      "         1.8895e-02,  3.6574e-02,  5.6588e-02,  4.9896e-02,  7.6692e-02,\n",
      "        -1.1628e-01, -7.4651e-02,  2.3393e-01,  1.4519e-02,  4.6062e-02,\n",
      "        -2.9626e-02, -2.9844e-02,  9.5501e-02,  4.9628e-02,  1.6374e-02,\n",
      "         2.2240e-02,  4.8958e-02,  4.2542e-02, -1.0187e-02, -3.0338e-02,\n",
      "         1.3051e-01, -1.4022e-02,  5.8869e-02, -2.9133e-02,  3.8883e-02,\n",
      "        -8.6945e-02, -8.4184e-03,  2.3912e-02,  1.5875e-01, -1.7088e-01,\n",
      "         1.8802e-02, -1.2062e-01, -3.6818e-02,  1.4377e-02,  2.0282e-02,\n",
      "         8.3468e-02,  5.4870e-02, -7.5138e-02,  2.0580e-02, -1.2086e-02,\n",
      "         3.1952e-02,  1.8025e+01,  5.6510e-02,  2.1165e-02, -3.9347e-02,\n",
      "        -6.7978e-03, -2.2931e-02, -4.2664e-03,  2.9439e-02, -3.3396e-01,\n",
      "        -1.4705e-02,  2.5412e-02,  8.3593e-02, -1.0512e-01, -1.9392e-02,\n",
      "         1.9773e-02,  2.9695e-02,  3.5207e-02, -2.6570e-02,  1.7659e-01,\n",
      "         5.1333e-02,  4.6748e-04,  9.0139e-02, -7.6965e-03,  8.5707e-02,\n",
      "         1.2781e-01,  4.0050e-02,  2.3497e-01], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "input_text = test_row['input']\n",
    "\n",
    "def preprocess_function2(examples):\n",
    "    return tokenizer(examples, padding=True, truncation=True, return_tensors='pt',max_length=2048)\n",
    "    \n",
    "inputs = preprocess_function2(input_text)\n",
    "\n",
    "def slices(index,size):\n",
    "    print(size)\n",
    "    if index < 255:\n",
    "        return 0,512\n",
    "    elif index >= 255:\n",
    "        if index + 256 > size:\n",
    "            return index-(512-(size-index)), size\n",
    "        else:\n",
    "            return index-255,index+256+1\n",
    "\n",
    "def slices2(index,size,context_size):\n",
    "    lower_c = int(context_size/2-1)\n",
    "    upper_c = int(context_size/2)\n",
    "    print(lower_c,upper_c)\n",
    "    if index < lower_c:\n",
    "        return 0,context_size\n",
    "    elif index >= lower_c:\n",
    "        if index + upper_c > size:\n",
    "            return index-(context_size-(size-index)), size\n",
    "        else:\n",
    "            return index-lower_c,index+upper_c+1  \n",
    "\n",
    "supper,slower = slices(i2,len(inputs['input_ids'][0]))\n",
    "supper2,slower2 = slices2(i2,len(inputs['input_ids'][0]),20)\n",
    "print(supper,slower,supper2,slower2)\n",
    "\n",
    "new_id = inputs['input_ids'][0][supper2:slower2].to(device)\n",
    "new_id2 = new_id.reshape(1,-1)\n",
    "new_att = inputs['attention_mask'][0][supper2:slower2].to(device)\n",
    "new_att2 = new_att.reshape(1,-1)\n",
    "niputs = {\n",
    "    \"input_ids\" : new_id2,\n",
    "    \"attention_mask\" : new_att2\n",
    "}\n",
    "i3 = new_id.tolist().index(ID)\n",
    "print(i3,new_id[i3])\n",
    "#print(inputs['input_ids'][0][supper:slower].to(device),len(inputs2),supper,slower)\n",
    "inputs.to(device)\n",
    "#print(inputs)\n",
    "#print(niputs)\n",
    "with torch.no_grad():  # Disable gradients for inference\n",
    "    outputs = model(**niputs,output_hidden_states=True)\n",
    "hidden_states = outputs.hidden_states\n",
    "last_hs = hidden_states[-1]\n",
    "print(last_hs.shape,last_hs[0][i3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
