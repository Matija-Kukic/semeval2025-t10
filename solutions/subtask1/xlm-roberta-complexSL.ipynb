{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dbfc10c-7c17-442f-8b3a-0d07a72513d1",
   "metadata": {},
   "source": [
    "# Solution 2\n",
    "\n",
    "### Using xlm-roberta for vectorization and then a simple neural net for label classification\n",
    "\n",
    "#### Let's load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf801245-b8c6-4a11-87f5-ba5088e8442c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/matijak/Documents/programiranje/projects/semeval/merged_data/subtask1.parquet\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "wd = Path.cwd()\n",
    "wd = wd.parent.parent\n",
    "wd = wd / 'merged_data' \n",
    "sub1 = str(wd) + '/subtask1.parquet'\n",
    "print(sub1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1c900b5-2170-4712-b87d-5eb73adcfee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>art_name</th>\n",
       "      <th>entity</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>class1</th>\n",
       "      <th>classes2</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_670.txt</td>\n",
       "      <td>Запад</td>\n",
       "      <td>152</td>\n",
       "      <td>156</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Conspirator, Instigator, Foreign Adversary]</td>\n",
       "      <td>Опитът на колективния Запад да „обезкърви Руси...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_670.txt</td>\n",
       "      <td>САЩ</td>\n",
       "      <td>530</td>\n",
       "      <td>532</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Instigator]</td>\n",
       "      <td>Опитът на колективния Запад да „обезкърви Руси...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_670.txt</td>\n",
       "      <td>НАТО</td>\n",
       "      <td>535</td>\n",
       "      <td>538</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Instigator]</td>\n",
       "      <td>Опитът на колективния Запад да „обезкърви Руси...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_670.txt</td>\n",
       "      <td>Украйна</td>\n",
       "      <td>578</td>\n",
       "      <td>584</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Foreign Adversary]</td>\n",
       "      <td>Опитът на колективния Запад да „обезкърви Руси...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_670.txt</td>\n",
       "      <td>украински войници</td>\n",
       "      <td>633</td>\n",
       "      <td>649</td>\n",
       "      <td>Innocent</td>\n",
       "      <td>[Victim]</td>\n",
       "      <td>Опитът на колективния Запад да „обезкърви Руси...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang    art_name             entity start  end      class1  \\\n",
       "0   BG  BG_670.txt              Запад   152  156  Antagonist   \n",
       "1   BG  BG_670.txt                САЩ   530  532  Antagonist   \n",
       "2   BG  BG_670.txt               НАТО   535  538  Antagonist   \n",
       "3   BG  BG_670.txt            Украйна   578  584  Antagonist   \n",
       "4   BG  BG_670.txt  украински войници   633  649    Innocent   \n",
       "\n",
       "                                       classes2  \\\n",
       "0  [Conspirator, Instigator, Foreign Adversary]   \n",
       "1                                  [Instigator]   \n",
       "2                                  [Instigator]   \n",
       "3                           [Foreign Adversary]   \n",
       "4                                      [Victim]   \n",
       "\n",
       "                                                text  \n",
       "0  Опитът на колективния Запад да „обезкърви Руси...  \n",
       "1  Опитът на колективния Запад да „обезкърви Руси...  \n",
       "2  Опитът на колективния Запад да „обезкърви Руси...  \n",
       "3  Опитът на колективния Запад да „обезкърви Руси...  \n",
       "4  Опитът на колективния Запад да „обезкърви Руси...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(sub1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727d758d-c579-42fa-914b-9fd854e0ebca",
   "metadata": {},
   "source": [
    "#### Now lets clean article text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d3d00c4-6f4d-4850-be15-fdf7a80f660d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lang                                                       EN\n",
       "art_name                                     EN_UA_103861.txt\n",
       "entity                                                Chinese\n",
       "start                                                     791\n",
       "end                                                       797\n",
       "class1                                             Antagonist\n",
       "classes2                                                [Spy]\n",
       "text        The World Needs Peacemaker Trump Again \\n\\n by...\n",
       "label                                                       0\n",
       "input       The World Needs Peacemaker Trump Again  by Jef...\n",
       "Name: 448, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def labelNum(row):\n",
    "    if row['class1'] == 'Antagonist':\n",
    "        return int(0)\n",
    "    if row['class1'] == 'Innocent':\n",
    "        return int(1)\n",
    "    if row['class1'] == 'Protagonist':\n",
    "        return int(2)\n",
    "def cleanText(row):\n",
    "    text = str(row['text'])\n",
    "    #text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = text.replace('\\n',' ').replace('  ', ' ')\n",
    "    return text\n",
    "df['label'] = df.apply(labelNum,axis=1)\n",
    "df['input'] = df.apply(cleanText,axis=1)\n",
    "df.loc[448]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f408c987-cee4-4310-97e9-549d19287c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang                                                       BG\n",
      "art_name                                           BG_670.txt\n",
      "entity                                                  Запад\n",
      "start                                                     152\n",
      "end                                                       156\n",
      "class1                                             Antagonist\n",
      "classes2         [Conspirator, Instigator, Foreign Adversary]\n",
      "text        Опитът на колективния Запад да „обезкърви Руси...\n",
      "label                                                       0\n",
      "input       Опитът на колективния Запад да „обезкърви Руси...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def find_all_substring_start_end(text, substring):\n",
    "    # Use re.finditer to find all occurrences of the substring in the text\n",
    "    matches = re.finditer(re.escape(substring), text)\n",
    "    \n",
    "    # Collect the start and end indices of all matches\n",
    "    positions = [(match.start(), match.end()) for match in matches]\n",
    "    \n",
    "    return positions\n",
    "def adjust_start_end(row):\n",
    "    org_text,cl_text,start,end,entity = str(row['text']),str(row['input']),int(row['start']),int(row['end']),str(row['entity'])\n",
    "    ss1 = find_all_substring_start_end(org_text,entity)\n",
    "    ss2 = find_all_substring_start_end(cl_text,entity)\n",
    "    #print(ss1,ss2)\n",
    "    #print(row['text'][start:end])\n",
    "    a = 0\n",
    "    for i in range(len(ss1)):\n",
    "        if abs((ss1[i][0] - start) + (ss1[i][1] - end) ) <= 2:\n",
    "            a = i\n",
    "            break\n",
    "    if org_text[ss1[a][0]:ss1[a][1]] != cl_text[ss2[a][0]:ss2[a][1]]:\n",
    "        print(\"ERROR!\")\n",
    "    return ss2[a][0],ss2[a][1]\n",
    "print(df.loc[0])\n",
    "df['new_start_end'] = df.apply(adjust_start_end,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "790f5e9e-5e11-488f-9361-aafa6be270fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizerFast\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-base\", num_labels=3).to(device)\n",
    "tokenizer = XLMRobertaTokenizerFast.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['input'], padding=True, truncation=True,max_length=8192,return_offsets_mapping=True)\n",
    "\n",
    "data = df.loc[ : , ['input','label','new_start_end','entity']]\n",
    "data['tokenized']=data.apply(preprocess_function,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3201b7e0-58cf-4555-a772-6dd49a362762",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [0, 1089, 22617, 1669, 29, 47829, 2097, 32275, 69, 137, 197, 35359, 53335, 2827, 40053, 155, 135, 128601, 29, 12747, 226, 49, 94511, 137, 2687, 591, 7533, 135, 10099, 54293, 35, 25977, 245, 131732, 155, 35, 18777, 183, 159814, 153, 1089, 22617, 1669, 29, 47829, 2097, 32275, 69, 137, 197, 35359, 53335, 2827, 40053, 155, 135, 128601, 29, 12747, 226, 49, 94511, 137, 2687, 591, 7533, 135, 10099, 54293, 35, 25977, 245, 131732, 155, 35, 18777, 183, 159814, 4629, 69, 62086, 16846, 33318, 4, 3756, 77, 63084, 15258, 1669, 29, 92173, 59, 6208, 29, 6047, 39540, 197, 14114, 16641, 44267, 5, 61216, 193342, 43219, 84535, 2262, 36690, 45961, 213358, 222, 31458, 2549, 29, 45775, 59, 29, 103285, 245, 34078, 29, 40108, 47239, 303, 3512, 105, 22192, 4, 12434, 47853, 19737, 245, 6, 163308, 183, 109560, 205, 29, 40108, 135694, 25223, 650, 447, 3873, 8458, 63522, 5, 44, 123209, 24724, 2374, 205, 29, 40108, 4, 20292, 35, 4907, 155386, 74300, 4301, 61, 51192, 205, 49, 159814, 19173, 40053, 218, 1093, 7054, 212, 5, 7932, 12210, 255, 134845, 29, 176323, 168489, 1835, 49, 27068, 29, 61, 43473, 5672, 6367, 105, 1323, 4, 3756, 77, 107935, 226, 35400, 56560, 1200, 4306, 29, 19789, 183, 41374, 35, 61683, 166631, 111998, 89, 4, 8803, 35, 157716, 22524, 245, 38273, 69, 114, 70576, 53335, 2827, 40053, 19523, 42777, 19658, 2004, 17212, 447, 3873, 8458, 63522, 5, 44, 3159, 32104, 17214, 61, 120850, 336, 29, 7631, 3738, 14933, 12332, 4, 440, 52281, 67400, 969, 123807, 4, 114, 140670, 72653, 135, 10099, 54293, 35, 25977, 245, 131732, 830, 40594, 10797, 13582, 41374, 326, 812, 812, 26012, 13110, 5, 20, 417, 231945, 40053, 89053, 129, 35458, 28476, 740, 5901, 18777, 77, 6579, 167186, 197, 237621, 29, 175432, 245, 35, 77, 6579, 12053, 20684, 209016, 11373, 212, 74958, 4, 48554, 183, 159814, 35253, 33318, 4629, 69, 62086, 2004, 84, 5514, 2582, 218, 447, 3873, 8458, 63522, 5, 17345, 137189, 44, 14927, 23394, 11373, 212, 74958, 58, 49, 57231, 32561, 29, 164110, 49, 1537, 743, 67412, 66213, 15, 5221, 104809, 78455, 1114, 247, 5724, 4404, 12053, 20684, 29, 423, 13528, 71147, 129, 159069, 29, 180774, 35, 29, 5724, 40053, 77, 4404, 11004, 336, 212, 5, 124406, 1983, 155386, 63016, 26012, 62760, 40594, 1862, 3258, 164110, 4, 975, 11849, 218, 1714, 25067, 57650, 551, 33545, 59, 3670, 5, 10604, 328, 4334, 8005, 183, 1537, 35030, 49208, 77, 231238, 79971, 53051, 245, 13053, 183, 164110, 5, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'offset_mapping': [(0, 0), (0, 1), (1, 4), (4, 6), (7, 9), (10, 18), (18, 21), (22, 27), (28, 30), (31, 32), (32, 33), (33, 36), (36, 39), (39, 41), (42, 47), (47, 48), (49, 50), (51, 57), (58, 60), (61, 67), (67, 69), (70, 71), (72, 76), (77, 78), (78, 80), (81, 84), (84, 88), (89, 90), (91, 93), (93, 95), (96, 97), (98, 100), (100, 101), (101, 104), (104, 105), (106, 107), (108, 113), (114, 116), (117, 124), (125, 128), (129, 130), (130, 133), (133, 135), (136, 138), (139, 147), (147, 150), (151, 156), (157, 159), (160, 161), (161, 162), (162, 165), (165, 168), (168, 170), (171, 176), (176, 177), (178, 179), (180, 186), (187, 189), (190, 196), (196, 198), (199, 200), (201, 205), (206, 207), (207, 209), (210, 213), (213, 217), (218, 219), (220, 222), (222, 224), (225, 226), (227, 229), (229, 230), (230, 233), (233, 234), (235, 236), (237, 242), (243, 245), (246, 253), (254, 258), (259, 261), (262, 268), (269, 274), (275, 279), (279, 280), (281, 284), (285, 287), (288, 295), (296, 302), (302, 304), (305, 307), (308, 314), (314, 315), (315, 319), (320, 322), (323, 327), (328, 330), (330, 331), (331, 333), (333, 336), (337, 345), (345, 346), (347, 351), (352, 358), (359, 364), (365, 371), (372, 376), (377, 379), (379, 381), (382, 388), (388, 389), (390, 395), (395, 398), (399, 401), (402, 409), (409, 410), (411, 413), (414, 422), (422, 423), (424, 432), (433, 435), (436, 439), (440, 444), (444, 445), (446, 448), (448, 449), (449, 451), (451, 452), (453, 456), (456, 460), (460, 465), (465, 466), (467, 468), (467, 476), (477, 479), (480, 485), (485, 487), (488, 490), (491, 494), (495, 498), (498, 500), (500, 501), (502, 503), (503, 505), (505, 508), (508, 511), (511, 512), (513, 514), (514, 517), (517, 520), (520, 522), (522, 524), (525, 527), (528, 531), (531, 532), (533, 537), (538, 539), (540, 545), (546, 553), (554, 558), (558, 562), (563, 565), (566, 571), (571, 573), (574, 575), (576, 583), (584, 589), (590, 595), (596, 597), (598, 601), (601, 603), (603, 605), (605, 606), (607, 611), (612, 616), (617, 619), (620, 627), (628, 630), (631, 640), (641, 646), (646, 648), (649, 650), (651, 656), (657, 659), (660, 662), (662, 665), (665, 668), (669, 671), (671, 672), (672, 674), (674, 675), (676, 679), (680, 682), (683, 688), (688, 690), (691, 698), (699, 703), (703, 705), (705, 709), (710, 712), (713, 717), (718, 720), (721, 732), (733, 734), (735, 745), (746, 752), (753, 763), (763, 764), (764, 765), (766, 771), (772, 773), (774, 778), (778, 782), (782, 783), (784, 788), (789, 791), (792, 794), (795, 799), (799, 802), (802, 804), (805, 810), (811, 815), (816, 821), (822, 828), (828, 830), (831, 835), (836, 837), (837, 839), (839, 842), (842, 845), (845, 846), (847, 848), (848, 849), (849, 852), (852, 856), (857, 859), (860, 867), (867, 869), (870, 872), (873, 877), (878, 883), (883, 886), (887, 890), (890, 891), (892, 895), (896, 902), (903, 904), (905, 908), (908, 912), (912, 913), (914, 916), (917, 923), (923, 926), (927, 928), (929, 931), (931, 933), (934, 935), (936, 938), (938, 939), (939, 942), (942, 944), (945, 950), (951, 954), (954, 958), (959, 970), (971, 973), (973, 975), (975, 977), (978, 984), (984, 988), (988, 989), (990, 991), (992, 993), (994, 1008), (1009, 1014), (1015, 1023), (1024, 1026), (1026, 1029), (1029, 1033), (1033, 1035), (1036, 1039), (1040, 1045), (1046, 1048), (1049, 1053), (1054, 1060), (1060, 1061), (1062, 1074), (1075, 1077), (1078, 1082), (1082, 1083), (1084, 1085), (1086, 1088), (1089, 1093), (1094, 1097), (1097, 1101), (1102, 1110), (1111, 1114), (1114, 1116), (1117, 1128), (1128, 1129), (1130, 1136), (1137, 1139), (1140, 1147), (1148, 1159), (1160, 1164), (1165, 1169), (1170, 1172), (1173, 1179), (1179, 1181), (1182, 1183), (1183, 1185), (1185, 1188), (1189, 1190), (1191, 1192), (1192, 1194), (1194, 1197), (1197, 1200), (1200, 1201), (1202, 1205), (1206, 1213), (1214, 1215), (1215, 1219), (1219, 1223), (1224, 1227), (1227, 1229), (1230, 1241), (1241, 1242), (1243, 1244), (1245, 1252), (1252, 1255), (1256, 1258), (1259, 1266), (1267, 1268), (1269, 1270), (1270, 1271), (1271, 1275), (1275, 1279), (1280, 1281), (1281, 1282), (1282, 1285), (1285, 1288), (1288, 1290), (1290, 1292), (1293, 1298), (1299, 1303), (1304, 1307), (1307, 1311), (1312, 1314), (1315, 1317), (1317, 1320), (1321, 1324), (1325, 1327), (1328, 1338), (1339, 1341), (1342, 1348), (1349, 1350), (1351, 1353), (1354, 1359), (1360, 1365), (1366, 1368), (1369, 1373), (1374, 1378), (1378, 1380), (1380, 1382), (1382, 1383), (1384, 1388), (1389, 1394), (1395, 1402), (1403, 1414), (1415, 1421), (1421, 1426), (1427, 1432), (1432, 1434), (1435, 1439), (1440, 1447), (1447, 1448), (1449, 1451), (1452, 1454), (1455, 1456), (1457, 1460), (1460, 1463), (1463, 1465), (1465, 1467), (1468, 1470), (1470, 1471), (1471, 1474), (1474, 1475), (1476, 1478), (1478, 1480), (1481, 1485), (1486, 1492), (1493, 1495), (1496, 1497), (1497, 1499), (1499, 1501), (1502, 1504), (1505, 1513), (1514, 1520), (1520, 1526), (1526, 1527), (1528, 1536), (1537, 1539), (1540, 1547), (1547, 1548), (0, 0)]}\n"
     ]
    }
   ],
   "source": [
    "print(data.iloc[0]['tokenized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9e79ca62-1259-4a16-b867-40da353e576a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data.loc[0]['tokenized'])\n",
    "def indexes(row):\n",
    "    off_mask = row['tokenized']['offset_mapping']\n",
    "    start,end = row['new_start_end'][0],row['new_start_end'][1]\n",
    "    inds = list()\n",
    "    for p in range(len(off_mask)):\n",
    "        if off_mask[p][0] >= start and off_mask[p][1] <= end:\n",
    "            if p != len(off_mask)-1:\n",
    "                inds.append(p)\n",
    "    #if len(inds) > 1:\n",
    "        #print(\"GREATER THAN 1\")\n",
    "    if len(inds) == 0:\n",
    "        print(start,end)\n",
    "    return inds\n",
    "data['indexes'] = data.apply(indexes,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ec11da4f-89c6-4618-95a2-d05c1f80a746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input            The World Needs Peacemaker Trump Again  by Jef...\n",
      "label                                                            0\n",
      "new_start_end                                           (785, 792)\n",
      "entity                                                     Chinese\n",
      "tokenized              [input_ids, attention_mask, offset_mapping]\n",
      "indexes                                                      [180]\n",
      "Name: 448, dtype: object input            जयपुर में जलवायु परिवर्तन को लेकर स्टेट लेवल ट...\n",
      "label                                                            2\n",
      "new_start_end                                           (623, 636)\n",
      "entity                                               केन्द्र सरकार\n",
      "tokenized              [input_ids, attention_mask, offset_mapping]\n",
      "indexes                                                 [162, 163]\n",
      "Name: 1000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data.loc[448],data.loc[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "81b9a4e2-900a-4d91-8be1-e0c328d1f3fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2535 2535 2535\n",
      "tensor([     0,   1089,  22617,   1669,     29,  47829,   2097,  32275,     69,\n",
      "           137,    197,  35359,  53335,   2827,  40053,    155,    135, 128601,\n",
      "            29,  12747,    226,     49,  94511,    137,   2687,    591,   7533,\n",
      "           135,  10099,  54293,     35,  25977,    245, 131732,    155,     35,\n",
      "         18777,    183, 159814,    153,   1089,  22617,   1669,     29,  47829,\n",
      "          2097,  32275,     69,    137,    197,  35359,  53335,   2827,  40053,\n",
      "           155,    135, 128601,     29,  12747,    226,     49,  94511,    137,\n",
      "          2687,    591,   7533,    135,  10099,  54293,     35,  25977,    245,\n",
      "        131732,    155,     35,  18777,    183, 159814,   4629,     69,  62086,\n",
      "         16846,  33318,      4,   3756,     77,  63084,  15258,   1669,     29,\n",
      "         92173,     59,   6208,     29,   6047,  39540,    197,  14114,  16641,\n",
      "         44267,      5,  61216, 193342,  43219,  84535,   2262,  36690,  45961,\n",
      "        213358,    222,  31458,   2549,     29,  45775,     59,     29, 103285,\n",
      "           245,  34078,     29,  40108,  47239,    303,   3512,    105,  22192,\n",
      "             4,  12434,  47853,  19737,    245,      6, 163308,    183, 109560,\n",
      "           205,     29,  40108, 135694,  25223,    650,    447,   3873,   8458,\n",
      "         63522,      5,     44, 123209,  24724,   2374,    205,     29,  40108,\n",
      "             4,  20292,     35,   4907, 155386,  74300,   4301,     61,  51192,\n",
      "           205,     49, 159814,  19173,  40053,    218,   1093,   7054,    212,\n",
      "             5,   7932,  12210,    255, 134845,     29, 176323, 168489,   1835,\n",
      "            49,  27068,     29,     61,  43473,   5672,   6367,    105,   1323,\n",
      "             4,   3756,     77, 107935,    226,  35400,  56560,   1200,   4306,\n",
      "            29,  19789,    183,  41374,     35,  61683, 166631, 111998,     89,\n",
      "             4,   8803,     35, 157716,  22524,    245,  38273,     69,    114,\n",
      "         70576,  53335,   2827,  40053,  19523,  42777,  19658,   2004,  17212,\n",
      "           447,   3873,   8458,  63522,      5,     44,   3159,  32104,  17214,\n",
      "            61, 120850,    336,     29,   7631,   3738,  14933,  12332,      4,\n",
      "           440,  52281,  67400,    969, 123807,      4,    114, 140670,  72653,\n",
      "           135,  10099,  54293,     35,  25977,    245, 131732,    830,  40594,\n",
      "         10797,  13582,  41374,    326,    812,    812,  26012,  13110,      5,\n",
      "            20,    417, 231945,  40053,  89053,    129,  35458,  28476,    740,\n",
      "          5901,  18777,     77,   6579, 167186,    197, 237621,     29, 175432,\n",
      "           245,     35,     77,   6579,  12053,  20684, 209016,  11373,    212,\n",
      "         74958,      4,  48554,    183, 159814,  35253,  33318,   4629,     69,\n",
      "         62086,   2004,     84,   5514,   2582,    218,    447,   3873,   8458,\n",
      "         63522,      5,  17345, 137189,     44,  14927,  23394,  11373,    212,\n",
      "         74958,     58,     49,  57231,  32561,     29, 164110,     49,   1537,\n",
      "           743,  67412,  66213,     15,   5221, 104809,  78455,   1114,    247,\n",
      "          5724,   4404,  12053,  20684,     29,    423,  13528,  71147,    129,\n",
      "        159069,     29, 180774,     35,     29,   5724,  40053,     77,   4404,\n",
      "         11004,    336,    212,      5, 124406,   1983, 155386,  63016,  26012,\n",
      "         62760,  40594,   1862,   3258, 164110,      4,    975,  11849,    218,\n",
      "          1714,  25067,  57650,    551,  33545,     59,   3670,      5,  10604,\n",
      "           328,   4334,   8005,    183,   1537,  35030,  49208,     77, 231238,\n",
      "         79971,  53051,    245,  13053,    183, 164110,      5,      2],\n",
      "       device='cuda:0') tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       device='cuda:0')\n",
      "[180]\n"
     ]
    }
   ],
   "source": [
    "data['list'] = data['tokenized'].apply(lambda x: x['input_ids'])\n",
    "data['attention'] = data['tokenized'].apply(lambda x: x['attention_mask'])\n",
    "ids = data['list']\n",
    "att = data['attention']\n",
    "indexes = data['indexes']\n",
    "tids = list()\n",
    "tatt = list()\n",
    "print(len(ids),len(att),len(indexes))\n",
    "for i in range(len(ids)):\n",
    "    tids.append(torch.tensor(ids[i]).to(device))\n",
    "    tatt.append(torch.tensor(att[i]).to(device))\n",
    "print(tids[0],tatt[0])\n",
    "print(indexes[448])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "82c0d314-c958-4e7f-98fa-be7c77cebd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19] tensor(76438, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "sliced_ids = list()\n",
    "sliced_ntids = list()\n",
    "sliced_att = list()\n",
    "key_inds = list()\n",
    "key_ids = list()\n",
    "\n",
    "def slices(index,size,context_size):\n",
    "    if (size<context_size):\n",
    "        return 0,size\n",
    "    lower_c = int(context_size/2-1)\n",
    "    upper_c = int(context_size/2)\n",
    "    #print(lower_c,upper_c)\n",
    "    if index < lower_c:\n",
    "        return 0,context_size\n",
    "    elif index >= lower_c:\n",
    "        if index + upper_c > size:\n",
    "            return index-(context_size-(size-index)), size\n",
    "        else:\n",
    "            return index-lower_c,index+upper_c+1  \n",
    "\n",
    "\n",
    "for i in range(len(tids)):\n",
    "    slower,supper = slices(indexes[i][0],len(tids[i]),40)\n",
    "    key_id = ids[i][indexes[i][0]]\n",
    "    #key_tid = tids[i][indexes[i][0]]\n",
    "    pid = ids[i][slower:supper]\n",
    "    key_inds.append([])\n",
    "    for j in indexes[i]:\n",
    "        \n",
    "        key_id = ids[i][j]\n",
    "        if key_id not in pid:\n",
    "           print(len(ids[i]),key_id,slower,supper,indexes[i])\n",
    "        key_inds[i].append(pid.index(key_id))\n",
    "    sliced_ids.append(tids[i][slower:supper])\n",
    "    sliced_att.append(tatt[i][slower:supper])\n",
    "\n",
    "Min = 10000\n",
    "for i in range(len(indexes)):\n",
    "    if len(indexes[i]) < Min:\n",
    "        Min = len(indexes[i])\n",
    "#print(Min)\n",
    "#print(len(sliced_ids[448]),len(tids[448]),sliced_ids[0],sliced_att[0])\n",
    "print(key_inds[448],tids[448][99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "21c4723a-8d9e-433d-ab0e-ed548e91e956",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "input_ids_batch = torch.nn.utils.rnn.pad_sequence(sliced_ids, batch_first=True, padding_value=0)\n",
    "attention_mask_batch = torch.nn.utils.rnn.pad_sequence(sliced_att, batch_first=True, padding_value=0)\n",
    "\n",
    "dataset = TensorDataset(input_ids_batch, attention_mask_batch)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=100)\n",
    "\n",
    "ind = 0\n",
    "\n",
    "vectors = []\n",
    "\n",
    "#print(input_ids_batch)\n",
    "for batch in dataloader:\n",
    "    #print(len(batch[0]),batch)\n",
    "    input_for_model = {\n",
    "        \"input_ids\": batch[0],\n",
    "        \"attention_mask\" : batch[1]\n",
    "    }\n",
    "\n",
    "    with torch.no_grad():  # Disable gradients for inference\n",
    "        outputs = model(**input_for_model,output_hidden_states=True)\n",
    "    hidden_states = outputs.hidden_states\n",
    "    last_hs = hidden_states[-1]\n",
    "    #print(last_hs.shape)\n",
    "    for i in range(len(last_hs)):\n",
    "        vectors.append([])\n",
    "        for j in range(len(key_inds[ind])):\n",
    "            vectors[len(vectors)-1].append(last_hs[i][key_inds[ind][j]])\n",
    "        ind+=1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ced5b10f-a6ca-41de-9f7c-96ad2f11a0e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([ 6.0182e-02,  9.6063e-02, -2.4367e-03,  2.3522e-04,  1.4157e-01,\n",
      "        -1.9084e-01, -8.9138e-02,  2.4629e-01,  8.1022e-02,  3.3121e-02,\n",
      "        -1.5948e-02,  4.0185e-02,  2.4637e-01, -6.7611e-02, -2.0017e-02,\n",
      "         7.8462e-02,  1.9462e-02, -2.9817e-02,  1.0935e-01, -6.4263e-02,\n",
      "        -1.3107e-01,  1.9458e-02, -5.3467e-03,  5.3320e-02,  8.4158e-02,\n",
      "        -6.5116e-02,  1.8467e-02, -4.7020e-02,  1.1844e-01, -9.7403e-02,\n",
      "         8.4644e-02,  4.4193e-02, -7.0033e-02, -2.3572e-02,  4.5031e-02,\n",
      "         7.6761e-02,  8.1940e-02, -3.7150e-02,  1.3652e-01, -1.2604e-02,\n",
      "         1.1577e-01,  4.1190e-02, -1.9032e-03,  6.6562e-02,  1.9405e-02,\n",
      "        -2.0590e-02, -3.8596e-02,  1.9137e-02,  6.8997e-02, -3.5650e-02,\n",
      "        -4.4676e-04,  8.4557e-02,  1.6037e-02,  6.6177e-02,  1.5282e-02,\n",
      "        -9.7177e-02,  1.1209e-01, -1.0169e-01,  2.8294e-02,  1.5552e-01,\n",
      "        -5.2742e-02,  2.1420e-02, -2.7690e-02, -1.7846e-01,  1.4243e-01,\n",
      "        -9.2559e-04, -1.1287e-01,  4.3927e-04, -7.2785e-02,  4.2706e-03,\n",
      "         2.5011e-02, -1.8827e-01,  2.2548e-01, -9.2832e-02, -1.4289e-01,\n",
      "        -2.7295e-02,  5.4647e-02, -2.3256e-02,  3.3518e-02,  2.6055e-02,\n",
      "         2.6007e-02, -1.2899e-01, -2.4877e-02, -4.4582e-02,  1.1717e-01,\n",
      "         9.7440e-02, -1.3432e-03,  6.9589e-02, -2.6364e-02,  1.1063e-01,\n",
      "        -6.1262e-02, -5.9848e-02,  2.5725e-01, -9.9376e-02,  8.8115e-02,\n",
      "        -3.0871e-02,  4.9382e-02,  7.0491e-02,  3.5862e-04, -3.9709e-01,\n",
      "        -2.7658e-03, -8.4901e-02, -3.4777e-02,  5.4618e-02, -2.1368e-01,\n",
      "         3.5211e-02,  6.3247e-02, -4.0742e-02,  5.1963e-02,  2.8585e-02,\n",
      "         1.2091e-01, -1.8893e-02, -1.6307e-01, -7.7922e-02,  1.0876e-01,\n",
      "        -7.5997e-02,  8.1200e-02,  1.0412e-01,  8.6734e-02,  7.8363e-02,\n",
      "        -2.1471e-01, -5.9485e-02, -5.1358e-02,  4.6692e-02, -1.5127e-02,\n",
      "        -2.2359e-02, -3.5963e-02,  1.0707e-02,  5.5525e-02,  1.1100e-01,\n",
      "         1.3605e-01, -1.4076e-01,  2.2208e-02, -4.6786e-02,  2.4249e-02,\n",
      "        -6.3870e-03, -9.4121e-03,  5.2501e-03, -3.4427e-02,  2.6700e-01,\n",
      "        -8.6046e-02, -6.8212e-02, -1.5668e-02,  1.0107e-01, -2.2432e-02,\n",
      "         1.3863e+00, -1.6596e-02, -4.8716e-02, -7.2376e-02,  2.0437e-01,\n",
      "        -1.2642e-01,  2.7650e-01, -9.4974e-01,  2.3356e-02,  2.5477e-02,\n",
      "         1.0627e-01,  9.2677e-02, -5.4242e-02,  1.2351e-02, -2.1753e-02,\n",
      "         1.0337e-01,  2.2927e-02,  5.1439e-02, -8.6017e-03,  2.0965e-02,\n",
      "         7.4532e-02,  2.3841e-01, -3.5520e-02, -3.9176e-02,  6.0298e-02,\n",
      "         4.3500e-02,  1.4791e-02, -7.2060e-03, -4.0140e-02, -3.3480e-02,\n",
      "        -1.0290e-01, -4.9050e-02,  2.0209e-01, -6.8831e-03, -7.0380e-02,\n",
      "        -1.1168e-01, -2.7620e-02, -6.3500e-02,  7.7637e-02, -1.3582e-01,\n",
      "        -3.6031e-02,  9.5108e-02, -1.5606e-03,  6.2554e-02, -1.7980e-02,\n",
      "         4.4139e-02,  4.2738e-02, -1.1120e-02,  6.7768e-04,  1.5602e-02,\n",
      "         7.0257e-02, -1.9334e-02,  5.6865e-02, -3.4925e-02, -1.0510e-01,\n",
      "         2.7270e-02,  2.7268e-02, -1.5148e-01, -2.4255e-02, -7.4962e-02,\n",
      "        -7.8472e-03,  3.0667e-02,  3.4447e-01,  4.7840e-02,  8.9000e-02,\n",
      "         3.0071e-02, -1.0175e-02,  3.9195e-02, -2.6151e-02,  3.0901e-02,\n",
      "        -2.0309e-01, -7.1325e-02,  9.9519e-02,  1.0070e-01,  3.9153e-02,\n",
      "        -7.7226e-02, -1.8054e-01,  3.0543e-02,  3.9777e-02,  1.3318e-02,\n",
      "         7.6804e-02,  4.0349e-02, -3.7037e-02,  6.0412e-03, -2.1517e-01,\n",
      "        -2.0052e-02, -4.3938e-02, -7.5585e-04,  6.4774e-02,  2.3190e-02,\n",
      "         1.9850e-02,  5.0430e-02, -1.3773e-02,  4.4036e-03, -4.8290e-01,\n",
      "        -5.7690e-03,  6.4345e-02,  7.2345e-04, -5.6276e-03,  3.0075e-02,\n",
      "         1.0144e-01, -2.1300e-02,  1.2994e-01,  2.3156e-01,  9.0832e-02,\n",
      "         3.4769e-02,  2.1380e-02, -2.4527e-02, -8.1677e-02, -1.2200e-02,\n",
      "         1.6032e-01, -1.6350e-01, -8.2795e-02,  7.5896e-02,  1.3160e-01,\n",
      "        -3.3222e-02,  4.2573e-02,  3.4887e-02,  7.1119e-02,  5.1693e-02,\n",
      "         2.7093e-02,  3.7537e-01, -4.4570e-02, -1.0074e-01, -1.3366e-02,\n",
      "         2.0090e-02, -7.0906e-02, -9.7894e-02,  8.9697e-02,  3.5916e-02,\n",
      "         1.3014e-02,  1.7623e-01, -1.4546e-01, -1.2470e-01, -7.1456e-02,\n",
      "         5.4396e-02, -1.1573e-01,  4.2554e-03, -9.5249e-02,  9.4814e-02,\n",
      "        -7.8096e-02, -8.1598e-02,  4.1616e-02,  1.2176e-01, -1.1638e-01,\n",
      "        -1.7170e-02,  4.2860e-02, -4.9778e-02, -1.5252e-02,  2.5610e-01,\n",
      "         8.0055e-02, -7.7365e-02, -9.1632e-02,  2.7324e-02,  5.2081e-02,\n",
      "        -6.4975e-03, -2.6383e-02,  1.6282e-01, -7.3613e-03,  4.3158e-02,\n",
      "        -7.4185e-02,  4.4429e-01, -1.6374e-02,  4.8480e-03,  7.8228e-02,\n",
      "        -3.3102e-02, -4.9543e-02, -1.6467e-01, -2.0493e-01, -8.6137e-02,\n",
      "         5.3754e-02, -1.9212e-01,  8.2266e-02, -1.3499e-02,  4.1461e-02,\n",
      "         1.5236e-01, -4.9965e-02,  2.0941e-02,  1.3430e-01,  5.5793e-02,\n",
      "         9.2026e-02,  2.8545e-03,  5.4677e-02, -7.7594e-02,  8.0438e-03,\n",
      "         8.2892e-02, -3.3342e-02, -2.1315e-02,  1.2483e-02, -4.8665e-02,\n",
      "         6.7160e-02,  1.2903e-02, -9.7857e-03, -1.9037e-03, -5.8092e-02,\n",
      "         6.7326e-02, -8.7002e-02, -1.8113e-01, -4.0873e-02, -3.9693e-02,\n",
      "         1.3203e-02,  4.6591e-02, -4.3296e-02,  3.2699e-02,  1.2265e-02,\n",
      "         1.5262e-01, -1.5086e-02,  9.1609e-02, -1.3055e-01, -9.6883e-02,\n",
      "        -2.5095e-02, -2.1898e-01,  1.3399e-01,  6.3234e-02, -9.8950e-02,\n",
      "         4.4030e-02,  1.9696e-02, -3.9432e-03,  5.4070e-02, -4.2262e-02,\n",
      "         8.1360e-02,  1.4547e-01,  1.0316e-01, -2.5030e-02,  1.0383e-01,\n",
      "         1.9186e-01,  3.4769e-02,  4.3433e-02, -1.4660e-02,  6.5550e-02,\n",
      "         2.4063e-02,  4.4342e-02,  3.9345e-02, -7.8632e-03,  1.0717e-01,\n",
      "         1.7333e-02,  5.9651e-02, -8.2168e-02,  1.8648e-02,  7.8980e-02,\n",
      "        -7.0548e-02, -9.4536e-03, -4.2951e-02, -7.3016e-02,  3.4531e-02,\n",
      "         3.8679e-02, -5.9574e-01, -3.6342e-02,  3.0228e-02,  2.5199e-02,\n",
      "         2.9327e-01,  2.2829e-02, -3.0058e-02, -1.7777e-02,  7.6926e-02,\n",
      "         1.1791e-01,  2.3341e-02, -9.6498e-02,  6.5162e-02,  5.6541e-02,\n",
      "        -6.7827e-02,  1.1313e-01,  7.6364e-02,  2.8983e-02, -6.9509e-02,\n",
      "         8.1445e-02, -1.9856e-02,  2.7919e-02, -1.9118e-02,  2.8269e-02,\n",
      "         2.3768e-02,  8.7583e-02,  2.1805e-02, -1.7606e-01,  1.7340e-01,\n",
      "        -1.4888e-01,  9.1621e-02, -1.0763e-02, -1.1459e-01, -5.2431e-03,\n",
      "         1.9544e-01, -5.5167e-02, -7.3059e-03, -1.2944e-02, -2.9178e-03,\n",
      "        -2.0955e-02,  3.3831e-02,  4.3681e-02,  1.2696e-01,  8.1323e-03,\n",
      "         2.5177e-02, -8.2223e-02,  2.5831e-02,  1.0168e-01,  5.0512e-02,\n",
      "        -6.2674e-02, -6.3148e-02, -8.2538e-03,  1.6481e-01, -2.7768e-02,\n",
      "         3.8394e-02,  7.6792e-02,  1.5348e-03, -1.1086e-02,  1.9103e-04,\n",
      "        -1.3957e-03, -2.1666e-02,  4.0779e-02, -2.7217e-02, -8.7099e-02,\n",
      "        -1.8900e-01,  2.3336e-02,  2.8156e-02,  9.9046e-03, -1.2203e+00,\n",
      "         2.1385e-01,  4.5046e-02,  2.8042e-02,  1.0852e-01, -1.1884e-01,\n",
      "        -1.1865e-01, -2.0749e-03, -1.5684e-01,  1.4355e-01,  5.5862e-02,\n",
      "        -6.4451e-02,  3.7311e-02,  2.9718e-02, -1.0050e-01, -1.9645e-02,\n",
      "        -5.4600e-02,  4.5846e-02, -2.1889e-01,  1.0458e-01,  1.2896e-02,\n",
      "         5.4189e-02, -2.4569e-02, -2.6940e-01,  3.2216e-02, -1.0665e-03,\n",
      "         8.6064e-02, -6.1578e-02,  3.4162e-01,  4.7166e-02, -1.9341e-02,\n",
      "         4.6737e-02, -3.5237e-02, -7.9568e-02,  4.5212e-02,  4.4934e-02,\n",
      "         1.2966e-02, -6.5060e-02, -1.8385e-01,  9.6952e-02,  7.8952e-03,\n",
      "        -7.4488e-03,  1.0350e-01, -7.2572e-02,  2.5348e-02, -1.4404e-02,\n",
      "         3.5683e-02,  5.7543e-02, -8.9092e-03,  7.6493e-02, -6.7703e-04,\n",
      "         4.8413e-01, -8.1740e-02, -1.3852e-02, -5.2001e-02,  9.6972e-02,\n",
      "        -3.4226e-02, -2.9119e-02,  8.2067e-02,  1.8754e-02, -1.9928e-02,\n",
      "         1.8803e-01,  2.8549e-02, -4.1176e-02,  2.7500e-02,  4.2854e-02,\n",
      "        -1.4809e-02, -4.0944e-02,  2.2414e-02,  7.1671e-03,  2.1226e-01,\n",
      "        -7.6990e-03, -2.2858e-02,  1.2341e-02, -2.2078e-01, -1.9641e-02,\n",
      "        -7.7663e-02, -6.4872e-02,  4.9903e-02, -2.3242e-02, -3.0747e-02,\n",
      "         2.8414e-01,  3.5211e-02,  1.9113e-01,  9.3289e-02, -1.4427e-02,\n",
      "         5.9164e-02,  8.4640e-02,  1.7164e-02,  3.2837e-02,  2.7512e-02,\n",
      "         9.8997e-03, -2.0024e-01, -3.8284e-02, -1.5916e-01, -9.5446e-02,\n",
      "         8.9299e-02,  1.8820e-02,  1.0212e-01,  6.9423e-02, -7.7150e-02,\n",
      "         9.6861e-02,  7.8769e-02,  2.7484e-04,  6.4827e-02, -3.0132e-02,\n",
      "         3.7628e-02,  7.8067e-02,  5.1020e-02,  1.1576e-02,  1.1046e-01,\n",
      "        -1.7770e-01,  3.4427e-02, -1.8657e-03,  1.7878e-01,  1.2707e-01,\n",
      "         7.1237e-02,  1.6407e-02, -6.6034e-03,  8.0876e-03, -2.3665e-01,\n",
      "        -1.6699e-01, -1.0180e-01,  7.9027e-02, -1.8682e-02, -2.2347e-01,\n",
      "        -5.0197e-02, -5.8931e-02,  2.1874e-01, -6.0772e+00, -6.4336e-02,\n",
      "         1.6626e-01,  1.9279e-01, -4.0968e-02, -5.0692e-02,  6.4308e-02,\n",
      "         3.4619e-02,  7.4726e-02,  1.1727e-01,  3.7730e-02, -1.0665e-01,\n",
      "         1.2050e-01,  4.8214e-02,  3.4495e-03, -3.9659e-02, -6.4305e-02,\n",
      "        -2.4075e-01, -1.3060e-02,  7.2220e-03,  7.2013e-02,  2.3143e-01,\n",
      "         2.2863e-01,  1.4113e-01,  1.1236e-01,  1.6555e-02, -7.9723e-02,\n",
      "         1.8848e-01,  8.2672e-02,  2.3405e-02, -8.0117e-02,  1.4989e-01,\n",
      "         5.8177e-02, -8.8184e-03,  1.9196e-03, -8.0769e-02, -5.9322e-02,\n",
      "        -2.7494e-02,  2.4659e-02,  9.4624e-02, -3.6524e-02, -1.3521e-01,\n",
      "         1.1367e-01,  6.4937e-02, -4.8003e-02, -1.2715e-01,  2.9548e-01,\n",
      "         3.8780e-02,  3.5123e-02, -1.6516e-02,  1.3673e-01,  1.7079e-02,\n",
      "         3.9213e-02,  1.2747e-01, -9.8428e-02, -6.0614e-03,  4.2019e-02,\n",
      "        -6.2513e-02, -3.2707e-02, -4.0336e-02, -7.1723e-02, -3.4225e-02,\n",
      "         2.0225e-01,  4.7664e-02, -7.3285e-02,  1.0336e-01, -2.1075e-01,\n",
      "        -6.2069e-03, -5.2673e-03, -5.6840e-03,  1.1476e-01, -1.3054e-04,\n",
      "        -4.0664e-01,  2.9917e-02,  3.9275e-02, -2.0051e-02,  8.0873e-02,\n",
      "        -2.3207e-02,  1.3966e-01, -6.0375e-03, -6.1934e-02,  1.6850e-01,\n",
      "         4.0431e-02,  5.3603e-02,  2.9893e-02, -1.2939e-01,  1.5847e-01,\n",
      "        -1.2402e-02,  2.5295e-02,  1.8328e-02, -8.0891e-02, -8.3576e-02,\n",
      "         3.0439e-01,  8.9526e-02,  8.8754e-02, -7.1071e-02,  7.1028e-02,\n",
      "        -5.5419e-02,  1.4643e-01,  1.1306e-02, -1.2123e-02,  5.6780e-02,\n",
      "        -1.2908e-01,  6.7640e-02,  4.6051e-02,  4.9707e-02, -2.3107e-01,\n",
      "        -5.4953e-02,  3.1282e-02, -2.7719e-02, -1.1444e-01,  6.9171e-02,\n",
      "         7.6379e-02,  5.6373e-02,  4.7624e-02,  3.1599e-03,  1.4225e-01,\n",
      "         9.0444e-02, -6.0426e-02, -1.2934e-01, -2.5188e-02,  6.4386e-02,\n",
      "         1.7307e-02, -5.1150e-02,  2.9648e-01,  2.1386e-03,  4.5403e-02,\n",
      "        -1.3316e-01,  9.0571e-02,  1.2972e-02, -1.7691e-01,  1.7338e-02,\n",
      "         1.6071e-01,  6.2892e-02, -2.9099e-01, -8.0388e-02,  6.9517e-03,\n",
      "        -5.6557e-02,  5.9826e-02,  2.9176e-02,  8.8541e-02,  7.0012e-02,\n",
      "         3.7593e-02, -1.6426e-01, -6.2103e-02,  8.6139e-02,  8.7183e-02,\n",
      "        -4.5603e-02,  1.9142e-01,  1.9352e-02,  3.4555e-02, -2.2882e-01,\n",
      "         1.8266e-02,  1.7937e+01,  8.2790e-02,  5.2025e-02, -1.0756e-02,\n",
      "         4.6547e-02, -9.4926e-02, -8.4193e-02,  1.0759e-01, -4.5089e-01,\n",
      "         1.2965e-02,  3.1679e-02,  2.7416e-02, -4.0391e-02,  1.0701e-02,\n",
      "         2.3289e-02,  4.2992e-02,  3.3445e-02, -5.1405e-02,  2.7537e-02,\n",
      "        -2.5385e-02,  8.1334e-02, -8.7522e-03, -1.6177e-02,  2.5628e-01,\n",
      "        -8.8105e-02,  4.7785e-02,  2.3166e-01], device='cuda:0'), tensor([ 7.8172e-02,  1.0938e-01,  2.6099e-02,  5.2643e-02,  2.5346e-01,\n",
      "        -1.2265e-01, -4.7528e-02,  2.7023e-01,  6.8609e-02, -1.4541e-02,\n",
      "        -1.9777e-01,  6.0652e-02,  6.3856e-02, -2.0493e-01,  4.7152e-03,\n",
      "         8.9083e-02,  1.2286e-02, -3.3575e-02,  3.5980e-02, -5.1987e-02,\n",
      "         1.8062e-01,  3.2858e-02, -1.0838e-01,  9.8553e-02,  9.2446e-02,\n",
      "        -1.3222e-01,  9.1582e-02, -7.4558e-02,  6.3143e-02, -1.0592e-01,\n",
      "         5.7915e-02,  2.5535e-02, -1.4036e-02, -6.5047e-02, -2.3222e-02,\n",
      "         6.1299e-02,  1.1900e-01, -2.6988e-02,  2.0883e-01, -2.9380e-02,\n",
      "         1.3356e-01, -1.0729e-02, -5.0976e-02,  8.1903e-02,  2.8917e-03,\n",
      "        -1.2620e-02, -2.8404e-02, -4.5996e-02,  8.2559e-02, -3.3046e-02,\n",
      "         3.1080e-02, -1.3896e-01, -1.3984e-03, -1.2506e-01, -2.1676e-01,\n",
      "        -8.8847e-02,  9.7127e-02, -1.6907e-01,  4.0420e-02,  3.5987e-01,\n",
      "         1.3469e-02,  1.2460e-01, -1.1617e-03,  1.5662e-01, -1.3786e-01,\n",
      "        -3.1988e-02, -6.9005e-02,  4.1577e-03, -5.4414e-02,  6.8292e-02,\n",
      "         1.6625e-02, -1.4415e-01,  1.9710e-01,  2.1645e-02, -4.1350e-02,\n",
      "        -5.5664e-02,  3.8118e-02, -2.8200e-03,  5.1893e-02, -5.0791e-02,\n",
      "         2.3327e-02, -9.2690e-02, -4.4756e-03,  1.7204e-01,  2.2400e-01,\n",
      "         1.4441e-01, -6.6972e-02,  5.4509e-03,  3.1032e-02,  1.0215e-01,\n",
      "        -6.3448e-02, -6.8795e-02,  1.4398e-01, -1.7324e-02,  9.7365e-02,\n",
      "        -3.4286e-02,  7.6476e-03,  7.7488e-02, -3.3053e-02, -2.8385e-01,\n",
      "         2.4765e-02, -1.4048e-01, -5.8704e-02, -2.7049e-02, -3.8426e-02,\n",
      "         7.6986e-02,  7.8864e-02, -2.5544e-02, -3.2600e-02,  7.1172e-02,\n",
      "         4.0655e-02, -3.8084e-02, -1.2496e-01, -1.8942e-01,  1.1657e-01,\n",
      "        -4.7756e-02,  1.0706e-01,  1.2346e-01,  7.7551e-02,  4.4230e-04,\n",
      "        -2.2075e-01,  7.9098e-02, -6.9873e-02,  2.7119e-02, -2.1269e-02,\n",
      "        -7.0939e-02, -2.3198e-03, -8.6762e-02,  6.6826e-02, -1.1174e-01,\n",
      "         1.4244e-01, -2.0064e-01, -3.3367e-02, -4.0931e-02, -5.0653e-02,\n",
      "        -7.5121e-02, -8.4628e-03, -4.3478e-02, -5.5138e-02, -3.5278e-02,\n",
      "        -5.8638e-02,  1.2584e-01,  4.2101e-02,  1.5694e-01, -5.4645e-03,\n",
      "         1.0141e+00,  2.4207e-03,  5.0516e-02,  7.3075e-02,  1.0014e-01,\n",
      "        -1.8020e-01,  1.8550e-01, -1.3471e-01, -4.8788e-02, -6.4552e-02,\n",
      "         7.0675e-02, -4.4616e-04, -6.0655e-03, -7.8997e-02, -1.1940e-02,\n",
      "         4.7000e-02,  1.4590e-01,  1.0682e-01,  3.5440e-02,  1.3129e-01,\n",
      "        -2.5778e-02,  1.4121e-01,  1.3010e-02, -2.5249e-02,  9.0278e-03,\n",
      "        -1.3005e-02, -1.3887e-02,  2.5233e-01, -2.3881e-03, -2.1582e-02,\n",
      "        -1.1716e-01, -5.1506e-02, -7.3083e-02, -2.3872e-02,  1.3552e-01,\n",
      "        -1.3150e-01, -6.0632e-02,  1.4161e-01,  6.7980e-02, -1.9486e-01,\n",
      "        -2.2530e-02,  3.5251e-02, -2.3938e-02, -4.2234e-02,  6.2631e-04,\n",
      "        -2.8841e-03, -8.9899e-02, -4.4159e-02,  5.2248e-02,  6.0370e-02,\n",
      "         6.2922e-02, -4.1813e-02,  6.4559e-02, -2.2757e-03, -7.3467e-02,\n",
      "         5.8480e-03, -1.6457e-04, -1.0213e-01,  7.5875e-02, -5.0326e-02,\n",
      "        -5.1271e-02,  5.7749e-02,  1.8963e-01,  2.1520e-02,  1.6818e-01,\n",
      "         2.5912e-02,  1.0608e-02,  7.0866e-02, -2.3909e-02,  2.6881e-02,\n",
      "        -1.2253e-01, -2.7562e-02,  1.4981e-01,  8.9727e-02,  1.0068e-02,\n",
      "        -2.7697e-02, -6.6602e-02, -1.2651e-01,  5.0658e-02,  5.8387e-02,\n",
      "         6.6737e-02,  2.6718e-02, -1.1790e-02,  1.7949e-02, -9.7093e-02,\n",
      "         6.3495e-02,  8.3852e-02, -4.6823e-02, -3.5152e-02,  2.4297e-02,\n",
      "         6.5375e-02, -6.0764e-02,  4.1041e-02,  6.4424e-02, -4.9552e-01,\n",
      "         1.0608e-01,  1.1567e-02,  3.3006e-02, -7.7701e-03,  7.3957e-02,\n",
      "         4.3169e-02, -3.1349e-02,  4.2152e-02, -7.1104e-02,  1.8067e-01,\n",
      "        -5.7646e-02, -2.3978e-02, -6.8320e-02, -1.1471e-01,  1.0277e-01,\n",
      "         7.5478e-02, -5.0289e-02, -2.8228e-02,  1.1142e-01,  3.3979e-01,\n",
      "         1.9706e-01, -5.6597e-03,  3.1184e-02,  6.6900e-02,  1.6984e-02,\n",
      "        -8.0826e-03,  3.3091e-02,  8.1930e-02, -2.4030e-01,  4.0744e-02,\n",
      "         1.0539e-02, -4.3139e-02, -3.6505e-02,  1.6040e-01,  4.5093e-02,\n",
      "        -1.2164e-02,  8.2714e-02, -2.2059e-01,  1.0259e-01, -6.3417e-02,\n",
      "         2.1323e-02, -1.9779e-01, -5.9902e-02, -1.1311e-01,  1.1855e-01,\n",
      "         5.6794e-02, -7.5094e-02,  5.1341e-02,  6.9784e-02, -4.2806e-02,\n",
      "        -9.4974e-02,  2.5138e-02, -2.4175e-02,  3.1791e-02,  2.7912e-01,\n",
      "         4.7127e-02, -9.5739e-02, -7.0156e-02, -3.3029e-02, -5.0963e-02,\n",
      "         4.5975e-02, -1.5895e-01,  3.0103e-02, -4.9994e-03,  4.0844e-03,\n",
      "        -9.7477e-02,  4.3182e-01, -2.8582e-02, -2.3130e-01,  1.4933e-01,\n",
      "        -4.0330e-02, -3.4494e-02, -1.7384e-01,  1.5842e-02, -1.4192e-01,\n",
      "        -1.1116e-01, -5.7221e-03,  1.2446e-01, -8.6585e-02, -6.3353e-02,\n",
      "         1.1090e-01, -2.1759e-02,  2.0117e-02,  8.0566e-02,  2.0249e-03,\n",
      "         7.7122e-02,  1.1756e-02,  4.3051e-02, -1.4520e-01, -3.3909e-03,\n",
      "         4.2569e-02, -5.8792e-02, -6.4463e-02, -1.1915e-02,  3.8513e-04,\n",
      "         1.2616e-01, -1.5325e-02, -8.9430e-02, -1.1801e-01,  2.2365e-01,\n",
      "        -7.3519e-02, -8.7858e-02,  2.4636e-01,  4.5481e-02, -9.3330e-02,\n",
      "        -6.1372e-02, -2.0309e-02,  1.2948e-01, -3.2287e-02,  2.0929e-02,\n",
      "         1.0534e-01,  8.2778e-02,  1.4943e-02,  5.1785e-02, -5.3072e-02,\n",
      "         5.8547e-03, -3.4313e-01,  1.3286e-01,  1.7157e-01, -1.6875e-01,\n",
      "         1.7358e-03, -3.8521e-02, -3.7259e-02,  1.0085e-01, -5.4339e-02,\n",
      "         4.6151e-02,  8.4758e-02,  9.9939e-02, -1.8207e-03,  5.8891e-02,\n",
      "         3.2144e-01, -4.7086e-02, -4.0755e-02,  9.5962e-03,  1.1947e-02,\n",
      "         7.8497e-03, -8.3451e-04, -2.8673e-01, -6.7665e-03,  2.5004e-01,\n",
      "         4.8388e-02,  6.7184e-02, -8.7518e-02,  3.4449e-02,  5.9765e-03,\n",
      "         8.4674e-02,  3.7979e-02,  2.8219e-01, -1.8239e-01,  3.4109e-02,\n",
      "        -2.6078e-02, -3.7670e-01,  3.7864e-02, -8.4369e-02,  1.5840e-02,\n",
      "         2.4515e-01,  8.2746e-02,  2.7939e-02, -2.3447e-02,  6.8062e-02,\n",
      "         1.5373e-01,  4.7283e-03,  3.3509e-02,  3.4292e-02,  3.4916e-02,\n",
      "        -1.4800e-01, -1.4096e-01,  2.0046e-02,  4.9085e-03, -3.4925e-02,\n",
      "         3.7302e-02, -1.2353e-01,  4.8629e-02, -1.1443e-01, -4.8604e-02,\n",
      "         3.0041e-02,  1.3925e-02,  2.0989e-02, -1.3217e-01,  1.6211e-01,\n",
      "        -8.1800e-02,  1.1824e-01,  4.4420e-02, -8.2322e-02, -2.1021e-02,\n",
      "         1.5940e-01, -7.5724e-02,  6.1691e-03,  3.0776e-02, -4.9229e-02,\n",
      "        -1.1172e-02, -3.0712e-02,  9.6188e-02,  9.1695e-02,  3.7622e-03,\n",
      "         8.8008e-02, -1.5844e-01,  8.0695e-02,  8.8878e-02,  8.2914e-02,\n",
      "         2.4167e-02, -4.1781e-02,  4.2333e-02,  1.5282e-01,  1.6039e-02,\n",
      "         2.7757e-02, -4.7828e-02,  5.4870e-02,  2.7342e-01, -6.5953e-02,\n",
      "        -2.2987e-02,  2.1043e-03,  5.6103e-02, -3.3312e-03, -4.0501e-02,\n",
      "        -1.7085e-01,  5.5725e-02,  7.5642e-02, -1.0271e-03, -5.1181e-01,\n",
      "         2.9844e-01,  7.8295e-03,  2.4046e-01, -1.2454e-01, -2.0159e-01,\n",
      "        -2.8208e-01,  1.2676e-02, -3.4456e-02,  9.9155e-02, -4.0915e-02,\n",
      "        -8.5224e-02, -3.4667e-02,  7.2168e-02,  1.0701e-01, -4.4886e-02,\n",
      "        -4.4669e-02, -8.7314e-02, -9.7312e-02,  1.3367e-01, -6.9567e-02,\n",
      "         3.7587e-02, -1.5171e-01, -1.6202e-01, -2.9049e-02,  1.2291e-01,\n",
      "         1.1416e-02, -2.7126e-01,  2.1563e-01,  5.1471e-02, -3.0762e-02,\n",
      "        -1.4287e-01, -3.0489e-02, -7.6216e-02,  1.8681e-02,  9.4128e-02,\n",
      "         3.3672e-02, -2.2168e-01, -4.0905e-01,  8.5480e-02, -9.1980e-02,\n",
      "         3.3860e-02,  1.3261e-01, -5.0569e-02, -1.8736e-02, -1.2739e-01,\n",
      "         5.6617e-02, -1.5637e-01,  4.4817e-02,  1.0673e-01, -7.0505e-02,\n",
      "         6.2908e-01, -1.1042e-01, -9.4461e-03, -4.5951e-02, -4.9659e-02,\n",
      "        -1.0183e-01, -7.6567e-02,  3.8739e-02,  6.7465e-02, -5.3191e-02,\n",
      "         1.5435e-01, -5.0720e-02, -3.3256e-02,  6.9552e-03,  4.9010e-02,\n",
      "        -8.6313e-03,  5.6387e-03, -5.2939e-02, -3.9914e-02,  2.1148e-01,\n",
      "         1.7828e-02, -1.1306e-01,  7.0062e-02, -1.2551e-01, -1.3519e-01,\n",
      "         2.4763e-01, -9.1057e-02,  6.5433e-02, -4.1278e-02,  2.0271e-02,\n",
      "         3.6128e-01,  5.9164e-02,  2.0395e-01,  1.2950e-01, -8.8124e-03,\n",
      "         9.7780e-02,  6.5276e-02,  7.8519e-02,  2.6582e-02,  2.4073e-02,\n",
      "         7.0598e-02,  8.2581e-02, -3.5836e-03,  1.8869e-01, -8.5213e-02,\n",
      "        -1.7262e-01,  2.1211e-02,  1.7386e-03,  4.7682e-02, -4.8896e-02,\n",
      "         1.1158e-01,  4.5733e-02,  2.9214e-02,  2.6848e-02, -2.3112e-02,\n",
      "        -5.0238e-02,  7.4998e-02,  1.7784e-02,  5.6316e-02, -2.1122e-02,\n",
      "         1.5926e-02,  3.0653e-02,  2.1723e-02,  1.6431e-01, -1.6306e-01,\n",
      "         9.5126e-02,  1.5290e-02,  5.4281e-02,  1.4690e-01, -6.4119e-01,\n",
      "        -2.9772e-02,  1.8841e-02, -9.9290e-03, -7.7639e-02, -7.3047e-03,\n",
      "        -4.9913e-02, -4.3646e-02,  1.3601e-01, -5.9029e+00,  1.7394e-01,\n",
      "         6.2914e-02,  2.1050e-01,  4.8903e-02, -3.1268e-02,  4.0003e-02,\n",
      "         3.4330e-02,  7.9764e-02,  2.0100e-01,  7.7627e-02,  8.6164e-02,\n",
      "         2.7061e-02,  6.4784e-02, -1.2478e-02,  6.3029e-02, -7.5493e-02,\n",
      "        -2.0669e-01,  7.5471e-03,  2.5490e-01,  7.3842e-02,  1.2003e-01,\n",
      "         7.1624e-02,  1.0121e-01, -3.4615e-03,  1.6922e-01, -1.2214e-01,\n",
      "         3.3202e-02,  1.0435e-01, -3.2767e-02, -1.6513e-01,  1.3150e-01,\n",
      "         4.5046e-02, -1.0504e-02,  5.9039e-02, -4.8528e-02, -2.4087e-02,\n",
      "        -1.9665e-02,  3.9997e-03,  5.2597e-02, -1.9198e-02,  5.3777e-02,\n",
      "        -2.4039e-02,  3.0072e-02,  1.7773e-01, -2.3883e-02,  1.9822e-01,\n",
      "         1.0362e-02, -2.9889e-02, -1.2839e-01,  2.7969e-01,  3.9841e-02,\n",
      "         1.4927e-01,  1.3301e-01, -9.1604e-02,  3.0345e-02,  3.8165e-02,\n",
      "        -1.0624e-02, -2.8819e-03, -1.6143e-02,  2.1626e-01,  2.4036e-02,\n",
      "         1.3492e-01,  5.4930e-02, -6.6779e-02, -9.2110e-02, -1.2234e-01,\n",
      "         4.7492e-02, -3.6433e-02,  2.2076e-03,  5.1905e-02,  3.6342e-02,\n",
      "        -2.9693e-01,  1.7064e-01,  3.4144e-02,  1.3157e-01,  9.8930e-02,\n",
      "        -5.7218e-02,  9.3819e-02,  2.5451e-02, -1.9337e-01,  1.7413e-01,\n",
      "         1.6316e-02,  7.2475e-02,  1.0219e-01, -2.1399e-01,  2.3110e-01,\n",
      "        -5.6340e-02,  1.4454e-02,  1.7509e-02, -1.9707e-01, -5.8964e-02,\n",
      "         2.1016e-01,  9.1774e-02,  6.4279e-02, -1.8048e-02,  8.3320e-02,\n",
      "         2.9955e-02,  3.5652e-01, -2.7099e-03, -4.6169e-02, -2.1458e-02,\n",
      "        -9.9900e-02, -3.2393e-02, -2.2654e-02, -2.8073e-03, -3.3677e-01,\n",
      "        -5.2502e-02,  1.7701e-02, -2.0411e-02, -6.5258e-02, -5.8086e-02,\n",
      "         2.8959e-02, -2.5112e-02,  6.3399e-02, -9.2787e-03,  1.2617e-01,\n",
      "         1.0024e-01, -8.0500e-02, -2.7088e-01, -1.2907e-02,  1.9920e-01,\n",
      "         6.4288e-03, -8.2549e-02, -1.7737e-01, -2.6039e-02,  3.9297e-02,\n",
      "        -4.6825e-02,  1.0233e-01,  4.1601e-02, -2.2605e-01,  5.2517e-02,\n",
      "         1.5305e-01,  9.5915e-02, -8.3004e-02,  1.3128e-01, -5.5786e-02,\n",
      "        -2.5318e-03,  1.0710e-01,  5.9825e-03,  1.1641e-01, -1.3044e-01,\n",
      "        -5.8210e-02, -1.5880e-01, -6.3570e-02,  9.2558e-02, -3.0795e-01,\n",
      "        -3.6895e-02,  1.2264e-01,  8.4083e-02, -2.8787e-02, -2.6699e-01,\n",
      "         7.6138e-02,  1.7970e+01,  3.1582e-02,  9.0999e-03,  1.2903e-02,\n",
      "         2.1821e-02, -1.0195e-01, -5.3240e-02, -9.7530e-02, -3.8359e-01,\n",
      "         4.5209e-02,  1.0511e-02,  2.6270e-02, -4.1053e-02,  1.7155e-02,\n",
      "         2.8075e-02,  2.7395e-02,  3.4614e-02,  3.4866e-02,  2.2568e-01,\n",
      "        -2.4740e-02,  2.9895e-02,  1.0464e-01,  2.2520e-03,  3.6133e-01,\n",
      "         9.7878e-02,  1.6050e-02, -2.0104e-02], device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "print(vectors[500])\n",
    "#print(vectors[448],key_inds[448])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ce17ef64-6453-4a41-bae7-82d4972543f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2535\n",
      "<class 'list'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "X = list()\n",
    "for i in range(len(vectors)):\n",
    "    Sum = 0\n",
    "    for j in range(len(vectors[i])):\n",
    "        Sum += vectors[i][j]\n",
    "    X.append(Sum)\n",
    "print(len(X))\n",
    "print(type(X))\n",
    "X = torch.stack(X)\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "800b6902-f985-499f-b310-49374feae1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2, device='cuda:0') tensor([-3.0607e-02, -4.8388e-03,  4.3151e-02,  1.0151e-01,  1.2123e-01,\n",
      "        -1.1919e-01, -4.7051e-02,  4.7089e-01,  8.6444e-02, -8.4271e-02,\n",
      "         3.7279e-01,  1.5769e-02,  1.1586e+00,  1.2930e-01,  1.2015e-01,\n",
      "        -8.8587e-02,  4.6082e-02, -8.1174e-02,  5.1833e-03,  1.6612e-01,\n",
      "         2.4407e-02,  4.7630e-02,  5.4761e-02,  1.3848e-01,  7.4771e-02,\n",
      "        -5.1961e-02,  9.2482e-02, -4.3879e-02, -1.6148e-01,  2.1498e-01,\n",
      "         1.4433e-02,  4.4248e-02, -2.7221e-02, -5.1553e-01,  2.9440e-02,\n",
      "         5.4720e-03, -1.9554e-01,  1.0129e-02,  5.7673e-02, -6.7010e-02,\n",
      "         1.0623e-01,  2.7086e-01,  7.2336e-02,  2.3089e-01,  1.2077e-01,\n",
      "        -1.6994e-02,  5.9846e-02,  1.8232e-01, -1.8017e-02, -1.1366e-01,\n",
      "         6.7394e-02,  4.5340e-01, -5.4690e-02,  5.1189e-01,  2.8533e-01,\n",
      "        -1.6626e-02, -7.3314e-02,  1.3215e-01,  3.2630e-02, -1.6430e-01,\n",
      "         7.6323e-02,  7.4527e-02, -1.0001e-01, -4.6767e-01,  1.8547e-01,\n",
      "        -2.2468e-02, -2.0382e-01, -6.1064e-04, -4.8166e-02, -7.8275e-02,\n",
      "         1.0969e-01,  8.1904e-03,  5.4035e-01,  7.9274e-02, -1.3989e-01,\n",
      "         5.3421e-02, -6.1961e-02,  1.7142e-01, -1.8025e-01, -1.5224e-01,\n",
      "         2.4089e-02, -1.0715e-01,  4.4124e-02, -5.2575e-03,  5.8710e-01,\n",
      "        -1.5875e-02,  4.7426e-02,  1.1625e-01,  5.8321e-02,  1.4672e-01,\n",
      "         1.0892e-01, -3.8994e-02,  2.6041e-01,  1.1432e-01,  1.0842e-01,\n",
      "         5.8488e-02, -4.1601e-03,  6.4365e-02, -1.0425e-02, -3.0535e-01,\n",
      "        -1.4937e-01, -6.5325e-01,  1.5080e-01,  1.8840e-01,  2.9803e-01,\n",
      "        -1.3447e-02, -1.0539e-01,  1.4860e-02,  8.7012e-02,  1.0158e-01,\n",
      "         9.3269e-02, -6.0925e-02,  2.5877e-01,  9.9740e-02,  1.0392e-01,\n",
      "        -3.1812e-04, -2.7465e-01, -3.5233e-01,  1.7336e-01,  4.2541e-02,\n",
      "         1.3237e-02, -1.0577e-02, -1.1462e-01,  5.4571e-03, -1.1845e-02,\n",
      "        -4.4972e-02, -4.9212e-02, -9.6456e-02,  1.5297e-02, -2.5572e-01,\n",
      "        -9.5779e-02,  3.1088e-01,  7.8609e-02,  1.3932e-01, -4.0111e-02,\n",
      "         2.5734e-01,  6.5569e-02,  8.2062e-02, -2.4797e-02,  5.7805e-02,\n",
      "        -4.6693e-02, -3.1157e-01, -1.1242e-01, -2.5540e-01, -5.9037e-02,\n",
      "         1.2851e+00,  2.0323e-01, -9.8842e-02,  1.0762e-01, -1.9646e-01,\n",
      "         2.2641e-01,  6.9662e-01, -2.8456e+00,  1.3691e-01,  7.5239e-02,\n",
      "        -1.9580e-02,  2.0765e-02,  2.0839e-01, -4.7887e-02, -1.9909e-02,\n",
      "         2.7035e-02,  2.2299e-01, -1.5009e-02,  1.0316e-01,  3.9373e-01,\n",
      "        -8.0255e-02,  2.4529e-01, -7.1963e-02,  1.0122e-01,  7.0906e-02,\n",
      "         2.0254e-02,  1.5586e-02, -3.5052e-01,  3.2441e-02,  7.9758e-02,\n",
      "         3.1865e-02,  3.0220e-02,  4.3195e-02,  3.3410e-01, -8.2164e-02,\n",
      "        -1.0163e-01, -1.5170e-02,  3.7568e-02,  1.1189e-01,  1.5941e-01,\n",
      "         2.2442e-02,  1.1782e-01,  6.2481e-02,  1.8082e-01, -2.0224e-01,\n",
      "         9.2272e-03,  8.6308e-02,  1.1366e-01,  1.1319e-01,  5.3037e-02,\n",
      "         3.4501e-02, -9.4870e-03, -4.7481e-02,  3.7331e-02, -2.4825e-02,\n",
      "         3.9643e-02, -8.4868e-03, -1.1200e-01,  1.3499e-01, -3.6918e-02,\n",
      "        -9.1710e-02, -3.7447e-02,  1.2957e-02,  4.1857e-03,  8.3248e-02,\n",
      "         1.5322e-01, -3.3244e-02, -3.5225e-01, -1.0128e-01, -1.9670e-01,\n",
      "         1.7550e-02, -1.4775e-01,  7.0480e-02,  1.0634e-02,  1.1758e-01,\n",
      "        -7.1774e-02, -1.0537e-01,  8.5576e-02, -2.3293e-02,  1.7932e-02,\n",
      "         5.6956e-04,  7.8911e-02, -9.2325e-02, -3.0686e-02,  3.9547e-02,\n",
      "        -7.3862e-02, -2.4312e-01, -7.6340e-03,  1.1498e-01, -4.9845e-03,\n",
      "        -1.4220e-01,  5.8376e-02, -2.0953e-01, -9.8671e-02, -9.6350e-01,\n",
      "         7.4907e-02,  5.9902e-02, -1.1686e-01, -1.5661e-02, -1.5222e-01,\n",
      "         1.8056e-01,  3.4276e-02,  9.9162e-02, -4.1828e-01,  2.9289e-02,\n",
      "        -2.0971e-02, -4.0559e-02, -1.1098e-02, -1.7939e-01,  5.9647e-02,\n",
      "        -9.1133e-02, -8.7682e-02, -1.5643e-01,  1.9625e-01,  2.8804e-01,\n",
      "         5.7403e-01,  1.3846e-01,  1.2636e-01,  1.5914e-02,  2.3756e-01,\n",
      "         1.8237e-01, -2.3214e-01, -7.7859e-02, -2.5550e-01,  4.8779e-03,\n",
      "         5.8136e-02, -1.2507e-01,  1.4878e-02,  2.3669e-01, -9.2488e-02,\n",
      "        -1.0474e-01, -5.7106e-02,  1.2064e-01, -2.6196e-01,  3.3503e-02,\n",
      "         1.8292e-01,  3.9604e-02, -3.3971e-01,  1.1297e-02,  5.4101e-02,\n",
      "         2.6404e-01,  2.2004e-01, -9.2788e-02,  2.9447e-02,  1.2066e-01,\n",
      "         1.3269e-01, -2.2497e-01, -6.4097e-02,  3.1223e-01,  3.4955e-01,\n",
      "        -6.1191e-02,  1.2360e-01,  1.3307e-01,  8.2574e-02, -5.9981e-02,\n",
      "        -6.6661e-03, -2.8992e-01, -7.2593e-01,  6.2870e-02,  5.5021e-02,\n",
      "         6.3896e-01,  9.3167e-01,  1.0774e-01, -2.0502e-01,  4.6060e-03,\n",
      "         6.3652e-03, -7.0160e-02, -7.5050e-02,  2.5006e-01, -2.4793e-01,\n",
      "         1.3870e-01,  5.1388e-02,  4.5040e-01,  2.0028e-02,  3.0436e-01,\n",
      "         3.0103e-01,  8.5672e-02, -9.4611e-02,  6.0981e-02, -1.4424e-01,\n",
      "         1.9353e-01, -1.1344e-01,  6.6251e-02, -5.3097e-02,  1.4999e-01,\n",
      "        -1.3848e-02,  6.4972e-02, -9.8210e-02,  2.2645e-01,  1.5304e-01,\n",
      "         2.1574e-01,  1.5160e-01,  3.0758e-02, -8.5251e-02, -1.9913e-01,\n",
      "        -2.1894e-02, -3.4432e-02, -2.8611e-01,  1.5086e-01,  1.8164e-02,\n",
      "         1.0613e-01,  3.8217e-02,  1.9092e-01,  3.0359e-02,  2.1835e-02,\n",
      "         4.8255e-02,  7.9912e-02,  4.8990e-02,  8.4280e-02, -1.3373e-01,\n",
      "        -9.0488e-02,  4.3405e-02, -1.9337e-01, -9.0249e-02, -1.7069e-01,\n",
      "        -3.9263e-03,  7.2836e-02,  1.6152e-02, -5.3900e-02, -4.3985e-02,\n",
      "        -9.3080e-02,  1.6482e-01, -9.9161e-04,  1.6338e-01,  1.2466e-01,\n",
      "         1.8798e-01, -5.9851e-02,  1.3112e-01, -1.3064e-01,  1.4206e-02,\n",
      "         4.8045e-02,  3.9362e-01, -4.1085e-01, -4.8672e-02,  2.0938e-01,\n",
      "         1.3927e-01,  1.1845e-01,  3.9521e-02, -3.0074e-03,  9.3998e-02,\n",
      "         1.4799e-01,  9.0979e-02,  1.5172e-01,  3.4148e-01,  4.4117e-02,\n",
      "         3.1777e-01,  8.0567e-02, -2.7646e-02, -1.3292e-01,  1.4027e-01,\n",
      "         3.9583e-01, -1.6338e-01, -2.7566e-02,  1.6627e-01,  1.4654e-01,\n",
      "         2.4833e-01, -5.5510e-02, -5.2000e-01, -2.8430e-02,  1.1763e-01,\n",
      "         6.2096e-02,  7.2025e-03, -4.6961e-02,  1.7006e-01,  2.6732e-01,\n",
      "         2.4078e-01, -2.1479e-01,  6.2024e-02, -1.8494e-01,  1.6928e-01,\n",
      "         3.5825e-02,  2.3924e-01, -6.2474e-02,  1.7652e-01,  8.5235e-02,\n",
      "         1.4489e-01,  9.9217e-02, -8.5093e-02, -9.3000e-03,  8.8963e-02,\n",
      "         2.8872e-01, -1.3335e-01, -8.0726e-02, -3.1015e-02,  4.7625e-02,\n",
      "         1.9647e-01, -1.4587e-03,  5.4167e-02, -8.9253e-02, -2.0653e-02,\n",
      "        -1.2537e-02,  1.9728e-01,  1.0240e-01, -4.7317e-02,  1.0234e-01,\n",
      "        -5.1925e-02,  3.8258e-02, -7.7447e-02,  1.6971e-02,  7.7110e-02,\n",
      "        -2.0524e-02,  5.2619e-03, -2.4851e-02, -6.1425e-02,  6.8476e-02,\n",
      "        -9.6446e-02,  5.9320e-02,  1.2393e-01,  1.2600e-02,  1.7384e-01,\n",
      "         9.7060e-02,  1.4474e-02,  1.2497e-01, -1.6013e-01, -4.0773e+00,\n",
      "         1.6811e-01, -3.1732e-01, -4.2771e-01,  1.6380e-01,  6.7505e-01,\n",
      "         3.8424e-01, -1.3523e-03,  6.8340e-03, -5.7372e-02, -5.5588e-02,\n",
      "         1.9293e-01, -1.4189e-01,  9.3311e-02, -4.8796e-02,  2.3739e-01,\n",
      "        -2.8833e-03,  1.9455e-01,  3.4183e-01, -3.6076e-02,  1.5810e-01,\n",
      "         6.5033e-02,  1.5095e-01, -1.0517e-01,  9.3679e-02,  1.2317e-01,\n",
      "         5.3483e-02, -1.5521e-01, -5.8113e-01,  2.3941e-01,  1.0354e-01,\n",
      "         2.0393e-01, -1.0424e-01, -6.9754e-02, -6.5374e-02, -1.1947e-01,\n",
      "         2.5323e-01, -7.7077e-02, -5.6776e-01, -6.0630e-02,  7.2252e-02,\n",
      "        -7.8711e-02,  9.8424e-02, -4.5847e-02,  7.9335e-02,  2.0453e-01,\n",
      "         1.1820e-01,  6.8770e-02, -1.0676e-01,  5.9427e-03,  3.8385e-02,\n",
      "         6.0767e-01,  1.3169e-01,  1.1672e-01,  6.6626e-03, -1.1800e-02,\n",
      "         1.6033e-01,  9.5113e-02, -2.5487e-02,  1.3029e-01, -7.9355e-02,\n",
      "         4.5986e-01,  9.3418e-02, -6.3090e-02,  6.6175e-02, -1.5528e-01,\n",
      "        -9.0984e-02,  1.4317e-01, -1.4251e-01, -5.8484e-02,  1.0288e-01,\n",
      "         1.0648e-01, -7.4303e-02,  7.5131e-03, -6.3032e-01, -8.8255e-02,\n",
      "         2.4886e-01,  1.7072e-02,  1.4108e-01, -9.6355e-02, -5.6064e-02,\n",
      "        -1.2629e-01,  3.7223e-02,  6.2077e-02,  8.8362e-02,  6.7475e-03,\n",
      "        -8.3915e-02,  1.6224e-01, -9.3116e-02,  5.9442e-02,  5.7316e-02,\n",
      "        -6.6124e-02, -1.8397e-02,  1.0796e-01,  1.1767e-01,  1.3588e-01,\n",
      "        -2.6879e-01,  7.9406e-02,  2.8379e-01,  2.6937e-02, -4.6088e-02,\n",
      "         4.6877e-02, -6.5213e-03, -4.0031e-02,  6.4983e-02,  1.3700e-01,\n",
      "         2.1715e-01, -1.2797e-01, -5.4792e-02, -1.4530e-01, -6.0178e-02,\n",
      "         2.9036e-01,  4.1906e-03, -4.9892e-02, -1.6983e-02, -2.0930e-01,\n",
      "         7.2495e-03, -3.8286e-02, -1.7508e-01,  2.1811e-01, -7.5194e-01,\n",
      "         2.5805e-01, -7.8109e-02,  4.4503e-02,  1.0250e-01, -2.3103e-01,\n",
      "        -2.6060e-02,  2.4747e-02, -4.2283e-03, -1.3644e+01, -1.0044e-01,\n",
      "         3.6300e-02, -1.8063e-01, -1.0414e-01,  3.0948e-02, -8.9028e-02,\n",
      "         3.9884e-02, -6.7074e-02, -9.6255e-02, -2.8354e-02, -6.7077e-02,\n",
      "         2.5768e-01, -5.5730e-02,  2.2947e-01, -1.5950e-01,  6.1632e-02,\n",
      "         4.5903e-01,  7.9078e-02,  2.6057e-02,  1.1915e-02, -1.1965e-02,\n",
      "         1.6651e-01,  5.1976e-02, -1.7255e-01,  2.6524e-02, -1.2811e-01,\n",
      "        -2.5710e-02, -9.9459e-02,  5.9180e-02,  4.6486e-02, -2.7291e-02,\n",
      "         4.2579e-02, -2.1981e-03, -4.0914e-03,  1.8874e-01, -8.8146e-02,\n",
      "         2.7912e-02,  5.0425e-01, -4.8749e-01, -8.4700e-02,  4.7316e-01,\n",
      "         3.8269e-02,  3.0434e-02,  4.6012e-01, -2.0660e-01,  1.5823e-01,\n",
      "        -3.1305e-02, -2.7128e-03,  1.5780e-01,  9.0704e-02,  8.8208e-02,\n",
      "        -4.0623e-01,  1.4572e-01,  1.4708e-02,  8.6302e-02, -1.1265e-02,\n",
      "         2.1113e-01,  7.7819e-02, -7.2600e-02,  1.6569e-01,  3.6808e-02,\n",
      "         1.2579e-01, -1.5096e-01,  6.3391e-02,  2.5800e-03,  8.5874e-02,\n",
      "         6.4623e-02, -1.0620e-01, -6.5046e-02,  1.2697e-01,  1.2370e-01,\n",
      "         6.5938e-01,  3.5938e-01, -1.7803e-02,  1.2374e-02,  8.9805e-02,\n",
      "        -9.8392e-02, -1.1641e-02,  2.4332e-01, -1.2797e-01, -3.1770e-01,\n",
      "        -1.3418e-01, -3.2688e-02,  6.3757e-02,  1.2003e-01,  5.0493e-02,\n",
      "        -6.4197e-02, -2.4402e-02,  8.8511e-02,  5.3304e-02,  3.3438e-01,\n",
      "        -8.1548e-02,  4.6498e-02,  1.1525e-01, -7.2494e-02,  6.9277e-03,\n",
      "        -8.7734e-02,  4.7467e-01,  6.2850e-02,  6.9265e-01, -2.1984e-01,\n",
      "        -1.4706e-01, -1.5532e-01, -6.6620e-02,  2.9057e-01, -7.1820e-01,\n",
      "         1.5299e-01,  1.0177e-01,  2.3578e-02, -2.4935e-01,  8.2180e-03,\n",
      "         8.8689e-02,  9.0768e-02,  1.5659e-01,  1.0631e-01,  2.7482e-01,\n",
      "        -9.3947e-02, -4.1192e-02,  2.8750e-01,  4.9038e-02,  2.7599e-01,\n",
      "        -2.0418e-02,  1.8230e-02,  1.1998e-01,  1.0656e-02,  7.8694e-02,\n",
      "        -3.2462e-01, -9.8682e-02,  9.1006e-02, -1.7190e-01,  5.0481e-02,\n",
      "         1.0615e-01,  7.5626e-02,  4.2071e-02,  2.0761e-01, -9.7509e-02,\n",
      "        -8.3835e-02,  2.8769e-02,  1.4857e-02,  1.5026e-02, -2.5009e-01,\n",
      "        -1.0052e-01, -2.5200e-01, -5.8032e-02,  8.4249e-02, -1.0757e-01,\n",
      "         7.9946e-02,  3.9047e-01,  2.4888e-01,  1.7319e-02, -4.1251e-01,\n",
      "         1.0920e-01,  3.5511e+01, -3.5655e-02,  1.6037e-01,  1.4047e-01,\n",
      "        -7.9848e-02,  2.3223e-01, -2.0267e-03,  1.9461e-01, -2.8006e-01,\n",
      "         1.8167e-01,  1.4022e-01, -6.1227e-02, -1.8324e-01, -2.2230e-01,\n",
      "        -5.8223e-02,  4.9720e-02,  9.6824e-02, -1.3894e-01,  1.7717e-01,\n",
      "        -2.6188e-02,  1.2361e-01,  4.7295e-02, -3.8665e-02,  6.7525e-01,\n",
      "         1.9737e-01,  3.2203e-02,  8.0080e-01], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "y = data['label']\n",
    "y = torch.tensor(y).to(device)\n",
    "print(y[1000],X[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "413b9e52-1875-4e4c-8c07-6a0c9d18f6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6.9675e-02,  7.7524e-02, -4.8405e-02,  8.7762e-02, -2.1373e-02,\n",
      "        -7.0729e-02, -1.3044e-02,  2.2310e-01,  3.5856e-02, -3.9805e-02,\n",
      "        -2.8858e-02,  9.9903e-02,  1.1901e-01,  7.0323e-02,  7.1627e-03,\n",
      "         8.1264e-02,  2.9464e-02,  2.1906e-02,  3.3575e-02,  1.5326e-02,\n",
      "         1.0041e-01,  2.4231e-02,  2.8257e-02,  1.0127e-01,  9.3648e-02,\n",
      "        -1.2036e-01,  4.5067e-02, -3.8167e-02,  1.5165e-01, -4.0828e-02,\n",
      "         5.3078e-02, -8.6856e-02, -8.1753e-02, -9.0155e-03,  8.3507e-02,\n",
      "         6.0432e-02,  8.2966e-04, -2.4601e-02, -2.2407e-01,  7.2635e-02,\n",
      "         1.3449e-01, -1.0850e-01,  2.9732e-03,  2.9165e-02,  2.9882e-02,\n",
      "         5.0211e-02,  1.6391e-02,  1.0101e-04, -3.7670e-03, -7.1267e-02,\n",
      "         4.0323e-02, -1.0894e-01,  9.6292e-02,  8.9507e-04, -6.3622e-02,\n",
      "        -4.7164e-02,  8.2625e-02,  1.0176e-02, -1.8386e-01,  1.2664e-01,\n",
      "         7.4938e-02,  1.5429e-02,  7.2286e-02, -6.2298e-02, -6.0989e-02,\n",
      "         1.7736e-02, -5.1333e-02, -4.2081e-03, -1.5176e-01,  7.2812e-02,\n",
      "         5.4317e-02,  1.0260e-01,  3.1016e-01,  4.1953e-02,  2.4561e-02,\n",
      "        -6.6368e-02,  1.2850e-02, -7.5583e-02,  1.0187e-02, -9.3573e-03,\n",
      "         3.9264e-02,  1.0277e-01, -2.0705e-02,  7.7945e-02, -3.6830e-02,\n",
      "        -7.0096e-02, -3.7758e-02, -1.8785e-02,  2.3875e-02,  1.8369e-01,\n",
      "        -4.4884e-02, -3.8794e-02,  1.2493e-01, -3.0499e-02,  3.6974e-02,\n",
      "         1.4708e-02,  9.8215e-02,  9.7232e-02, -2.1041e-02, -8.8996e-02,\n",
      "         2.7744e-02,  1.0272e-01, -1.5127e-01, -1.5768e-01, -2.2060e-02,\n",
      "         4.1509e-02,  9.7021e-02, -5.3934e-02,  3.9008e-02,  5.4586e-02,\n",
      "         1.7606e-02,  5.6841e-03, -1.1814e-01, -1.7500e-01,  1.6282e-01,\n",
      "        -4.6234e-02, -1.4668e-01,  1.1230e-01,  7.6459e-02,  8.3966e-02,\n",
      "         6.5838e-02,  1.6772e-01, -1.0131e-01,  8.5160e-02,  2.4855e-03,\n",
      "        -4.3828e-02,  9.4463e-03,  5.2257e-02, -1.9848e-02,  2.3949e-03,\n",
      "         8.6931e-02, -1.1369e-02, -6.2527e-03,  1.2294e-01, -2.9565e-02,\n",
      "         1.6156e-01, -6.3837e-02, -7.5232e-03, -2.6712e-03, -1.1497e-01,\n",
      "        -3.4223e-02,  1.6089e-01, -2.8813e-02,  4.9820e-03, -2.8777e-02,\n",
      "         1.0009e+00, -3.9888e-02,  2.6948e-02, -8.0087e-02,  1.6046e-01,\n",
      "         1.4899e-02,  3.0725e-01,  8.0963e-02, -8.2077e-02, -4.9894e-02,\n",
      "         1.7016e-02, -3.3799e-01, -4.1878e-02, -4.1587e-02,  5.4243e-02,\n",
      "        -5.5832e-02,  5.6449e-02,  1.4694e-01,  1.9691e-02,  2.4631e-01,\n",
      "         4.6610e-02,  3.7228e-02,  2.9303e-02, -8.1235e-02, -6.4245e-02,\n",
      "         1.1408e-02,  8.1110e-03,  9.5040e-02, -4.6756e-02,  4.6934e-02,\n",
      "        -1.8173e-03, -5.6202e-02, -1.3450e-01, -4.2714e-03, -3.6113e-02,\n",
      "        -2.3137e-01,  2.6727e-02,  1.2323e-03,  9.7961e-02, -1.4931e-02,\n",
      "         3.7065e-02, -1.2772e-02,  1.5689e-02, -2.5589e-02, -4.9127e-02,\n",
      "        -5.3478e-02,  2.2149e-01,  6.2269e-02,  1.3170e-01, -3.1043e-03,\n",
      "        -2.7718e-02, -6.9321e-03,  1.7943e-02,  2.0083e-03, -3.6654e-02,\n",
      "         8.7444e-02,  3.6273e-02,  2.1803e-02,  7.5669e-02, -5.7776e-02,\n",
      "        -1.5377e-01, -1.0708e-01,  1.7067e-01,  4.1990e-03,  1.2447e-01,\n",
      "         1.5575e-01,  7.4353e-02,  2.5440e-01, -5.4879e-02,  1.0701e-01,\n",
      "        -1.6438e-01,  2.3311e-02,  2.2717e-01,  1.2773e-01,  1.6044e-02,\n",
      "         1.7158e-02, -6.3482e-02, -3.6951e-02,  6.6605e-02,  5.7292e-02,\n",
      "        -2.6954e-02,  1.0649e-02, -3.2011e-02,  2.1686e-02, -1.1013e-01,\n",
      "         1.8919e-01, -1.2734e-01,  7.6550e-02, -3.8738e-02, -1.0785e-02,\n",
      "        -4.2203e-02, -3.8104e-02,  2.3455e-02,  4.9250e-02, -2.6693e-01,\n",
      "        -3.3970e-02,  3.0292e-02,  2.6526e-02,  7.8922e-03, -3.7506e-02,\n",
      "        -1.4169e-02, -7.9791e-02,  3.2702e-02, -1.4863e-02,  5.8988e-02,\n",
      "         1.5128e-01,  2.9558e-02,  2.3994e-02,  7.1060e-02, -2.4761e-02,\n",
      "         1.5659e-01,  3.1532e-02, -1.1959e-02,  9.0950e-02, -2.8183e-01,\n",
      "         1.2115e-01,  4.7816e-02,  1.4456e-01,  5.2165e-02,  8.8481e-02,\n",
      "        -1.4623e-01, -2.8009e-01, -3.0538e-02,  1.3798e-02,  5.8805e-02,\n",
      "        -2.8160e-02,  6.5230e-02, -7.5250e-02, -8.8642e-02, -5.1066e-03,\n",
      "        -8.8492e-02, -2.5830e-02,  4.5222e-02,  4.4997e-02, -8.8505e-03,\n",
      "         7.7248e-02,  8.4679e-02, -2.8089e-01, -6.9051e-02,  1.0733e-01,\n",
      "         2.0563e-01, -1.1560e-01,  2.2296e-01, -1.2175e-02, -1.0606e-01,\n",
      "        -2.8986e-03, -7.7109e-02, -4.8329e-02, -3.9592e-02,  3.1389e-01,\n",
      "         3.2674e-02,  8.9547e-04,  5.6407e-02, -5.9404e-02, -9.3794e-02,\n",
      "        -4.4360e-02, -1.1259e-01,  2.1306e-01, -1.2187e-02,  2.5525e-01,\n",
      "        -3.6736e-02,  3.0033e-01, -1.1811e-01, -2.6258e-01,  3.4056e-02,\n",
      "         3.9370e-02, -1.1449e-01, -1.5488e-01,  2.3522e-02,  7.4356e-02,\n",
      "         3.2126e-02,  3.4644e-01,  5.8147e-02,  1.3821e-02,  1.1516e-02,\n",
      "         1.6495e-02, -8.7970e-02, -3.6015e-02,  1.3016e-02,  1.5188e-01,\n",
      "         9.7069e-03,  4.7622e-02,  1.8281e-02,  1.2165e-01,  4.9541e-02,\n",
      "        -1.5982e-02, -1.3105e-02, -1.3622e-01, -2.2949e-02,  3.5161e-02,\n",
      "         2.7744e-02, -1.9364e-02, -8.2734e-02, -3.4290e-02,  5.7290e-03,\n",
      "        -2.2684e-02, -8.3185e-02, -5.4534e-02,  2.0705e-01,  4.2167e-02,\n",
      "         2.9717e-02,  1.6653e-02, -3.3749e-02,  8.3929e-02,  4.4030e-02,\n",
      "         3.4657e-02,  3.7842e-02,  1.2169e-02,  1.2763e-02, -1.5180e-01,\n",
      "         4.9722e-02,  9.1338e-02,  1.2264e-01,  5.5106e-02, -8.7599e-02,\n",
      "         1.6125e-02, -1.4918e-01,  3.8649e-02,  3.2489e-02, -6.3334e-02,\n",
      "         1.6910e-01, -6.5042e-02,  1.8714e-01, -7.9177e-03,  3.4269e-02,\n",
      "         9.5523e-02,  1.0177e-01,  1.1372e-02,  5.4687e-02, -5.0324e-02,\n",
      "         2.3701e-02,  1.0968e-01, -1.8421e-01,  4.6482e-02, -3.3040e-02,\n",
      "         4.5555e-02,  7.3240e-03,  5.4419e-02, -2.1319e-02, -6.4207e-02,\n",
      "         2.3695e-02, -5.1083e-03, -1.7461e-01,  9.1160e-03, -1.4791e-02,\n",
      "         1.2290e-01, -4.1431e-01, -6.5836e-03,  6.3857e-03,  2.8112e-02,\n",
      "         1.2999e-02,  1.8349e-02, -4.9116e-02, -4.6006e-02,  3.0973e-01,\n",
      "         7.0761e-02,  2.2805e-03, -1.8752e-01,  7.7115e-02,  2.4716e-02,\n",
      "         3.5677e-02, -1.6658e-01,  1.8174e-02,  1.0224e-01, -3.3841e-02,\n",
      "        -1.1936e-02, -4.4120e-02,  8.9442e-02, -1.4887e-02, -1.9890e-02,\n",
      "        -7.0363e-04, -3.2797e-02,  1.0360e-01,  3.1113e-01, -3.6632e-03,\n",
      "         5.9353e-02, -1.2801e-01,  8.7818e-03, -1.8688e-02, -7.9311e-02,\n",
      "         2.3024e-01, -1.1873e-01, -2.0273e-02,  4.3053e-02, -2.2937e-02,\n",
      "        -6.2006e-02, -8.9834e-03, -3.7961e-02,  1.0276e-01,  1.0658e-01,\n",
      "        -1.9234e-02, -5.8657e-02, -6.1342e-02,  1.9398e-01,  1.5437e-01,\n",
      "         9.2034e-02,  1.0157e-02,  3.5865e-02,  2.1911e-02, -6.5607e-02,\n",
      "         8.9087e-02,  4.9937e-02,  3.6384e-02,  2.1669e-01,  9.8875e-03,\n",
      "         7.8646e-03,  1.3528e-02,  6.8249e-02,  8.0534e-03, -4.6528e-03,\n",
      "         4.5320e-02, -9.1334e-02,  1.3227e-01,  4.5557e-02, -4.3657e-01,\n",
      "         2.6119e-01,  4.8084e-02,  4.6977e-02, -1.1221e-01, -1.0121e-01,\n",
      "        -1.3327e-01,  8.3392e-03,  1.3691e-01, -8.4512e-02, -4.7090e-02,\n",
      "        -3.5727e-02, -3.2035e-02, -1.1416e-02,  8.8523e-02,  1.0180e-03,\n",
      "        -5.9687e-02,  4.5639e-02,  2.0115e-01,  3.3442e-03,  8.2928e-03,\n",
      "        -2.3915e-02, -1.8693e-02, -4.9292e-02,  2.8500e-02,  6.0055e-02,\n",
      "         2.2408e-02, -3.3000e-01,  1.9824e-01,  4.5276e-02, -1.0030e-01,\n",
      "         3.5549e-02,  5.9069e-02, -3.2510e-02, -4.9837e-04,  2.3775e-02,\n",
      "        -1.2847e-01, -2.8260e-02, -1.4442e-01,  2.0839e-01, -1.0979e-01,\n",
      "         1.8974e-02,  7.7928e-02,  3.7794e-03, -1.5392e-02,  2.0104e-02,\n",
      "         9.5944e-02, -5.3970e-03, -5.0196e-03,  1.1916e-01,  3.3811e-02,\n",
      "         5.2514e-01, -2.1764e-02, -3.6849e-02, -4.1477e-02, -4.9159e-02,\n",
      "        -3.4042e-02, -9.4769e-02,  4.7915e-02,  4.3316e-02, -4.3662e-02,\n",
      "         6.2163e-04,  6.1479e-03, -4.2347e-02, -3.5871e-02, -9.4654e-03,\n",
      "         4.3069e-02, -9.0587e-02, -2.0749e-02,  1.1625e-02,  3.3432e-02,\n",
      "         1.6125e-01, -1.5141e-01,  7.7830e-02, -3.4590e-01, -1.0180e-01,\n",
      "         1.8691e-01, -1.5481e-02, -2.5354e-02,  3.4694e-02,  6.3130e-02,\n",
      "         1.2656e-01,  8.0110e-03,  6.7393e-02,  1.3037e-01, -1.5782e-03,\n",
      "         1.0388e-01,  6.8951e-02, -1.9085e-02, -1.0438e-02, -3.2148e-02,\n",
      "         3.3101e-03, -1.7653e-01, -8.7280e-03,  1.5208e-01, -2.0284e-01,\n",
      "        -2.9203e-02,  2.0123e-02, -4.2807e-02,  4.1818e-03,  5.6908e-02,\n",
      "         2.5630e-03,  3.3535e-02, -1.0940e-02,  6.8038e-03,  5.2853e-03,\n",
      "         5.9174e-02, -3.4058e-02, -3.7785e-03,  7.8385e-02,  5.5698e-02,\n",
      "        -1.6842e-01,  1.0756e-01, -2.6160e-02,  2.4163e-01,  8.0181e-02,\n",
      "         8.1959e-02,  1.0676e-01, -3.9901e-03,  1.4579e-01,  1.3351e-01,\n",
      "        -1.2610e-01, -1.5406e-01,  8.8911e-02, -1.0151e-01, -8.3292e-03,\n",
      "        -3.4352e-02, -1.3958e-02, -3.7441e-01, -5.6400e+00, -8.3925e-02,\n",
      "         8.2405e-02, -4.9055e-02,  1.0162e-01,  8.6836e-02,  6.5396e-02,\n",
      "        -4.2565e-02,  2.6952e-02,  6.9801e-02,  1.8226e-02,  9.8881e-02,\n",
      "        -8.5211e-02,  2.9465e-02,  1.4147e-03, -4.5483e-02, -5.1816e-02,\n",
      "        -2.1938e-01,  5.7432e-02,  2.2850e-02, -4.5232e-03,  2.3697e-01,\n",
      "         1.3075e-01,  2.1035e-02, -9.9482e-03, -8.7589e-03,  2.0205e-02,\n",
      "        -1.2434e-01,  5.6636e-02, -3.6970e-03, -3.0985e-02,  4.1052e-02,\n",
      "        -4.0303e-02,  4.5291e-02, -3.7000e-02,  6.3165e-03,  3.1157e-02,\n",
      "         1.4617e-02,  1.3735e-01, -1.8193e-01,  1.7569e-02,  8.7713e-02,\n",
      "         1.9791e-01, -2.1005e-02,  1.4668e-01, -3.5560e-01, -9.2418e-02,\n",
      "         6.6871e-03,  3.1730e-03,  1.2270e-02,  2.6787e-02,  2.0983e-02,\n",
      "        -2.3346e-01,  9.7788e-02, -8.0914e-03,  8.8890e-02,  1.7325e-02,\n",
      "        -1.2669e-01, -1.0739e-02,  4.3602e-02, -1.2164e-01,  1.8494e-01,\n",
      "         2.5994e-02,  3.8632e-02, -2.8370e-02, -3.7172e-02, -2.2844e-02,\n",
      "        -6.2928e-02, -9.9115e-02,  4.0490e-02,  3.4097e-02, -1.6403e-02,\n",
      "        -6.7404e-02, -1.0163e-01,  1.1563e-01, -5.1298e-02,  7.9258e-03,\n",
      "         1.9307e-02, -2.3912e-02,  2.3904e-03,  1.7739e-02, -7.0747e-03,\n",
      "         9.7980e-02,  8.6459e-02,  3.4255e-02, -3.4064e-02,  5.2226e-02,\n",
      "         5.8295e-02, -3.2140e-03, -1.0816e-02, -1.4035e-01, -1.3861e-01,\n",
      "        -7.8366e-02,  1.4876e-01,  8.0633e-02, -1.0771e-01,  2.2477e-01,\n",
      "         2.3095e-02,  2.5367e-01, -9.0645e-02, -8.1035e-02,  1.2216e-01,\n",
      "         3.3616e-02,  6.7455e-03, -2.2656e-02,  8.5773e-02, -3.9254e-01,\n",
      "         4.6046e-02,  2.4530e-03,  2.7747e-02,  2.0479e-02, -6.0014e-02,\n",
      "        -2.9637e-02,  3.0703e-02,  8.3093e-02, -1.8364e-02,  1.5833e-01,\n",
      "        -9.3345e-02,  5.5040e-03, -3.5507e-02, -6.1017e-02,  5.8184e-02,\n",
      "        -1.8475e-02,  5.3495e-03, -2.0928e-02,  6.4522e-04,  4.7362e-02,\n",
      "        -2.6823e-02, -7.3133e-02,  9.6829e-02,  9.4350e-02, -1.4595e-02,\n",
      "        -1.2808e-02, -4.2590e-04, -1.2372e-01,  1.4616e-03,  2.0763e-02,\n",
      "         1.8444e-02,  7.4227e-02,  7.0656e-03,  1.7126e-01, -8.5413e-02,\n",
      "        -1.7579e-02, -1.9407e-01,  1.7916e-02,  6.6390e-02, -1.7190e-01,\n",
      "        -4.1679e-02, -3.0377e-02,  7.7964e-02, -1.0833e-01, -6.1597e-02,\n",
      "        -3.9680e-02,  1.8048e+01, -5.6877e-03, -5.3306e-02,  2.9860e-02,\n",
      "         2.3391e-02,  1.0238e-02, -4.8455e-02,  4.1612e-02, -5.0956e-01,\n",
      "         3.6940e-02, -6.2688e-02,  2.4738e-02, -2.4539e-01, -2.6470e-02,\n",
      "        -6.4763e-03, -2.5473e-02,  6.9259e-02, -2.2276e-02,  5.8507e-02,\n",
      "        -1.0050e-02,  4.7768e-02,  4.5719e-02,  5.3153e-03, -1.2967e-01,\n",
      "        -7.2574e-02,  2.7658e-02, -5.3765e-02], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#print(len(X))\n",
    "#print(X.shape)  # Should print: torch.Size([length_of_sequence])\n",
    "#print(type(X))#X_Stack = torch.stack(X)\n",
    "#print(X_Stack.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=12\n",
    ")\n",
    "print(X[0])\n",
    "#print(X_train.shape,X_test.shape,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0476e700-6699-4284-b7f3-2a3d2aa949f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test,y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "01f5cd32-3543-48dc-83ab-d3ae276296d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleNN(\n",
       "  (fc1): Linear(in_features=768, out_features=128, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # Input to hidden layer\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        # Second hidden layer\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        # Output layer\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model2 = SimpleNN(input_size=768, hidden_size=128, output_size=3)\n",
    "model2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c63f9d96-6da0-4e71-a263-58753ffdd4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/50: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 352.80it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Training loss: 1.0947, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 1/50: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 423.38it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 404.70it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "Training loss: 1.0945, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 2/50: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 724.78it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 371.99it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "Training loss: 1.0945, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 3/50: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 677.73it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 400.22it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "Training loss: 1.0945, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 4/50: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 648.52it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/50: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 341.96it/s, loss=1.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "Training loss: 1.0944, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 5/50: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 636.75it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 363.37it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "Training loss: 1.0946, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 6/50: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 651.95it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 367.68it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "Training loss: 1.0945, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 7/50: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 595.99it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/50: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 380.62it/s, loss=1.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "Training loss: 1.0943, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 8/50: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 553.14it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/50: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 336.50it/s, loss=1.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "Training loss: 1.0945, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 9/50: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 515.27it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/50: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 347.37it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "Training loss: 1.0946, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 10/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 575.55it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/50: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 344.26it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "Training loss: 1.0946, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 11/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 452.86it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/50: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 362.10it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50\n",
      "Training loss: 1.0945, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 12/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 549.01it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13/50: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 383.19it/s, loss=1.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "Training loss: 1.0944, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 13/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 525.88it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14/50: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 342.37it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "Training loss: 1.0945, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 14/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 687.56it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15/50: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 385.92it/s, loss=1.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "Training loss: 1.0944, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 15/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 636.34it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16/50: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 428.81it/s, loss=1.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50\n",
      "Training loss: 1.0945, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 16/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 471.07it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17/50: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 332.45it/s, loss=1.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50\n",
      "Training loss: 1.0945, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 17/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 400.30it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18/50: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 311.57it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "Training loss: 1.0946, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 18/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 553.61it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19/50: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 320.24it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "Training loss: 1.0946, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 19/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 505.84it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20/50: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 273.02it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "Training loss: 1.0945, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 20/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 372.25it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 21/50: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 281.18it/s, loss=1.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50\n",
      "Training loss: 1.0948, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 21/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 411.48it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 22/50: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 296.35it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50\n",
      "Training loss: 1.0945, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 22/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 473.30it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 23/50: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 317.12it/s, loss=1.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50\n",
      "Training loss: 1.0944, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 23/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 488.15it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 24/50: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 315.72it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50\n",
      "Training loss: 1.0945, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 24/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 508.69it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 25/50: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 267.73it/s, loss=1.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "Training loss: 1.0944, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 25/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 434.42it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 26/50: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 340.53it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50\n",
      "Training loss: 1.0945, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 26/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 451.80it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 27/50: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 268.96it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      "Training loss: 1.0946, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 27/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 448.23it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 28/50: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 323.58it/s, loss=1.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "Training loss: 1.0947, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 28/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 406.85it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 29/50: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 348.80it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "Training loss: 1.0947, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 29/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 541.03it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 30/50: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 311.31it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50\n",
      "Training loss: 1.0946, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 30/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 612.62it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 31/50: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 331.45it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "Training loss: 1.0946, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 31/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 385.02it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 32/50: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 280.10it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      "Training loss: 1.0946, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 32/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 439.97it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 33/50: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 300.41it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "Training loss: 1.0946, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 33/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 562.33it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 34/50: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 271.39it/s, loss=1.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "Training loss: 1.0943, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 34/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 480.43it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 35/50: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 365.08it/s, loss=1.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "Training loss: 1.0945, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 35/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 354.80it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 36/50: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 285.52it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50\n",
      "Training loss: 1.0945, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 36/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 504.18it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 37/50: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 309.27it/s, loss=1.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50\n",
      "Training loss: 1.0945, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 37/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 488.06it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 38/50: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 293.75it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "Training loss: 1.0945, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 38/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 481.18it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 39/50: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 346.26it/s, loss=1.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "Training loss: 1.0945, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 39/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 518.58it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 40/50: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 372.71it/s, loss=1.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "Training loss: 1.0945, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 40/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 579.00it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 41/50: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 353.34it/s, loss=1.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "Training loss: 1.0945, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 41/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 605.48it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 42/50: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 332.79it/s, loss=1.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "Training loss: 1.0945, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 42/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 616.70it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 43/50: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 341.87it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50\n",
      "Training loss: 1.0945, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 43/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 609.55it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 44/50: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 341.18it/s, loss=1.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50\n",
      "Training loss: 1.0944, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 44/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 503.50it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 45/50: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 301.42it/s, loss=1.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "Training loss: 1.0944, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 45/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 446.87it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 46/50: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 335.63it/s, loss=1.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      "Training loss: 1.0944, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 46/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 439.27it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 47/50: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 315.97it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      "Training loss: 1.0946, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 47/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 637.58it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 48/50: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 320.20it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50\n",
      "Training loss: 1.0946, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 48/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 557.38it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 49/50: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 397.43it/s, loss=1.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "Training loss: 1.0944, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 49/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 636.18it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 50/50: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 410.55it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "Training loss: 1.0946, Training accuracy: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 50/50: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 571.31it/s, loss=1.11]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0984, Test accuracy: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 50\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model2.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    # Initialize tqdm progress bar for training\n",
    "    train_progress_bar = tqdm(train_dataloader, desc=f\"Training Epoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    for batch in train_progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Move data and labels to device (CPU or GPU)\n",
    "        data, labels = batch\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model2(data)  # Shape will be (batch_size, 3)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        _, preds = torch.max(outputs, 1)  # Correct way to get predicted class\n",
    "        #print(preds)\n",
    "        correct_predictions += (preds == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "        \n",
    "        # Update tqdm description with current loss\n",
    "        train_progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    print(f\"Training loss: {avg_train_loss:.4f}, Training accuracy: {train_accuracy:.4f}\")\n",
    "    \n",
    "    # Test phase\n",
    "    model2.eval()\n",
    "    test_loss = 0\n",
    "    correct_test_predictions = 0\n",
    "    total_test_predictions = 0\n",
    "    \n",
    "    test_progress_bar = tqdm(test_dataloader, desc=f\"Test Epoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_progress_bar:\n",
    "            data, labels = batch\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model2(data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Calculate test accuracy\n",
    "            preds = torch.argmax(outputs, dim=-1)  # Correct way to get predicted class\n",
    "            #print(preds)\n",
    "            correct_test_predictions += (preds == labels).sum().item()\n",
    "            total_test_predictions += labels.size(0)\n",
    "            \n",
    "            test_progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    avg_test_loss = test_loss / len(test_dataloader)\n",
    "    test_accuracy = correct_test_predictions / total_test_predictions\n",
    "    \n",
    "    print(f\"Test loss: {avg_test_loss:.4f}, Test accuracy: {test_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
