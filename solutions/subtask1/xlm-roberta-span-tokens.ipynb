{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd98ef55-9064-4d3c-92d1-dbfd7984be9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/matijak/Documents/programiranje/projects/semeval/merged_data/subtask1.parquet\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "wd = Path.cwd()\n",
    "wd = wd.parent.parent\n",
    "wd = wd / 'merged_data' \n",
    "sub1 = str(wd) + '/subtask1.parquet'\n",
    "print(sub1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49018793-b401-4aba-8124-842944fddb96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>art_name</th>\n",
       "      <th>entity</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>class1</th>\n",
       "      <th>classes2</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_670.txt</td>\n",
       "      <td>Запад</td>\n",
       "      <td>152</td>\n",
       "      <td>156</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Conspirator, Instigator, Foreign Adversary]</td>\n",
       "      <td>Опитът на колективния Запад да „обезкърви Руси...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_670.txt</td>\n",
       "      <td>САЩ</td>\n",
       "      <td>530</td>\n",
       "      <td>532</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Instigator]</td>\n",
       "      <td>Опитът на колективния Запад да „обезкърви Руси...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_670.txt</td>\n",
       "      <td>НАТО</td>\n",
       "      <td>535</td>\n",
       "      <td>538</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Instigator]</td>\n",
       "      <td>Опитът на колективния Запад да „обезкърви Руси...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_670.txt</td>\n",
       "      <td>Украйна</td>\n",
       "      <td>578</td>\n",
       "      <td>584</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Foreign Adversary]</td>\n",
       "      <td>Опитът на колективния Запад да „обезкърви Руси...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_670.txt</td>\n",
       "      <td>украински войници</td>\n",
       "      <td>633</td>\n",
       "      <td>649</td>\n",
       "      <td>Innocent</td>\n",
       "      <td>[Victim]</td>\n",
       "      <td>Опитът на колективния Запад да „обезкърви Руси...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang    art_name             entity start  end      class1  \\\n",
       "0   BG  BG_670.txt              Запад   152  156  Antagonist   \n",
       "1   BG  BG_670.txt                САЩ   530  532  Antagonist   \n",
       "2   BG  BG_670.txt               НАТО   535  538  Antagonist   \n",
       "3   BG  BG_670.txt            Украйна   578  584  Antagonist   \n",
       "4   BG  BG_670.txt  украински войници   633  649    Innocent   \n",
       "\n",
       "                                       classes2  \\\n",
       "0  [Conspirator, Instigator, Foreign Adversary]   \n",
       "1                                  [Instigator]   \n",
       "2                                  [Instigator]   \n",
       "3                           [Foreign Adversary]   \n",
       "4                                      [Victim]   \n",
       "\n",
       "                                                text  \n",
       "0  Опитът на колективния Запад да „обезкърви Руси...  \n",
       "1  Опитът на колективния Запад да „обезкърви Руси...  \n",
       "2  Опитът на колективния Запад да „обезкърви Руси...  \n",
       "3  Опитът на колективния Запад да „обезкърви Руси...  \n",
       "4  Опитът на колективния Запад да „обезкърви Руси...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(sub1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7df448a3-e5c8-4b49-837d-750ad958209b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lang                                                       EN\n",
       "art_name                                     EN_UA_103861.txt\n",
       "entity                                                Chinese\n",
       "start                                                     791\n",
       "end                                                       797\n",
       "class1                                             Antagonist\n",
       "classes2                                                [Spy]\n",
       "text        The World Needs Peacemaker Trump Again \\n\\n by...\n",
       "label                                                       0\n",
       "input       The World Needs Peacemaker Trump Again  by Jef...\n",
       "Name: 448, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def labelNum(row):\n",
    "    if row['class1'] == 'Antagonist':\n",
    "        return int(0)\n",
    "    if row['class1'] == 'Innocent':\n",
    "        return int(1)\n",
    "    if row['class1'] == 'Protagonist':\n",
    "        return int(2)\n",
    "def cleanText(row):\n",
    "    text = str(row['text'])\n",
    "    #text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = text.replace('\\n',' ').replace('  ', ' ')\n",
    "    return text\n",
    "df['label'] = df.apply(labelNum,axis=1)\n",
    "df['input'] = df.apply(cleanText,axis=1)\n",
    "df.loc[448]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2ebfd06-f15e-4a74-9a45-a5241396d142",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang                                                            BG\n",
      "art_name                                                BG_670.txt\n",
      "entity                                                       Запад\n",
      "start                                                          152\n",
      "end                                                            156\n",
      "class1                                                  Antagonist\n",
      "classes2              [Conspirator, Instigator, Foreign Adversary]\n",
      "text             Опитът на колективния Запад да „обезкърви Руси...\n",
      "label                                                            0\n",
      "input            Опитът на колективния Запад да „обезкърви Руси...\n",
      "new_start_end                                           (151, 156)\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def find_all_substring_start_end(text, substring):\n",
    "    # Use re.finditer to find all occurrences of the substring in the text\n",
    "    matches = re.finditer(re.escape(substring), text)\n",
    "    \n",
    "    # Collect the start and end indices of all matches\n",
    "    positions = [(match.start(), match.end()) for match in matches]\n",
    "    \n",
    "    return positions\n",
    "def adjust_start_end(row):\n",
    "    org_text,cl_text,start,end,entity = str(row['text']),str(row['input']),int(row['start']),int(row['end']),str(row['entity'])\n",
    "    ss1 = find_all_substring_start_end(org_text,entity)\n",
    "    ss2 = find_all_substring_start_end(cl_text,entity)\n",
    "    #print(ss1,ss2)\n",
    "    #print(row['text'][start:end])\n",
    "    a = 0\n",
    "    for i in range(len(ss1)):\n",
    "        if abs((ss1[i][0] - start) + (ss1[i][1] - end) ) <= 2:\n",
    "            a = i\n",
    "            break\n",
    "    if org_text[ss1[a][0]:ss1[a][1]] != cl_text[ss2[a][0]:ss2[a][1]]:\n",
    "        print(\"ERROR!\")\n",
    "    return ss2[a][0],ss2[a][1]\n",
    "df['new_start_end'] = df.apply(adjust_start_end,axis=1)\n",
    "print(df.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2a7cb06-688a-4fb9-aec2-50d1dd290358",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Опитът на колективния Запад да „обезкърви Русия“ с ръцете на властите в Киев „се провали с гръм и трясък“ и скоро от Украйна ... Опитът на колективния [SPAN_START] Запад [SPAN_END] да „обезкърви Русия“ с ръцете на властите в Киев „се провали с гръм и трясък“ и скоро от Украйна няма да остане почти нищо, ако не започне процесът на разрешаване на този въоръжен конфликт. Тази гледна точка изрази пред ТАСС бившият началник на кабинета на държавния секретар на САЩ Колин Пауъл, пенсионирания полковник от армията на САЩ Лорънс Уилкерсън. \"Подкрепата на САЩ, НАТО и други западни съюзници за войната в Украйна срещу Русия е безумна. Това води до смъртта на украински войници в името на загубена кауза, ако не вземете предвид печеленето на пари от американски и европейски военни изпълнители, както и бруталния опит да се обезкърви Русия чрез трети страни“, каза Уилкерсън. \"Усилията за постигане на тази последна цел, при цялата ѝ подлост, се провалиха с гръм и трясък\", заяви видният американски военен анализатор. - В действителност Русия очевидно побеждава\". Ако скоро не бъде обявено прекратяване на огъня и не бъде свикана истинска мирна конференция, тогава от Украйна практически нищо няма да остане“, убеден е Уилкерсън. Той спомена \"истинска мирна конференция\" в противовес на срещата в Бюргенсток (Швейцария), която беше свикана на 15-16 юни по инициатива на Запада и на която Русия не беше поканена. Дори много западни политически анализатори заявиха след срещата, че тя е претърпяла фиаско. Нито една страна от БРИКС не подкрепи заключителния документ от срещата.\n"
     ]
    }
   ],
   "source": [
    "def addTokensToInput(row):\n",
    "    inp = row['input']\n",
    "    start,end = row['new_start_end']\n",
    "    #print(start,end)\n",
    "    start = int(start)\n",
    "    end = int(end)\n",
    "    token_input = inp[:start] + \"[SPAN_START] \" + inp[start:end] + \" [SPAN_END]\" + inp[end:]\n",
    "    return token_input\n",
    "\n",
    "df['span_input'] = df.apply(addTokensToInput,axis=1)\n",
    "print(df['span_input'].loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4221affc-302b-4b48-8394-dff5fb5d6921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "print(len(\"[SPAN_START] \"))\n",
    "def upStartEnd(row):\n",
    "    start,end = row['new_start_end']\n",
    "    start += len(\"[SPAN_START] \")\n",
    "    end += len(\"[SPAN_START] \")\n",
    "    return start,end\n",
    "\n",
    "df['new_start_end'] = df.apply(upStartEnd,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4a2ad11-aec1-4f71-8ec8-640df81ce778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "798 805\n",
      "Chinese\n"
     ]
    }
   ],
   "source": [
    "start,end = df['new_start_end'].loc[448]\n",
    "print(start,end)\n",
    "print(df['span_input'].loc[448][start:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2db66f20-fb08-4a23-a64f-fb3713551dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizerFast\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-base\", num_labels=3).to(device)\n",
    "tokenizer = XLMRobertaTokenizerFast.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['span_input'], padding=True, truncation=True,max_length=8192,return_offsets_mapping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a13640d3-735a-41ba-90d6-379e379c5eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "extraTokens = {\n",
    "    \"additional_special_tokens\": [\"[SPAN_START]\", \"[SPAN_END]\"]\n",
    "}\n",
    "num_added_toks = tokenizer.add_special_tokens(extraTokens)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "print(num_added_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2daddf8b-e0bc-4c01-b94e-2b8e3ecb2631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [0, 3293, 149357, 1556, 142, 5526, 250002, 28368, 250003, 10, 10, 10, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'offset_mapping': [(0, 0), (0, 4), (5, 13), (14, 17), (18, 20), (21, 30), (31, 43), (44, 51), (52, 62), (63, 64), (65, 66), (67, 68), (0, 0)]}\n",
      "['<s>', 'This', 'sentence', 'has', 'an', 'important', '[SPAN_START]', 'subject', '[SPAN_END]', 'a', 'a', 'a', '</s>']\n"
     ]
    }
   ],
   "source": [
    "test_sent = 'This sentence has an important [SPAN_START] subject [SPAN_END] a a a'\n",
    "tokenize = preprocess_function({'span_input' : test_sent})\n",
    "print(tokenize)\n",
    "print(tokenizer.batch_decode(tokenize['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03d6cdb8-97cf-4d45-a862-c612b8879a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.loc[ : , ['span_input','label','new_start_end','entity']]\n",
    "data['tokenized']=data.apply(preprocess_function,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da42e279-71a7-40d3-946d-efa68ffe3f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data.loc[0]['tokenized'])\n",
    "def indexes(row):\n",
    "    off_mask = row['tokenized']['offset_mapping']\n",
    "    start,end = row['new_start_end'][0],row['new_start_end'][1]\n",
    "    inds = list()\n",
    "    for p in range(len(off_mask)):\n",
    "        if off_mask[p][0] >= start and off_mask[p][1] <= end:\n",
    "            if p != len(off_mask)-1:\n",
    "                inds.append(p)\n",
    "    #if len(inds) > 1:\n",
    "        #print(\"GREATER THAN 1\")\n",
    "    if len(inds) == 0:\n",
    "        print(start,end)\n",
    "    return inds\n",
    "data['indexes'] = data.apply(indexes,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e6ee30e-609b-4fc9-af5f-f8923344d950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boris Johnson\n",
      "['Boris', 'Johnson']\n"
     ]
    }
   ],
   "source": [
    "print(data['entity'].loc[500])\n",
    "inds = data['indexes'].loc[500]\n",
    "toks = data['tokenized'].loc[500]\n",
    "tokid = toks['input_ids']\n",
    "a = list()\n",
    "for i in inds:\n",
    "    a.append(tokid[i])\n",
    "print(tokenizer.batch_decode(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "567dd33b-c3fd-46ad-876c-b34602171698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2902 2902 2902\n"
     ]
    }
   ],
   "source": [
    "data['list'] = data['tokenized'].apply(lambda x: x['input_ids'])\n",
    "data['attention'] = data['tokenized'].apply(lambda x: x['attention_mask'])\n",
    "ids = data['list']\n",
    "att = data['attention']\n",
    "indexes = data['indexes']\n",
    "tids = list()\n",
    "tatt = list()\n",
    "print(len(ids),len(att),len(indexes))\n",
    "for i in range(len(ids)):\n",
    "    tids.append(torch.tensor(ids[i]))\n",
    "    tatt.append(torch.tensor(att[i]))\n",
    "#print(tids[0],tatt[0])\n",
    "#print(indexes[448])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "150dd743-7d84-48d0-9f6b-a0ae78291c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(67151), tensor(59520)]\n",
      "['Boris', 'Johnson']\n"
     ]
    }
   ],
   "source": [
    "a = list()\n",
    "for i in indexes[500]:\n",
    "    a.append(tids[500][i])\n",
    "print(a)\n",
    "print(tokenizer.batch_decode(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48d298e4-b4f2-448a-919a-0f2c5a303999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511 588 67 512 67 956 [1, 2]\n"
     ]
    }
   ],
   "source": [
    "sliced_ids = list()\n",
    "sliced_ntids = list()\n",
    "sliced_att = list()\n",
    "key_inds = list()\n",
    "key_ids = list()\n",
    "\n",
    "def slices(index,size,context_size):\n",
    "    if (size<context_size):\n",
    "        return 0,size\n",
    "    lower_c = int(context_size/2-1)\n",
    "    upper_c = int(context_size/2)\n",
    "    #print(lower_c,upper_c)\n",
    "    if index < lower_c:\n",
    "        return 0,context_size\n",
    "    elif index >= lower_c:\n",
    "        if index + upper_c > size:\n",
    "            return index-(context_size-(size-index)), size\n",
    "        else:\n",
    "            return index-lower_c,index+upper_c+1  \n",
    "\n",
    "\n",
    "for i in range(len(tids)):\n",
    "    slower,supper = slices(indexes[i][0],len(tids[i]),510)\n",
    "    #key_tid = tids[i][indexes[i][0]]\n",
    "    pid = ids[i][slower:supper]\n",
    "    key_inds.append([])\n",
    "    for j in indexes[i]: \n",
    "        key_id = ids[i][j]\n",
    "        if key_id not in pid:\n",
    "           print(len(ids[i]),key_id,slower,supper,indexes[i])\n",
    "        key_inds[i].append(pid.index(key_id))\n",
    "    apid = tids[i][slower:supper]\n",
    "    apatt = tatt[i][slower:supper]\n",
    "    if 0 not in pid:\n",
    "        apid = torch.cat((torch.tensor([0]),apid),dim=0)\n",
    "        apatt = torch.cat((torch.tensor([1]),apatt),dim=0)\n",
    "    if 2 not in pid:\n",
    "        apid = torch.cat((apid,torch.tensor([2])),dim=0)\n",
    "        apatt = torch.cat((apatt,torch.tensor([1])),dim=0)\n",
    "    sliced_ids.append(apid)\n",
    "    sliced_att.append(apatt)\n",
    "\n",
    "Min = 10000\n",
    "Max = 0\n",
    "ind2 = 0\n",
    "for i in range(len(indexes)):\n",
    "    if len(sliced_ids[i]) < Min:\n",
    "        Min = len(sliced_ids[i])\n",
    "        ind2 = i\n",
    "        \n",
    "    if len(sliced_ids[i]) > Max:\n",
    "        Max = len(sliced_ids[i])\n",
    "print(len(sliced_ids[500]),len(tids[500]),Min,Max,len(tids[ind2]),ind2,key_inds[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b71f4c94-e14f-47e0-8a54-106bdda4ba76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(67151), tensor(59520)]\n",
      "['Boris', 'Johnson'] Boris Johnson\n"
     ]
    }
   ],
   "source": [
    "a = list()\n",
    "for i in key_inds[500]:\n",
    "    a.append(tids[500][i])\n",
    "print(a)\n",
    "print(tokenizer.batch_decode(a),df['entity'].loc[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b7cc4d9-c11e-4e74-943f-0255165289cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([     0,  67151,  59520,  35968,      7,  19507,    204,  95528,      7,\n",
      "          4420,   1295,     70,  41210,     92,     26,    136,  17378, 102374,\n",
      "        116000,    191,    111,  82739,   1221,    186,    204,  12986,  15663,\n",
      "           538,  39746,    297,     26, 250002,  67151,  59520, 250003,     47,\n",
      "         35968,  19507,    204,  95528,      7,   4420,   1295,     70,  41210,\n",
      "            92,     26,     23,   7639,  34695,  22120,      7,      6,  55776,\n",
      "         95954,    618,   8108,  12403,    214,     47,  82739, 127773,  14216,\n",
      "         45956,  59520,  18925,  19676,     71,  36061,  19507,     44,  95528,\n",
      "             7,   4420,   1295,     70,  41210,     92,     58,    111,   1631,\n",
      "            47,  71864,     10,  50029,  59714,    402,    927,     23,  82739,\n",
      "             5,   1913,   7639,  34695,  22120,      7,      6,  55776,  95954,\n",
      "           618,     70,   7198,   1221,   1631,     19,     70,     57,   4134,\n",
      "             9,   2175,     18,   2069, 110956,     73,  37515,    669,    764,\n",
      "            25,   1181,    186,     44,   3137,    720,    538,    136,  59714,\n",
      "         20102,  39746,    297,     58,   2174,    764, 205491,      7,      5,\n",
      "         49002,   1556,  10283,  29907,    297,   1286,   3501,    805,      4,\n",
      "          9508,   3428,  68818,     98,     70, 132988,    111,  82739,    136,\n",
      "            83,   5737,    297,     47,  95685,     23,      5,   8414,  59520,\n",
      "            20,   2750,     83,  12403,    214,     47,  82739, 127773,   2804,\n",
      "           142, 116000,    191,   2806,    186,     44,     66,  89931,   6392,\n",
      "          1515,    100,     70,   8999,    740,      6, 172797,    214,     23,\n",
      "         36369,    425,      4,   8414,  59520,   2804,     12,     44,  52231,\n",
      "            87,   1221,   5154,     47,  34202,  19507,      4,    237,     87,\n",
      "           765,   2804,   8108,      4,     83,    450,     87,   5351,    642,\n",
      "          6183,    756,   3871,     47,  29954,   4420,   1295,     70,  41210,\n",
      "            92,      5,     44,    568,   5351,  49002,  27117,     47,  29954,\n",
      "          4420,   1295,     70,  41210,     92,      5,     44,    568,   5351,\n",
      "           450,    142, 116000,    191,    111,  82739,      4,   2499,  73106,\n",
      "          6889,   3934,  82739, 107314,     70, 181991,     53,    450,  49002,\n",
      "          1556,  21771,  39958,     23,   1049,   2806,    186,    142,  89931,\n",
      "          6392,   1515,    100,     70,   8999,      4,    136,  36917,    756,\n",
      "           442,   2806,    186,     10,   6392,   1515,    100,  49002,   1242,\n",
      "          1529,   2804,    450,   2499, 102374, 116000,    191,   2806,    186,\n",
      "            44,   3137,    720,    538,    136,  59714,  20102,  39746,    297,\n",
      "            58,    390,     70,  61764,   3378,   3395,      5,     62, 185464,\n",
      "         33744,  18925,   2804, 102126,    621,     44,   3041,  36659,   2363,\n",
      "         74261,     58,     98,    456,  22189,  26518,  26548, 102374, 229000,\n",
      "           191,  98186,  82739,      4,     10, 185464,  33744,   9932,  14437,\n",
      "         18925,      5,   4804,    162,  44616, 127873,  72199,  26328,  91865,\n",
      "            13,  35627,   6259,  26548,     70,  13584,  16680,   1495,   3747,\n",
      "         57553,     20,    136,   1337,   6259,  61738,    100,     95,  19514,\n",
      "        130891,     91,   2452,   2480,    538,   5962,   4420,     99,  36061,\n",
      "         19507,      5,  17006,  12301,     23,    581,   7550,    581,  17274,\n",
      "            83,  58172,    214,     47,     91,   3719, 167244,      7,     98,\n",
      "          4620,      7,    136,   1194,   1970,    206,      7,    678,  21941,\n",
      "            47,     70, 110956,     73,     47,  15504,     70,   4911,   6492,\n",
      "             7,   7612,  19725,     98,  49002,      5,  56101,  30641,  79063,\n",
      "          1314,    621,     51,   5062,    538,     47,    186,   9325,     47,\n",
      "         78431,      4,    678,     70,   7198,  64457,  12601,   2852,     47,\n",
      "         13625,   6366,    133, 102374,  11037,      7,      5,   8414,  91865,\n",
      "            13,   2804,    903,  42141,     12,     44,  12137,    621,   4552,\n",
      "         34735,    450,   2174,  49002,  51776,  53333,  22631,  26548,  82739,\n",
      "             4,   7068,    642,   1221,  53333, 107137,     33,     70, 167244,\n",
      "             7,  63647,      7,  30388,    214,   8382, 108880,      4,    136,\n",
      "          3395,    678,     70,  20903,    271,  22317,     47,     70, 110956,\n",
      "            73,      5,     44, 215719, 130891,     83,   1632,    111,     70,\n",
      "           100,   9825,     18,    233,  54137,      7,      2]) tensor([     2,      7,  54137,    233,     18,   9825,    100,     70,    111,\n",
      "          1632,     83, 130891, 215719,     44,      5,     73, 110956,     70,\n",
      "            47,  22317,    271,  20903,     70,    678,   3395,    136,      4,\n",
      "        108880,   8382,    214,  30388,      7,  63647,      7, 167244,     70,\n",
      "            33, 107137,  53333,   1221,    642,   7068,      4,  82739,  26548,\n",
      "         22631,  53333,  51776,  49002,   2174,    450,  34735,   4552,    621,\n",
      "         12137,     44,     12,  42141,    903,   2804,     13,  91865,   8414,\n",
      "             5,      7,  11037, 102374,    133,   6366,  13625,     47,   2852,\n",
      "         12601,  64457,   7198,     70,    678,      4,  78431,     47,   9325,\n",
      "           186,     47,    538,   5062,     51,    621,   1314,  79063,  30641,\n",
      "         56101,      5,  49002,     98,  19725,   7612,      7,   6492,   4911,\n",
      "            70,  15504,     47,     73, 110956,     70,     47,  21941,    678,\n",
      "             7,    206,   1970,   1194,    136,      7,   4620,     98,      7,\n",
      "        167244,   3719,     91,     47,    214,  58172,     83,  17274,    581,\n",
      "          7550,    581,     23,  12301,  17006,      5,  19507,  36061,     99,\n",
      "          4420,   5962,    538,   2480,   2452,     91, 130891,  19514,     95,\n",
      "           100,  61738,   6259,   1337,    136,     20,  57553,   3747,   1495,\n",
      "         16680,  13584,     70,  26548,   6259,  35627,     13,  91865,  26328,\n",
      "         72199, 127873,  44616,    162,   4804,      5,  18925,  14437,   9932,\n",
      "         33744, 185464,     10,      4,  82739,  98186,    191, 229000, 102374,\n",
      "         26548,  26518,  22189,    456,     98,     58,  74261,   2363,  36659,\n",
      "          3041,     44,    621, 102126,   2804,  18925,  33744, 185464,     62,\n",
      "             5,   3395,   3378,  61764,     70,    390,     58,    297,  39746,\n",
      "         20102,  59714,    136,    538,    720,   3137,     44,    186,   2806,\n",
      "           191, 116000, 102374,   2499,    450,   2804,   1529,   1242,  49002,\n",
      "           100,   1515,   6392,     10,    186,   2806,    442,    756,  36917,\n",
      "           136,      4,   8999,     70,    100,   1515,   6392,  89931,    142,\n",
      "           186,   2806,   1049,     23,  39958,  21771,   1556,  49002,    450,\n",
      "            53, 181991,     70, 107314,  82739,   3934,   6889,  73106,   2499,\n",
      "             4,  82739,    111,    191, 116000,    142,    450,   5351,    568,\n",
      "            44,      5,     92,  41210,     70,   1295,   4420,  29954,     47,\n",
      "         27117,  49002,   5351,    568,     44,      5,     92,  41210,     70,\n",
      "          1295,   4420,  29954,     47,   3871,    756,   6183,    642,   5351,\n",
      "            87,    450,     83,      4,   8108,   2804,    765,     87,    237,\n",
      "             4,  19507,  34202,     47,   5154,   1221,     87,  52231,     44,\n",
      "            12,   2804,  59520,   8414,      4,    425,  36369,     23,    214,\n",
      "        172797,      6,    740,   8999,     70,    100,   1515,   6392,  89931,\n",
      "            66,     44,    186,   2806,    191, 116000,    142,   2804, 127773,\n",
      "         82739,     47,    214,  12403,     83,   2750,     20,  59520,   8414,\n",
      "             5,     23,  95685,     47,    297,   5737,     83,    136,  82739,\n",
      "           111, 132988,     70,     98,  68818,   3428,   9508,      4,    805,\n",
      "          3501,   1286,    297,  29907,  10283,   1556,  49002,      5,      7,\n",
      "        205491,    764,   2174,     58,    297,  39746,  20102,  59714,    136,\n",
      "           538,    720,   3137,     44,    186,   1181,     25,    764,    669,\n",
      "         37515,     73, 110956,   2069,     18,   2175,      9,   4134,     57,\n",
      "            70,     19,   1631,   1221,   7198,     70,    618,  95954,  55776,\n",
      "             6,      7,  22120,  34695,   7639,   1913,      5,  82739,     23,\n",
      "           927,    402,  59714,  50029,     10,  71864,     47,   1631,    111,\n",
      "            58,     92,  41210,     70,   1295,   4420,      7,  95528,     44,\n",
      "         19507,  36061,     71,  19676,  18925,  59520,  45956,  14216, 127773,\n",
      "         82739,     47,    214,  12403,   8108,    618,  95954,  55776,      6,\n",
      "             7,  22120,  34695,   7639,     23,     26,     92,  41210,     70,\n",
      "          1295,   4420,      7,  95528,    204,  19507,  35968,     47, 250003,\n",
      "         59520,  67151, 250002,     26,    297,  39746,    538,  15663,  12986,\n",
      "           204,    186,   1221,  82739,    111,    191, 116000, 102374,  17378,\n",
      "           136,     26,     92,  41210,     70,   1295,   4420,      7,  95528,\n",
      "           204,  19507,      7,  35968,  59520,  67151,      0])\n"
     ]
    }
   ],
   "source": [
    "print(sliced_ids[500],sliced_ids[500].flip(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c44c4ca-056b-4260-85b8-d642dcb53700",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_ids = list()\n",
    "att_mask = list()\n",
    "for ten,att in zip(sliced_ids,sliced_att):\n",
    "    if len(ten) < 512:\n",
    "        padding_length = 512 - len(ten)\n",
    "        padding_tensor = torch.full((padding_length,), tokenizer.pad_token_id, dtype=ten.dtype)\n",
    "        padding_tensor2 = torch.full((padding_length,), 0, dtype=att.dtype)\n",
    "        ten = torch.cat((ten,padding_tensor),dim=0)\n",
    "        att = torch.cat((att,padding_tensor2),dim=0)\n",
    "    input_ids.append(ten)\n",
    "    att_mask.append(att)\n",
    "inputIds = torch.stack(input_ids)\n",
    "attMask = torch.stack(att_mask)\n",
    "#print(input_ids[300],attMask[300],inputIds.shape,attMask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6bd8a07-ce74-497e-9878-c02257ef7129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(6), tensor(213542)]\n"
     ]
    }
   ],
   "source": [
    "a = list()\n",
    "for i in key_inds[300]:\n",
    "    a.append(inputIds[300][i])\n",
    "print(a)\n",
    "#print(tokenizer.batch_decode(a),df['entity'].loc[300])\n",
    "#print(tokenizer.batch_decode(inputIds[300]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "208eb938-63ee-4fe6-bbab-418ef8cca803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0] [[     0   1089  22617 ...      1      1      1]\n",
      " [     0   1089  22617 ...      1      1      1]\n",
      " [     0   1089  22617 ...      1      1      1]\n",
      " ...\n",
      " [     0   1343 212212 ...      5      2      1]\n",
      " [     0 189322     12 ...   1993      2      1]\n",
      " [     0   5832   9279 ...      1      1      1]] [[1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " ...\n",
      " [1 1 1 ... 1 1 0]\n",
      " [1 1 1 ... 1 1 0]\n",
      " [1 1 1 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "inputIds_np = inputIds.numpy()\n",
    "attMask_np = attMask.numpy()\n",
    "y = data['label'].values\n",
    "print(y,inputIds_np,attMask_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de973aaf-a7b4-4e7c-b45a-2aebe5f20a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_ids, X_test_ids, X_train_mask, X_test_mask, y_train, y_test = train_test_split(\n",
    "    inputIds_np, attMask_np, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4948f652-363a-4538-af4e-600f78cb0e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ids = torch.tensor(X_train_ids, dtype=torch.long).to(device)\n",
    "X_test_ids = torch.tensor(X_test_ids, dtype=torch.long).to(device)\n",
    "X_train_mask = torch.tensor(X_train_mask, dtype=torch.long).to(device)\n",
    "X_test_mask = torch.tensor(X_test_mask, dtype=torch.long).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "baf2fbe0-8d26-4b07-bc12-876bcab6eb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorDatasets\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(X_train_ids, X_train_mask, y_train)\n",
    "test_dataset = TensorDataset(X_test_ids, X_test_mask, y_test)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1baa684-92bf-42a2-9588-8ecf9d81104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "optimizer = AdamW(model.parameters(), lr=8e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ccdb31a2-4b5f-450f-9e66-1b4a0d89cd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 146/146 [02:09<00:00,  1.13it/s, loss=0.881]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Training loss: 1.0459, Training accuracy: 0.4632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 1/10: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:09<00:00,  3.82it/s, loss=0.73]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.9752, Test accuracy: 0.5422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/10: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 146/146 [02:10<00:00,  1.12it/s, loss=0.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "Training loss: 0.9710, Training accuracy: 0.5291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 2/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:09<00:00,  3.81it/s, loss=0.735]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.9268, Test accuracy: 0.5749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 146/146 [02:09<00:00,  1.13it/s, loss=0.472]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "Training loss: 0.9300, Training accuracy: 0.5756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 3/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:09<00:00,  3.80it/s, loss=0.599]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.9461, Test accuracy: 0.5525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 146/146 [02:09<00:00,  1.12it/s, loss=0.912]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "Training loss: 0.8416, Training accuracy: 0.6312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 4/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:09<00:00,  3.81it/s, loss=0.696]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6818, Test accuracy: 0.7177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 146/146 [02:09<00:00,  1.13it/s, loss=0.652]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "Training loss: 0.6279, Training accuracy: 0.7583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 5/10: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:09<00:00,  3.76it/s, loss=0.67]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5451, Test accuracy: 0.7986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 146/146 [02:11<00:00,  1.11it/s, loss=0.126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "Training loss: 0.4368, Training accuracy: 0.8440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 6/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:09<00:00,  3.74it/s, loss=0.771]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5106, Test accuracy: 0.8313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/10: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 146/146 [02:11<00:00,  1.11it/s, loss=0.0502]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "Training loss: 0.3189, Training accuracy: 0.8957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 7/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:09<00:00,  3.75it/s, loss=0.689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.4929, Test accuracy: 0.8330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/10: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 146/146 [02:10<00:00,  1.12it/s, loss=0.0738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "Training loss: 0.1983, Training accuracy: 0.9388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 8/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:09<00:00,  3.81it/s, loss=0.579]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5328, Test accuracy: 0.8451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/10: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 146/146 [02:09<00:00,  1.13it/s, loss=0.0215]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "Training loss: 0.1510, Training accuracy: 0.9556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 9/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:09<00:00,  3.81it/s, loss=0.883]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5928, Test accuracy: 0.8382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 146/146 [02:09<00:00,  1.13it/s, loss=0.0336]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "Training loss: 0.1239, Training accuracy: 0.9660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Epoch 10/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 37/37 [00:09<00:00,  3.81it/s, loss=0.84]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6217, Test accuracy: 0.8451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    # Initialize tqdm progress bar for training\n",
    "    train_progress_bar = tqdm(train_dataloader, desc=f\"Training Epoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    for batch in train_progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        labels = batch[2].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        #print(preds)\n",
    "        correct_predictions += (preds == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "        \n",
    "        # Update tqdm description with current loss\n",
    "        train_progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    print(f\"Training loss: {avg_train_loss:.4f}, Training accuracy: {train_accuracy:.4f}\")\n",
    "    \n",
    "    # Test phase\n",
    "    model.eval()\n",
    "    test_loss = 0 \n",
    "    correct_test_predictions = 0\n",
    "    total_test_predictions = 0\n",
    "    \n",
    "    # Initialize tqdm progress bar for test\n",
    "    test_progress_bar = tqdm(test_dataloader, desc=f\"Test Epoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_progress_bar:\n",
    "            input_ids = batch[0].to(device)\n",
    "            attention_mask = batch[1].to(device)\n",
    "            labels = batch[2].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Calculate test accuracy\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            correct_test_predictions += (preds == labels).sum().item()\n",
    "            total_test_predictions += labels.size(0)\n",
    "            \n",
    "            # Update tqdm description with current loss\n",
    "            test_progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    avg_test_loss = test_loss / len(test_dataloader)\n",
    "    test_accuracy = correct_test_predictions / total_test_predictions\n",
    "    \n",
    "    print(f\"Test loss: {avg_test_loss:.4f}, Test accuracy: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
